\chapter{Related Work}
\label{sec:related}

% TODO whatever else isn't here yet, and some of this might be factored out or partially factored out---all papers, including survey, plus generals.
% then organize and clean.

Proof repair can be viewed as program repair (Section~\ref{sec:repair})
for the domain of proof engineering (Section~\ref{sec:proofeng}).

\section{Proof Engineering}
\label{sec:proofeng}

\textit{Proof engineering} refers to the technologies that make it easier to develop and maintain
systems verified using proof assistants.
Proof repair falls into the domain of proof engineering.
This section briefly describes work in proof engineering relevant to my work on proof repair:
proof assistants other than Coq (Section~\ref{sec:ass}),
other technologies for proof evolution (Section~\ref{sec:refrep}),
proof reuse (Section~\ref{sec:reuse}),
proof design (Section~\ref{sec:design}),
and other kinds of proof automation (Section~\ref{sec:automation}.
See my and my coauthors' survey paper on proof engineering for a detailed overview of the field~\cite{PGL-045}. % TODO credit coauthors

\subsection{Proof Assistants}
\label{sec:ass}

Proof engineering as defined in our survey paper considers proof assistants that satisfy the \textit{de Bruijn criterion}~\cite{Barendregt2002,Barendregt2351}, which requires that they produce proof objects that a small proof-checking kernel can verify.
This includes Coq~\cite{coq}---the proof assistant that this thesis focuses on---but also other proof assistants like
Isabelle/HOL~\cite{isabelle}, HOL Light~\cite{hollight}, HOL4~\cite{hol4-interact}, Agda~\cite{agda}, Lean~\cite{lean}, and NuPRL~\cite{nuprl}.
These proof assistants have different foundations (in the case of Coq, \kl{CIC$_{\omega}$}),
different notions of proof objects (in the case of Coq, proof terms in \kl{Gallina}),
and different automation built on top of those proof objects (in the case of Coq, proof scripts in \kl{Ltac}).
Differences in proof assistants along these dimensions have different implications for proof repair.

\paragraph{Foundations}
The foundations that make up proof assistants vary by proof assistant.
The foundations of Coq, for example, build on the type theory \kl{CIC$_{\omega}$}.
CIC$_{\omega}$ is \textit{intuitionistic}~\cite{Heyting1956} (or \textit{constructive}) in that
proofs in CIC$_{\omega}$ must be constructed from basic principles.
For example, CIC$_{\omega}$ does not assume the \textit{Law of the Excluded Middle} (LEM),
which states that for any proposition, either that proposition is true, or its negation is true.
CIC$_{\omega}$ also does not assume \textit{Double Negation Elimination} (DNE),
which states that the negation of the negation is the original proposition or type.
Because of this, in CIC$_{\omega}$, it is not possible in general to prove existence by proving that 
nonexistence implies a contradiction.
Instead, one must supply a witness to the existential.\footnote{Perhaps notably, though, the witness to the existential can be that 
DNE \emph{provably} holds for a particular instance. This is true for decidable domains in \kl{CIC$_{\omega}$}.} 

The proof assistants Isabelle/HOL~\cite{isabelle}, HOL Light~\cite{hollight}, and HOL4~\cite{hol4-interact} are built on \textit{classical} foundations
in that they assume both LEM and DNE.
The proof assistants Agda and Lean are built on constructive foundations that are similar to Coq, though with some minor differences.
Lean in particular further assumes an axiom called \textit{Uniqueness of Identity Proofs} (UIP), which states that all proofs of
equality at a given type are equal.
As I detail in the survey paper, this axiom is incompatible with the \textit{univalence} axiom from Homotopy Type Theory~\cite{univalent2013homotopy},
which states that equivalence is equivalent to equality.
Cubical type theory~\cite{cohen2016cubical, angiuli2017cubical} gives univalence a constructive interpretation,
so that it is no longer an axiom.\footnote{There are two flavors of cubical type theory.
Bob Harper noted that I neglected to mention one of these in the proof engineering survey paper; I deeply regret this.
So I would like to draw extra attention to the paper by Carlo Angiuli, Bob Harper, and Todd Wilson that I have cited here~\cite{angiuli2017cubical}.}
Implementations of cubical type theory include RedPRL~\cite{redprl} and Cubical Agda~\cite{cubical-agda}.

Proof repair in this thesis assumes constructive rather than classical foundations.
The core techniques should largely transfer to other proof assistants built on constructive foundations, like Agda and Lean.
It is possible that the particular transformations may have to account for differences, like the presence of UIP in Lean,
which may make the correctness statement of the \toolnamec transformation---one that relies on univalence at the level of the metatheory---less meaningful.
The techniques transfer with a bit more resistance to proof assistants built on classical foundations,
since classical proofs may omit information helpful for repair.

\paragraph{Proof Objects} 
In proof assistants that satisfy the de Bruijn criterion, proof objects are the certificates that the kernel can check to make sure it proves a given theorem.
In Coq, proof objects are proof terms in \kl{Gallina}; the kernel verifies these terms by checking their types.
As \kl{Karl} notes in our survey paper, explicitly producing proof objects and checking them is one of two dominant approaches to satisfying 
the de Bruijn criterion---an approach followed by Coq, Agda, and Lean.
The other is to produce \textit{ephemeral} proof objects that are correct by construction~\cite{Barendregt2013}---an approach followed
by Isabelle/HOL, HOL Light, and HOL4. % what about NuPRL?

Proof repair in this thesis assumes explicit rather than ephemeral proof objects.
One possible way to apply the same techniques to proof assistants with ephemeral proof objects is to follow the following workflow:

\begin{enumerate}
\item Reify ephemeral proof objects to be explicit.
\item Apply differencing and transformations over those objects.
\item Decompile the transformed proof objects to automation.
\end{enumerate}
Chapter~\ref{chapt:conclusions} describes an example of this for Isabelle/HOL.

\paragraph{Automation} %Like different tactic languages.
Directly constructing proof objects may be too low-level to provide for a positive user experience for the proof engineer,
and in some cases the proof object may not be exposed to the proof engineer at all.
Typically, automation acts as an interface between the proof engineer and the kernel.
In Coq, for example, proof engineers write proof scripts interactively using tactics.
Proof engineers can combine existing tactics, or write their own, either in the general-purpose programming language
OCaml or in the tactic language \kl{Ltac}. 

In contrast, in Isabelle/HOL, proof engineers commonly write proofs in Isabelle/Isar~\cite{wenzel1999isar, Wenzel2007isar}, which is a high-level \textit{proof language}:
a language for structuring and composing propositions, facts, and proof goals.
Proof engineers can also mix these styles.
For example, Coq proof engineers can write proofs using the high-level proof language SSReflect~\cite{Gonthier2010, Gonthier2008},
or they can even mix SSReflect with Ltac tactics.
Isabelle/HOL proof engineers can write automation in the general-purpose language Standard ML---which was originally introduced specifically
for developing proof automation~\cite{Gordon1978}---or with the Ltac-inspired tactic language Eisbach~\cite{Matichuk2015EisbachAP}.
Agda proof engineers typical rely only on reflection~\cite{Demers95reflectionin, harrison-reflection, van2012engineering} to write proof automation.

The approach to proof repair taken in this thesis is independent of the kind of automation used, or the language used to implement it.
All that needs to change to transfer this approach to a different tactic or proof language, for example,
is the implementation of the decompiler.
Still, some kinds of automation may produce proof terms that are especially difficult to difference and transform,
or may make decompilation especially difficult.

Better languages for automation can also help circumvent some of the difficulties of repairing tactics directly, rather than relying a decompiler.
Or, they may help simplify the implementation of the decompiler.
The Ltac successor Ltac2~\cite{ltac2}, for example, is much more structured than Ltac, and may help ease proof repair in Coq in the future.

\subsection{Proof Evolution}
\label{sec:refrep}

% TODO some of this may move into Chapter 2

The need to evolve proofs to changes was raised as a barrier for verification of real software systems as far back as 1977, in my favorite critique of program verification~\cite{DeMillo1977}.
This barrier has been realized in real developments; a review~\cite{Elphinstone2013} of the evolution of the seL4 verified 
OS microkernel~\cite{Klein2009}, for example, notes that while
customizing the kernel to different environments may be desirable, 
``the formal verification of seL4 creates a powerful disincentive to changing the kernel.''
Leroy and friends 2012~\cite{leroy2012} motivates and describes updates to the initial CompCert memory model
that include changes in specifications, automation, and proofs~\cite{leroy-mem-2010}.

As I have shown in this thesis, breaking changes are not always in the proof engineer's control.
\textit{Proof refactoring}~\cite{WhitesidePhD} tools---meant to help proof engineers redesign proof developments---can also help proof engineers
repair proofs in response to breaking changes.
These tools are the proof engineering equivalent of \textit{program refactoring} tools, or tools
that restructure code in a way that preserves semantics~\cite{opdyke1992}.
While proof repair is a concept that I introduced with the work in this thesis,
some proof refactoring tools developed in parallel with my work can be viewed as proof repair tools.
This section describes refactoring tools that work at the level of proof scripts and proof terms;
\toolnamec is the only tool for proof evolution I am aware of that supports both proof scripts and proof terms.

\paragraph{Proof Scripts}
A few proof refactoring tools operate directly over tactics:
\textsc{POLAR}~\cite{Dietrich2013} refactors proof scripts in languages based on Isabelle/Isar~\cite{Wenzel2007isar},
CoqPIE~\cite{Roe2016} is an IDE with support for simple refactorings of Ltac scripts, and
Tactician~\cite{adams2015} is a refactoring tool for proof scripts in HOL Light
that focuses on refactoring proofs between sequences of tactics and tacticals.
This approach is not tractable for more complex changes~\cite{robert2018}.

Some proof refactoring tools focus on specific refactoring tasks that are common in proof development.
For example, Levity~\cite{Bourke12} is a proof refactoring tool for an old version of Isabelle/HOL that automatically
moves lemmas to maximize reuse. The design of Levity is informed by experiences with two large proof developments.
Levity addresses problems that are especially pronounced in the domain of proof refactoring, such as the
context-sensitivity of proof scripts. Levity has seen large scale industrial use.
 
\paragraph{Proof Terms}
There is little work on refactoring proof terms directly. This is the main focus of Chick~\cite{robert2018}, 
which refactors terms in a language similar to \kl{Gallina}.
Chick was developed in parallel to the \sysname prototype, and both tools influenced one another.
Consequentially, Chick and \sysnamelong have similar workflows:
both take example changes supplied by the proof engineer,
use differencing algorithms to determine the changes to make elsewhere,
and then (in Chick and \toolnamec, but only sometimes in \sysname) apply the changes they find. 
Chick supports insertion, deletion, modification, and permutation of subterms.
Chick does this using a syntactic algorithm that handles only simple transformations,
and so presents itself primarily as a proof refactoring tool.

Another term-based refactoring tool is the refactoring tool RefactorAgda~\cite{wibergh2019} for a subset of Agda terms.
RefactorAgda supports many changes, including changing indentation, renaming terms, moving terms, converting between implicit and
explicit arguments, reordering subterms, and adding or removing constructors to or from types; 
it also documents ideas for supporting other refactorings, such as adding and removing arguments and indicies to and from types.
Both Chick and RefactorAgda support primarily syntactic changes and do not have tactic support.

\subsection{Proof Reuse}
\label{sec:reuse}

Proof repair is ultimately a form of \textit{proof reuse}---applying software reuse principles to proof assistants
in order to repurpose existing proofs as much as possible.
Like software reuse, proof reuse leverages design principles and language constructs.
In addition, the interactive nature of proof assistants naturally leads to a class of proof reuse technologies less explored
in the software reuse world: automated tooling.
Proof repair falls into the class of automated tooling for proof reuse.
This section describes other automated tooling for proof reuse that may be useful to a future proof repair tool.

\paragraph{Extending Inductive Types} 
\toolnamec is yet to save proof engineers work when it comes to extending inductive types.
In the future, it may help to draw on early work in proof reuse for extending inductive types.
For example, a 2004 paper~\cite{Boite2004} describes a tactic to adapt proof obligations
to changes in inductive types.
Soon after, a 2006 paper~\cite{Mulhern06proofweaving} provides a high-level
description of a possible method to synthesize missing proofs for those new obligations using a type reconstruction algorithm,
though it is not currently implemented.

\iffalse
\paragraph{Proof Planning}
Proof repair tools may also benefit from work in \textit{proof planning}~\cite{Bundy1998}, a proof search technique
that uses plans to guide search for proofs with similar structures.
Proof planning can involve the use of \textit{critics}~\cite{ireland1996},
which reuse information from failing proofs to guide search for correct proofs.
While proof planning was originally designed for use with automated theorem provers, it has also reached
proof assistants.
For example, IsaPlanner~\citep{Dixon2003} is a proof planner for Isabelle with support
for rippling~\citep{shah2005}, a technique for automatic induction.
Rippling has also been implemented in an induction automation
tool for Coq~\citep{wilson2010}.
\fi

\paragraph{Proof Transformation}
Proof repair in this thesis combiness differencing with proof term transformations, or program transformations over proof terms.
The idea of applying program transformations over proof terms dates back to at least 1987~\cite{pfenning}.
Any proof reuse tool that works by proof term transformation can, in theory, be used for repair,
especially when coupled with something like the \toolnamec decompiler.

One common proof term transformation is \textit{generalization}, which arose in the context of proof assistants
in the 1990s~\cite{hasker1992generalization, kolbe1998proof, pons1999conception}.
Coq's \lstinline{generalize} tactic does basic syntactic generalization~\cite{coq-tactics}.
Both \sysnamelong and a tool~\cite{Johnsen2004} for generalizing theorems in Isabelle/HOL
implement more complex transformations for generalization.

Magaud \& Bertot 2000~\cite{magaud2000changing} implement a proof term transformation between
unary and binary numbers. 
This fits into a \toolnamec configuration.
Still, the expansion algorithm from the paper describing this transformation may help guide the design
of better unification heuristics for \toolnamec.

The refinement framework CoqEAL~\cite{cohen:hal-01113453} transforms functions across relations in Coq,
and these relations can be more general than \toolnamec's equivalences.
However, while \toolnamec supports both functions and proofs, CoqEAL supports only simple functions
due to the problem that \lstinline{Iota} addresses.
CoqEAL may be most useful to chain with \toolnamec to get faster functions,
or to help support better workflows for changes that do not correspond to equivalences.

One of the automatic configurations in \toolnamec automates discovery of and transport across algebraic ornaments.
This automatic configuration formed the basis of the first tool for ornamentation to operate over a non-embedded dependently typed language,
initially called \textsc{Devoid}---but later generalized all equivalences and renamed \toolnamec.
This stands in contrast to the many wonderful embedded implementations of 
ornaments~\cite{Dagand:2013:CTO:2591370.2591396, ko2013relational, dagand2014transporting, ko2016programming, dagand2017essence}
that had arose since their discovery~\cite{mcbride}.
It essentially moved the automation-heavy approach of Ornamentation in ML~\cite{Williams2017},
which operates on non-embedded ML code, into CIC$_{\omega}$.
It also introduced the first differencing algorithm to identify ornaments, which in the past 
had been identified as a ``gap'' in the literature~\cite{ko2016programming}.
Other kinds of ornaments may prove useful for future \toolnamec differencing algorithms and configurations.
A recent thesis~\cite{williamsphd} on ornaments may prove especially useful.
% TODO survey paper, and some of the work below
% TODO note the thing about transfer versus transport, and correct thesis (see Twitter)

\paragraph{Transfer \& Transport}
\toolnamec automatically transports proofs across equivalences.
The need to automatically \textit{transfer} functions and proofs across equivalences and other relations is a long-standing challenge for proof 
engineers~\cite{magaud2000changing, Barthe2001, magaud2003changing}.
Particular successful is the widely used Transfer~\cite{Huffman2013} package, which supports proof reuse in Isabelle/HOL. % TODO somewhere discuss other proof assistants
Transfer works by combining a set of extensible transfer rules with a type inference algorithm.
Transfer is not yet suitable for repair, as it necessitates maintaining references to both datatypes.
Chapter~\ref{chapt:conclusions} describes one possible path building on Transfer to implement a proof repair tool for Isabelle/HOL.
%In addition, the proof assistant Isabelle/HOL that Transfer works for lacks both dependent types and proof terms.

The \toolnamec transformation implements a particular kind of transfer called automatic transport.
The name here is a bit overloaded and (in my opinion) confusing: \textit{transport} itself refers to a particular form of 
rewriting along a propositional equality, or inhabitance of the identity type.
It often (but not always) refers to \textit{univalent transport}, an induction principle derivable
in homotopy type theory from univalence~\cite{univalent2013homotopy}
that rewrites along the identity type corresponding to an equivalence~\cite{escardo2018self}.
\textit{Automatic transport} refers to any automated tooling for rewriting along propositional equalities
that behaves like transport at the level of either the theory or (as in \toolnamec) the metatheory.
Automatic transport is a kind of transfer, though transport itself is not,
and transfer may apply more broadly than across equalities or equivalences.\footnote{I got this wrong in the survey paper.}

\toolnamec implements automatic univalent transport without relying on any additional axioms at the level of the theory itself.
UP~\cite{tabareau2017equivalences} approximates automatic univalent transport
in Coq, only sometimes relying on functional extensionality.
While powerful, it does not remove references to the old type, making it poorly suited for repair.
However, unlike \toolnamec, it supports type-directed search---analogous functionality
may help improve \toolnamec substantially.

Recent work~\cite{tabareau2019marriage} extends UP with 
a white-box transformation that may work for repair,
but that imposes proof obligations on the proof engineer beyond those imposed by \toolnamec,
%that establish what is effectively the correctness criteria
%for the configuration in \toolname, while \toolname needs only that it holds metatheoretically.
and that includes neither differencing algorithms for equivalences nor proof script generation.
It also does not support changes in inductive structure,
instead relying on its original black-box functionality;
\lstinline{Iota} solves this in \toolnamec, and is based on lessons learned from reading that article.
The most fruitful progress may come from combining these tools. % to take advantage of the benefits of both.

\subsection{Proof Design}
\label{sec:design}

Much work focuses on designing proofs
to be robust to change, rather than fixing broken proofs.
This can take the form of robust abstractions or robust automation.

% TODO QED if time

\paragraph{Robust Abstractions}
Proof engineers often use design principles to make proofs less likely to break to beign with.
Examples of this include using 
information hiding techniques~\cite{Woos:2016:PCF:2854065.2854081, Klein2014}
or any of the structures~\cite{Chrzaszcz2003, Sozeau2008, Saibi:PhD} for encoding interfaces in Coq.
CertiKOS~\cite{certikos} introduces the idea of a deep specification to ease verification of large systems.
Design principles for specific domains (like formal metatheory~\cite{Aydemir2008, Delaware2013POPL, Delaware2013ICFP})
can also make verification more tractable.
Design and repair are complementary: design requires foresight, while repair can occur retroactively.
Repair can help with changes that occur outside of the proof engineer's control,
or with changes that are difficult to protect against even with informed design.

\paragraph{Robust Automation}
Another approach to robust design is to use heavy proof automation, for example through
program-specific proof automation~\cite{chlipala:cpdt}
%implementations of decision procedures~\cite{Pugh1991},
or general-purpose hammers~\cite{Blanchette2016b, Blanchette2013, Kaliszyk2014, Czajka2018}.
The degree to which proof engineers rely on automation varies, as seen in the data from the \textsc{REPLica} user study.
Automation-heavy proof engineering styles localize the burden of change to the automation,
but can result in terms that are large and slow to type check,
and tactics that can be difficult to debug.
While these approaches are complementary, more work is needed for proof repair tools to better support 
developments in this style.

\subsection{Proof Automation}
\label{sec:automation}

Proof repair implements a kind of proof automation.
New proof automation continues to make proof repair more feasible.

\paragraph{Ontology Repair}
GALILEO~\cite{chan2011galileo} is a tool build on Isabelle for identifying and repairing faulty ontologies in response to contradictory
evidence; it has been applied to repair faulty physics ontologies, and may have applications more generally for mathematical proofs.
GALILEO uses repair plans to determine when to trigger a repair, as well as how to repair the ontology.

\paragraph{Knowledge Sharing Methods}
Knowledge sharing methods~\cite{gauthier2014} match concepts across
different proof assistants with similar logics and identify isomorphic types,
and may have implications for proof repair.
Later work uses these methods in combination with HOL(y)Hammer to
reprove parts of the standard library of HOL4 and HOL Light using combined knowledge 
from the two proof assistants~\cite{Gauthier2015}. 
More recently, this approach has been used to identify similar concepts
across libraries in proof assistants with different logics~\cite{gauthier2017}.
These methods combined with automation like hammers may help the proof engineer 
adapt proofs between isomorphic types, and may have applications
when repairing proofs even within the same logic, using information from different 
libraries, different commits, or different representations of similar types.

\paragraph{E-Graphs} % TODO lol this sucks
The \toolnamec proof term transformation can in some sense be viewed as a rewrite system across equivalences.
A number of modern rewrite systems use data structures called \textit{e-graphs}~\cite{egraph1} for managing equivalences~\cite{egg}.
E-graphs have been implemented in Lean~\cite{selsam:lean} (assuming UIP),
and in Cubical Agda~\cite{egraph6} (implying univalence).
Similar implementations of e-graphs could help improve \toolnamec and similar tools to support
type-directed search and more (Chapter~\ref{chapt:conclusions}).

\section{Program Repair}
\label{sec:repair}

Proof repair can be viewed as a form of \textit{program repair}~\cite{Monperrus:2018:ASR:3177787.3105906, Gazzola:2018:ASR:3180155.3182526}
for proof assistants. % TODO use knowledge package
Proof assistants like Coq are an especially good fit for program repair (Section~\ref{sec:lessons}).
While it is not straightforward to apply existing program repair techniques to proof assistants,
looking to them for inspiration may help improve proof repair tools more in the future (Section~\ref{sec:techniques}).

\subsection{A Good Fit}
\label{sec:lessons}

A recent survey of program repair distinguishes between repair tools based on the \textit{oracle} they use to
judge whether a patch is correct.
For example, proof repair is a kind of \textit{specification-based} repair,
since it uses a specification (a goal type derived from differencing) as an oracle.
Program repair tools sometimes use other oracles---commonly, test suites (\textit{test-based} repair).

A recent review~\cite{Qi:2015:APP:2771783.2771791} of a popular test-based program repair tool~\cite{LeGoues:2012:SSA:2337223.2337225} and its variants
shows that most of the reported patches generated by the tool are not correct.
These observations are later reaffirmed in a different setting~\cite{DBLP:journals/corr/abs-1811-02429}.
In response, the paper recommends that program repair tools draw on extra information, like specifications or example patches.
In Coq, specifications and examples are rich and widely available: specifications thanks to dependent types,
and examples thanks to constructivism. This shows why proof repair in Coq is an especially good fit for program repair.
 
\paragraph{Specifications}
One limitation of test-based program repair tools is that tests in evaluation suites are often underspecified,
so it can be hard to know when a patch to a program is correct.
For example, the review notes that some tests in the evaluation suite for the tool check whether a program terminates with an exit code of 0, 
but do not check the program output.
In addition, patches are often overfit to the tests in the test suite; additional tests expose problems with those patches.
In fact, some patches are outright harmful, as they introduce new problems which the test suite does not check for.

In contrast, in the world of proof repair, there is always a specification to work with---the theorem being proven---so
a proof repair tool does not need to rely on tests.
Furthermore, the scope of properties that can be specified in proof assistants like Coq is especially large thanks to its experessive type system \kl{CIC$_{\omega}$},
with polymorphism and dependent types.
The richness of the type theory further makes it possible for \sysnamelong to check itself along the way and make sure it is on the right track.

Still, there is always a chance that the specification itself must change in order for proof repair to work,
as I showed with \toolnamec.
In those cases, it is helpful to have some assurance that the specifications the tool produces are meaningful---in the case of
\toolnamec, that the old and new specifications are equal up to transport along the change in the datatype.
It is also useful to have a human in the loop to check specifications in the end,
as \toolnamec does.
Section~\ref{sec:techniques} discusses other specification-based repair tools,
as well as other repair tools that bring a human into the loop.

\paragraph{Examples}
Another challenge for test-based program repair tools is defining the correct search space and searching efficiently within it.
For example, the review found that running the same tool on strengthened versions of the test suites produced no patches at all in the time alloted.
One possible reason for this is that the tools could not search for the correct patches efficiently enough.
Example-based techniques can help navigate a large search space quickly.

\sysnamelong uses examples---in the former of changes to datatypes or proofs---to derive patches.
The constructive foundations of Coq makes this especially appealing and powerful,
since it means that existence proofs, for example, must be accompanied by a witness.
Each of these witnesses is in effect an example that \sysnamelong can extract and generalize,
narrowing down the search space of possible repairs.

Thanks to the richness of the type theory, \sysnamelong can in practical use cases repair proofs by generalizing a very small number of examples,
like a single example patched proof, or a single example change to a datatype.
Section~\ref{sec:techniques} describes other example-based repair tools.

\subsection{Techniques for Inspiration}
\label{sec:techniques}

% TODO explain why here it's not straightforward to just use program repair tools for proof repair, like did in the talk.
% But then segue into saying the techniques are still useful.
%\sysname\ uses similar techniques to existing tools, though it is in a different language
%and so encounters different challenges. Some things are in fact easier for \sysname\ than for other tools;
%the richness of specifications tells \sysname\ exactly when a patch is successful, for example. 
%But the proof assistant \sysname\ operates over supports dependent types, and in the world of proof repair,
%the criteria for a patch being correct is very strict. 

Proof repair can learn a lot from program repair tools, even though the tools do not carry over in a straightforward way (Section~\ref{sec:how}).
This section discusses techniques from existing program repair tools that are relevant to proof repair.
It focuses in particular on what a recent survey~\cite{Monperrus:2018:ASR:3177787.3105906} of program repair calls behavioral repair,
or patching the code, rather than state repair, or patching the dynamic behavior.
Among behavioral repair tools, it focuses on regression repair, specification-based repair,
repair by example, and other techniques that bring a human into the loop.

\paragraph{Regression Repair}
Regression repair tools target regression bugs, or bugs introduced by changes in code.
Test-based regression repair tools repair code that causes a set of tests (the \textit{regressed tests}) that used to pass to no longer pass,
such that regressed tests pass on the repaired code.
In some sense, proof repair is a kind of regression repair, as it repairs
proofs that used to succeed, but after some change, no longer do (the \textit{regressed proofs}).
A section that \kl{Karl} wrote in our survey paper~\cite{PGL-045} describes the correspondence between regressed proofs and regressed tests in more detail,
and details existing techniques~\cite{Palmskog2018, Wenzel2013MultiProcessing, Barras2013, Celik:2017:IRP:3155562.3155588, Wenzel2013, Barras2015, deMoura2015, Wenzel2014, WenzelScalingIsabelle, WenzelFurtherScalingIsabelle} for rechecking regressed proofs.

One test-based regression program repair tool is ReAssert~\cite{daniel2009reassert} for Java,
which focuses on regressions caused by refactoring.
ReAssert uses a program analysis to identify broken code,
chooses a strategy for repair, and suggests repairs to the programmer using that strategy that cause regressed tests to pass.
It loops through strategies until one works or none remain.
Another such tool is Relifix~\cite{Tan:2015:RAR:2818754.2818813} for C.
Relifix uses a manual inspection to find code transformations based on regressions, then searches those transformations for 
patches that make the regressed tests pass without making other tests fail.
Both ReAssert and Relifix are configurable like \sysnamelong, and may provide interesting examples of configurations
or ways of inferring new configurations.

While not quite a regression repair tool, GRAFTER~\cite{Zhang:2017:ATD:3097368.3097448} is a related tool that adapts the tests themselves,
rather than the code under test. Its focus is on testing software clones for errors introduced during the
cloning process. It uses a static analysis to identify variables and methods that correspond between the clones,
then ensures that the flow is preserved using that mapping. The user can then run the new tests to compare behavior.
It provides a guarantee about type safety, and it performs reasonably well on some real-world software.
GRAFTER, like \toolnamec, takes an approach to repair that uses a form of differencing.
Looking to this to help inform new differencing algorithms for \sysnamelong could be fruitful,
in spite of foundational differences of the target domains.

\paragraph{Specification-Based Repair}
Some tools use specifications as an oracle, like \sysnamelong.
For example, AutoFix-E~\cite{Wei:2010:AFP:1831708.1831716, pei2014automated} uses contracts to repair Eiffel programs. 
Specification-Based Program Repair Using SAT~\cite{gopinath2011specification}
encodes pre and post conditions in combination with other constraints from the code 
into SAT and then uses Alloy to generate patches.
Other tools combine test-based program repair with logical specifications and automated solving~\cite{10.1007/978-3-540-24721-0_20, nguyen2013semfix, nguyen2013semfix, Xuan:2017:NAR:3071893.3071964, Mechtaev:2015:DLS:2818754.2818811, Ke:2015:RPS:2916135.2916260}.
For future proof reuse tools, making better use of existing proof automation in proof assistants to generate
patches that satisfy specifications may prove fruitful.

Proof-directed repair~\cite{dennis2006proof} presents a methodology
for repairing programs based on information from incomplete proofs in Isabelle.
Essentially, the programmer writes a proof, and then uses feedback
from the attempted proof to debug and fix the code.
In a sense, since if the repair succeeds the proof should go through,
it uses proofs as an oracle. The paper presents a few techniques for fixing the broken code,
then shows some examples using those techniques with existing tools.
It does not yet automate it in a tool.
Still, perhaps using partial proofs as in proof-directed repair can help a proof repair tool like \sysnamelong
better repair functions.
It also matches the workflow of proof engineers seen in the \textsc{REPLica} user study. % TODO say it's mine somehow 

\paragraph{Repair by Example}
Some program repair tools work by example, like \sysnamelong.
Prophet~\cite{Long:2016:APG:2837614.2837617}, a test-based repair tool for C,
uses human-generated patches from software repositories as examples.
These examples can come from different applications from the one that is being repaired.
Prophet uses differencing over ASTs % of the unpatched and patched code 
to extract features that describe the behavior of the example patch abstracted from its particular application.
From these patches, it learns a model of correct code. Then,
it localizes faults and generates candidates, which it ranks according to the learned model.
In this way, it produces patches that not only cause the tests to succeed, but also
are likely according to the learned model to be correct to humans.

The repair tool QACrashFix~\cite{gao2015fixing} uses pairs of buggy and fixed code from Q \& A sites like
StackOverflow to derive patches for crashing input bugs. These patches are in the form of edit scripts,
so that they can apply in different contexts. %The idea here is that many bugs recur, so they look for fixes that apply to fix other bugs. 
It uses a preprocessing step to find the right query for the Q \& A site, then they
look at answers for buggy and fixed code examples, then from those they derive edit scripts to try to fix the bug.
It then uses a combination of tests and human validation to determine whether the patches are correct.

SearchRepair~\cite{Ke:2015:RPS:2916135.2916260} turns code from repositories into a searchable database.
To form this database, it uses a static analysis to encode the input-output behavior of the code as constraints for an SMT solver.
It then localizes the fault in the buggy program,
encodes the buggy program similarly, performs a semantic code search over that database to identify candidate patches,
and finally uses the test suite as an oracle to determine whether candidates succeed.

Systematic editing~\cite{meng2011systematic} is a technique that could help repair by example tools.
This technique generalizes an edit to a program into a program transformation that can apply in similar program contexts.
It works by syntactic differencing over the AST of the example edit, abstracting the difference, and applying it elsewhere.
It can handle insertions, deletions, updates, and moves.
\textsc{Lase}~\cite{meng2013lase} implements and improves on this,
making use of multiple examples instead of just one, % maybe we should too? for implications for sysname section
and also automatically identifying locations to apply transformations.
Similarly, \lstinline{spdiff}~\cite{andersen2010generic} generalizes patches into semantic patches for Cocinelle~\cite{padioleau2008documenting},
which can then apply those patches automatically in different contexts. This way, the library designer can write a semantic patch
himself, or \lstinline{spdiff} can infer one.

A number of program repair tools above---much like the proof repair tools decribed in this thesis---build on differencing algorithms.
Existing work in differencing and incremental computation may help 
improve semantic differencing algorithms for both program and proof repair.
Type-directed diffing~\cite{Miraldo:2017:TDS:3122975.3122976}
finds differences in algebraic data types.
Semantics-based change impact analysis~\cite{Autexier:2010:SCI:1860559.1860580} models semantic differences
between documents.
Differential assertion checking~\cite{differential-assertion-checking-2} analyzes different
versions of a program for relative correctness with respect to a specification.
Incremental $\lambda$-calculus~\cite{Cai:2014:TCH:2594291.2594304} introduces a general model for program changes.
All of these may be useful for improving semantic differencing.

Several of the repair by example tools make use of code repositories and libraries to identify examples.
One challenge that I faced in my proof repair work was making use of examples changes in code repositories, since Github commits are typically large.
These tools may offer some insights for how to approach this problem.
Some of these tools also use machine learning---I discuss some ideas combining proof repair
with machine learning in Section~\ref{sec:synthesis}.

\paragraph{Human in the Loop}
Some tools avoid using test suites to judge correctness of candidate patches, and instead
bring the programmer into the loop. For example, both ReAssert~\cite{daniel2009reassert}
and QACrashFix~\cite{gao2015fixing} suggest repairs directly to the programmer---a workflow
that partially inspired the tactic suggestion interface in \toolnamec.
In general, an approach that suggests repairs to proof engineers in the end
and allows them to vet the specifications and tactics used seems to fit naturally into proof engineering workflows. 

A natural integration point for a repair tool like \sysnamelong is at the IDE level. 
CatchUp!~\cite{Henkel:2005:CCR:1062455.1062512} is an IDE plugin (implemented for Eclipse in Java) that automatically adapts library clients to API refactorings.
It records refactorings that the library developer makes inside of the IDE,
then replays the refactorings in in client code, reconstructing everything from the recorded trace.
Future proof repair tools may benefit from IDE integration of this kind.
For example, it may be useful to record changes within a project inside of an IDE 
so that \sysnamelong can find patches corresponding to incremental changes without the proof engineering needing to deconstruct them manually.
It may also help to have something like the trace file in CatchUp! so that library developers can easily provide patches for client proof developments.

\iffalse
\section{More Inspiration}
\label{sec:inspiration}

Other inspiration comes from type theory (Section~\ref{sec:typetheory}),
program synthesis (Section~\ref{sec:synthesis}),
and differencing (Section~\ref{sec:diff-incremental}).


\subsection{Type Theory}
\label{sec:typetheory}

(TODO move this! Because moving HoTT stuff to foundations.)

\paragraph{Indexed Types}
The automatic configuration for algebraic ornaments in \toolnamec focuses on the specific problem of reuse and repair when adding fully-determined indices to types.
Other approaches to this problem include combinators which definitionally reduce to desirable terms~\cite{DBLP:journals/corr/abs-1803-08150} in the language Cedille,
and automatic generation of conversion functions in Ghostbuster~\cite{McDonell:2016:GTS:2951913.2951914} for GADTs in Haskell.
My work focuses on a type theory different from both of these, in which the properties that allow for such combinators in Cedille are not present, and in which dependent types introduce challenges not present in Haskell.

\subsection{Program Synthesis}
\label{sec:synthesis}

\paragraph{Programming by Example}
My approach to proof repair works by example.
There is an entire field of program synthesis dedicated to programming by example~\cite{DBLP:journals/ftpl/GulwaniPS17}. 
This field addresses different challenges in different logics,
but may drive solutions to similar problems in a dependently typed language.
% TODO elaborate

\paragraph{Neurosymbolic Programming}

\paragraph{Congruence}

\fi


