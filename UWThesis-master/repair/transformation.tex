\section{Transformation}
\label{sec:pumpkin-trans}

The proof term transformations together transform a patch candidate into a reusable proof patch.
At a high level, these transformations adapt the candidate to the context of the goal type that \sysname infers.
As with differencing, the transformations are aware of and guided by the semantics of Gallina's type theory CIC$_{\omega}$.
This section describes the design (Section~\ref{sec:pumpkin-trans-design}) and limitations (Section~\ref{sec:pumpkin-trans-limitations}) of these transformations.
Section~\ref{sec:pumpkin-impl-trans} describes the implementation in \sysname.

% TODO could write more probably

\subsection{Design}
\label{sec:pumpkin-trans-design}

% TODO honestly this should go in spec then? both of these in each section? and just say we don't show too much here since prototype?
The transformations together recurse over the structure of each term in the list of candidates $\vec{t}$ in an environment $\Gamma$,
and adapt that candidate to some new context in a goal-direct manner.
In the end, if successful, they produce a reusable proof patch $p$ with type $G$, where $G$ is the inferred goal type.
That is, we can view the high-level composition of transformations as a single judgment
$\Gamma\ \vdash\ (\vec{t},\ G)\ \Downarrow_{t} p$, where in the end, $\Gamma \vdash p : G$. 
The details vary by transformation,
and the details of which transformations run at all and in what order to reach the goal vary by configuration.

For historical reasons, as \sysname was a prototype, these tranformations are not formalized. % TODO formalize if time
Instead, I describe at a high level the design of each of the four transformations in CIC${_\omega}$.
I still refer to the corresponding judgments as the interfaces, even though I do not provide the derivations.
In Chapter~\ref{chapt:pi}, I will formalize a more elegant proof term transformation for the \toolnamec extension,
building on some of the insights from the transformations in the \sysname prototype.

% From Motivating the Core and Implementation

\paragraph{Specialization}
Sometimes, patch candidates are too general.
Specialization takes a candidate that is too general,
and specializes it to specific arguments as determined by the difference in terms.
To find a patch for Figure~\ref{fig:example}, for example, \sysname
specialized the patch candidate to \lstinline{p} to produce the final patch.

Specialization takes a single patch candidate, some arguments, and a reduction strategy, and returns a new candidate.
It first applies the function to the argument, then applies the reduction strategy on the result.
The default reducer, for example, uses $\beta\iota$-reduction in Coq~\cite{equality}.
Section~\ref{sec:pumpkin-impl-trans} decribes other reducers.
The only requirement for a reducer is that the end result should be definitionally equal to the original.

Depending on the configuration and the step in the process, the transformed candidate may be the reusable patch,
or it may just be an intermediate candidate.
It is the job of the patch finding procedure to provide both the candidate and the arguments,
and to determine which transformation to run next, if applicable.

\iffalse
It works by combining application with reduction, with just one derivation:

\begin{mathpar}
\small
\hfill\fbox{$\Gamma$ $\vdash$ $(t,\ \vec{a},\ \Downarrow{r}) \Downarrow_{s} t'$ }\\

\inferrule[Specialize]
  { \Gamma \vdash t\ \vec{a} \Downarrow_{r} t'}
  { \Gamma \vdash (t,\ \vec{a},\ \Downarrow_{r}) \Downarrow_{s} t'}
\end{mathpar}
There is just one super weird thing I do not even know if I am allowed to do here:
the reduction strategy $\Downarrow_{r}$ is itself a transformation that reduces a term in an arbitrary way.
\fi

\paragraph{Generalization} In other cases, a patch candidate is too specific.
Generalization takes a candidate that is too specific and generalizes it.
We saw this for the example in Figure~\ref{fig:example} as well:
to go from the candidate that \sysname found in the base case to the eventual reusable patch,
\sysname generalized the candidate by the argument \lstinline{m} (before applying specialization).

There are two kinds of generalization.
The first generalizes candidates that map between types that share a common argument, like: % TODO need to explain the arrow syntax and assume we can do it for CIC somewhere

\begin{lstlisting}[language=coq]
  $Q\ t\ \rightarrow P\ t$
\end{lstlisting}
by the common argument:

\begin{lstlisting}[language=coq]
  $\Pi (\diff{t'} : T),\ Q\ \diff{t'} \rightarrow P\ \diff{t'}$
\end{lstlisting}
where $T$ is the type of $t$.
The second generalizes candidates that map between types that share a common function, like:

\begin{lstlisting}[language=coq]
  $P\ t'\ \rightarrow P\ t$
\end{lstlisting}
by the common function:

\begin{lstlisting}[language=coq]
  $\Pi (\diff{Q} : T),\ \diff{Q} t' \rightarrow \diff{Q} t$
\end{lstlisting}
where $T$ is the type of $Q$.

Generalization takes a patch candidate, the goal type, and the function arguments or function by which to generalize.
It first wraps the candidate inside of a lambda from the type of the term by which to generalize.
Then, it substitutes terms inside the body with the generalized term.
It continues to do this until there is nothing left to generalize, then filters results by the goal type.
Consider, for example, generalizing this candidate by \lstinline{m}: % TODO note it's from the thing

\begin{lstlisting}[language=coq]
  $\lambda (H : n <= m) . \mathrm{le\_plus\_trans}\ n\ m\ (S\ O)\ H$
  $: n <= m \rightarrow n <= \mathrm{plus}\ m\ 1$
\end{lstlisting}
where \lstinline{<=} is an inductive type, and \lstinline{le_plus_trans} and \lstinline{plus} are both functions in the current context.
The first step wraps this in a lambda from some \lstinline{nat}, the type of \lstinline{m}:

\begin{lstlisting}[language=coq]
  $\lambda (\diff{n0} : \mathrm{nat}) . \lambda (H : n <= m) . \mathrm{le\_plus\_trans}\ n\ m\ (S\ O)\ H)$
  $: \Pi (\diff{n0} : \mathrm{nat}), n <= m \rightarrow n <= \mathrm{plus}\ m\ 1$
\end{lstlisting}
The second step substitutes \lstinline{n0} for \lstinline{m}:

\begin{lstlisting}[language=coq]
  $\lambda (\diff{n0} : \mathrm{nat}) . \lambda (H : n <= \diff{n0}) . \mathrm{le\_plus\_trans}\ n\ \diff{n0}\ (S\ O)\ H)$
  $: \Pi (\diff{n0} : \mathrm{nat}), n <= \diff{n0} \rightarrow n <= \mathrm{plus}\ \diff{n0}\ 1$
\end{lstlisting}

In general, generalization is a kind of anti-unification problem, % TODO cite and so on
as the terms and types may be reduced,
so that the common function or argument does not appear explicitly.
This is of course undecidable.
This poses a challenge for generalization in the second step---substitution.

To handle this challenge, generalization uses a list of \textit{substitution strategies}\footnote{I originally called these \textit{abstraction strategies}, but this is more accurate.}
to determine what subterms to substitute.
In this case, the simplest strategy works: the tool
replaces all terms that are convertible to the concrete argument \lstinline{m} with the generalized argument
\lstinline{n0}, which produces a single candidate. Type checking this candidate confirms that it is a patch.
In some cases, the simplest strategy is not sufficient, even when it is possible to genearlize the term.
Section~\ref{sec:pumpkin-impl-trans} describes a sample of other strategies.

It is the job of the patch finding procedure to provide the candidate and the terms by which to generalize.
In addition, each configuration includes a list of strategies.
The configuration for changes in conclusions, for example, starts with the simplest strategy,
and moves on to more complex strategies only if that strategy fails.
This design makes generalization simple to extend with new strategies and simple to call with different strategies
for different configurations, or even as an optimization for the proof engineer.

\paragraph{Inversion} Sometimes, when two types are propositionally equal, % TODO explain this earlier in Coq explanation and so on, too, and refer back; use pi explanation
candidate patches may appear in the wrong direction.
For example, consider two list lemmas (this example is in Coq rather than CIC$_{\omega}$ for simplicity): % TODO just use CIC here and below 

\begin{lstlisting}[language=coq]
  old : (@\ltacforall@) l' l, length (l' ++ l) = length l' + length l(@\vspace{-0.08cm}@)
  new : (@\ltacforall@) l' l, length (l' ++ l) = length l' + length (rev l)
\end{lstlisting} 
If \sysname searches the difference in proofs of these lemmas for a patch from the 
conclusion of \lstinline{new} to the conclusion of \lstinline{old},
it may find a candidate \emph{backwards}:

\begin{lstlisting}
  candidate l' l (H : (@\diff{old}@) l' l) :=(@\vspace{-0.04cm}@)
    eq_rect_r ... (@\diff{(rev\_length l)}@)(@\vspace{-0.04cm}@)
  : (@\ltacforall@) l' l, (@\diff{old}@) l' l $\rightarrow$ (@\diff{new}@) l' l
\end{lstlisting}
The component can invert this to get the patch: %from \lstinline{new} to \lstinline{old}:

\begin{lstlisting}
  patch l' l (H : (@\diff{new}@) l' l) :=(@\vspace{-0.04cm}@)
    eq_rect_r ... (@\diff{(eq\_sym (rev\_length l))}@)(@\vspace{-0.04cm}@)
  : (@\ltacforall@) l' l, (@\diff{new}@) l' l $\rightarrow$ (@\diff{old}@) l' l
\end{lstlisting}
We can then use this patch to port proofs.
For example, if we add this patch to a hint database~\cite{hints},
we can port this proof:

\begin{lstlisting}
  Theorem app_rev_len : (@\ltacforall@) l l',(@\vspace{-0.04cm}@)
    length (rev (l' ++ l)) = length (rev l) + length (rev l').(@\vspace{-0.04cm}@)
  Proof.(@\vspace{-0.04cm}@)
    intros. rewrite rev_app_distr. (@\succeeds{apply old.}@)(@\vspace{-0.04cm}@)
  Defined.
\end{lstlisting}
to this proof:

\begin{lstlisting}
  Theorem app_rev_len : (@\ltacforall@) l l',(@\vspace{-0.04cm}@)
    length (rev (l' ++ l)) = length (rev l) + length (rev l').(@\vspace{-0.04cm}@)
  Proof.(@\vspace{-0.04cm}@)
    intros. rewrite rev_app_distr. (@\succeeds{apply new.}@)(@\vspace{-0.04cm}@)
  Defined.
\end{lstlisting}

Rewrites like \lstinline{candidate} are \textit{invertible}:
We can invert any rewrite in one direction by rewriting in the opposite direction.
In contrast, it is not possible to invert the patch \sysname
found for Figure~\ref{fig:example}.

When a candidate is invertible, patch inversion exploits symmetry to try to reverse the conclusions of a candidate patch.
It first factors the candidate using the factoring component, then calls the primitive inversion
function on each factor, then finally folds the resulting list in reverse.
The primitive inversion function exploits symmetry. 
For example, equality is symmetric, so the component can invert any application of the equality eliminators.
I will explain this more in Section~\ref{sec:pumpkin-impl-diff}.

\paragraph{Factoring} The other transformations sometimes need help breaking a large function into smaller subterms.
This can break other problems, like generalization, into smaller subproblems.
It is also necessary to invert certain terms, since the inverse of:

\begin{lstlisting}
  $g \circ f$
  : $X \rightarrow Z$
\end{lstlisting}
where:

\begin{lstlisting}
  $g : Y \rightarrow Z$
  $f : X \rightarrow Y$
\end{lstlisting}
for arbitrary non-dependent types $X$, $Y$, and $Z$,
is of course:

\begin{lstlisting}
  $f\inv \circ g\inv$
  : $Z \rightarrow X$ 
\end{lstlisting}
This shows up often for inverting sequences of rewrites, as I will show in Section~\ref{sec:pumpkin-impl-diff}.
To invert a term like this, \sysname identifies the factors \lstinline{[f; g]}, 
inverts each factor to \lstinline{[f}$\inv$\lstinline{; g}$\inv$\lstinline{]}, 
then folds and applies the inverse factors in the opposite direction.

The factoring transformation looks within a term for its factors.
For the term above, it returns both factors: \lstinline{f} and \lstinline{g}.
In this case, factoring takes the composite term and \lstinline{X} as arguments.
It first searches as deep as possible for a term of type \lstinline{X} $\rightarrow$ \lstinline{Y} for some \lstinline{Y}.
If it finds such a term, then it recursively searches for a term with type \lstinline{Y} $\rightarrow$ \lstinline{Z}. 
It maintains all possible 
paths of factors along the way, and it discards any paths that cannot reach \lstinline{Z}.
It does not yet support paths where \lstinline{Y} depends on \lstinline{X}.

\subsection{Limitations}
\label{sec:pumpkin-trans-limitations}

This section describes a few fundamental limitations of the transformations in \sysname,
and whether they are addressed in the later \toolnamec extension.
Limitations that are due to the choice of implementation strategy are in Section~\ref{sec:pumpkin-impl-trans}.

\paragraph{Undecidability}
Several of the transformations are undecidable.
For example, generalization will necessarily sometimes fail, since fundamentally it relies on a kind of unification.
The general problem of finding all possible nontrivial factors of a function is likewise undecidable:
there are always infinitely many factors if factors can compose to identity.
Determining all possible \textit{nontrivial} factors---those that contain no subsets of factors
that compose to identity---reduces to detecting whether an arbitrary function is extensionally equal
to the identity function at a fixed but arbitrary type,
which is itself undecidable.\footnote{Edward Z. Yang wrote a very cute proof of this \href{https://twitter.com/ezyang/status/1391546552989241346}{on Twitter}: Let the function be an arbitrary Turing complete program parameterized by fuel, returning
the number of steps taken when it does not terminate within that number of steps, or otherwise returning zero when it does terminate.
Then determining whether or not the function is extensionally equal to identity reduces to determining whether or not
the program terminates.}
Inversion will also sometimes fail, in part because it depends on factoring,
and in part because not every term is invertible to begin with.
The later \toolnamec transformation does not fully circumvent undecidability,
but it does more cleanly separate the transformation itself from the undecidable pieces.

\paragraph{Modeling Diverse Proof Styles}
Some of the transformations make assumptions about the proof style.
For example, proofs about decidable domains that work by provable double negation elimination
(\lstinline{dec_not_not}) pose difficulties for generalization and inversion.
The later \toolnamec transformation, in contrast, is generic over the
proof style.

