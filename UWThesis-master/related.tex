\chapter{Related Work}

% TODO whatever else isn't here yet, and some of this might be factored out or partially factored out---all papers, including survey, plus generals

\section{Programs}

\subsection*{Program Refactoring} 

Refactoring~\cite{Mens:2004:SSR:972215.972286}.

\subsection*{Program Repair} 

% From PUMPKIN PATCH, unchanged

Adapting proofs to changes is essentially program repair
for dependently typed languages. 
Program repair tools for 
languages with non-dependent type 
systems~\cite{Pei:2014:APR:2731750.2731779, Long:2016:APG:2837614.2837617, Le:2017:SSS:3106237.3106309, Mechtaev:2016:ASM:2884781.2884807, Monperrus2015} 
may have applications in the context of a dependently typed language.
Similarly, our work may have applications within program repair in these languages:
Future applications of our approach may repurpose it to repair programs for functional languages.

\subsection*{Ornaments}

% From DEVOID, unchanged

\toolnameb automates discovery of and lifting across algebraic ornaments in a higher-order dependently typed language.
In the decade since the discovery of ornaments~\cite{mcbride}, there have been a number
of formalizations and embedded implementations of ornaments~\cite{Dagand:2013:CTO:2591370.2591396, ko2013relational, dagand2014transporting, ko2016programming, dagand2017essence}.
\toolnameb is the first tool for ornamentation to operate over a non-embedded dependently typed language.
It essentially moves the automation-heavy approach of Ornamentation in ML~\cite{Williams2017},
which operates on non-embedded ML code, into the type theory that forms the basis of theorem provers like Coq. 
In doing so, it takes advantage of the properties of algebraic ornaments~\cite{mcbride}.
It also introduces the first search algorithm to identify ornaments, which in the past 
was identified as a ``gap'' in the literature~\cite{ko2016programming}.

\subsection*{Programming by Example}

% From PUMPKIN PATCH, unchanged

Our approach generalizes an example that the programmer provides.
This is similar to programming by example, a subfield of 
program synthesis~\cite{DBLP:journals/ftpl/GulwaniPS17}. 
This field addresses different challenges in different logics,
but may drive solutions to similar problems in a dependently typed language.

\subsection*{Differencing \& Incremental Computation}

% From PUMPKIN PATCH, unchanged

Existing work in differencing and incremental computation may help 
improve our semantic differencing component.
Type-directed diffing~\cite{Miraldo:2017:TDS:3122975.3122976}
finds differences in algebraic data types.
Semantics-based change impact analysis~\cite{Autexier:2010:SCI:1860559.1860580} models semantic differences
between documents.
Differential assertion checking~\cite{differential-assertion-checking-2} analyzes different
versions of a program for relative correctness with respect to a specification.
Incremental $\lambda$-calculus~\cite{Cai:2014:TCH:2594291.2594304} introduces a general model for program changes.
All of these may be useful for improving semantic differencing.

\section{Proofs}

\subsection*{Proof Reuse}

% From PUMPKIN PATCH, unchanged

Our approach reimagines the problem of proof reuse in the context of proof automation.
While we focus on changes that occur over time, traditional proof reuse techniques can help
improve our approach.
Existing work in proof reuse focuses on transferring proofs between isomorphisms,
either through extending the type system~\cite{Barthe:2001:TIP:646793.704711} or through an automatic method~\cite{Magaud2002}.
This is later generalized and implemented in Isabelle~\cite{Huffman2013} and Coq~\cite{ZimmermannH15, tabareau:hal-01559073};
later methods can also handle implications. 
%Transfer tactics apply these functions but do not infer them, while our approach
%infers these functions but does not apply them.
Integrating a transfer tactic with a proof patch finding tool will create an end-to-end
tool that can both find patches and apply them automatically.

Proof reuse for extended inductive types~\cite{Boite2004} adapts proof obligations
to structural changes in inductive types. Later work~\cite{Mulhern06proofweaving} proposes a method
to generate proofs for new constructors. These approaches may be useful when extending the differencing
component to handle structural changes. Existing work in theorem reuse and proof generalization~\cite{Felty1994, pons00, Johnsen2004} abstracts existing proofs for reusability, and may be useful
for improving the abstraction component.
Our work focuses on the components critical to searching for patches; these complementary approaches
can drive improvements to the components.

% From DEVOID, unchanged

\toolnameb identifies and lifts proofs along a specific equivalence 
similar to that from existing ornaments work~\cite{ko2016programming}.
The need to automatically lift functions and proofs
across equivalences and other relations is a long-standing challenge for proof 
engineers~\cite{magaud2000changing, barthe2001type, magaud2003changing, huffman2013lifting, zimmermann2015automatic, cohen:hal-01414881}.
The univalence axiom from Homotopy Type Theory~\cite{univalent2013homotopy} enables transparent transport of proofs;
cubical type theory~\cite{cohen2016cubical} gives univalence a constructive interpretation. 

% TODO EFF was here, but better EFF rel work comes from PUMPKIN Pi

Similarly, our work is related to CoqEAL~\cite{cohen:hal-01414881}, which transfers functions along arbitrary relations
between types. As these relations do not necessarily need to be equivalences, this framework is more general
than our work. Similar tradeoffs between automation and generality apply: CoqEAL produces functions that refer to the old type,
and does not yet support automatic inference of relations. In addition, CoqEAL currently only supports automatic transfer of functions,
and does not yet handle proofs.

These tools may provide an alternative backend for \toolnameb. Furthermore,
our search algorithm may help discover relations that make these tools easier to use,
and our lifting algorithm may help improve automation and efficiency for 
certain relations in these tools.

The problem that we solve is fundamentally about proof reuse,
which applies software reuse principles to ITPs. 
There is a wealth of work in proof reuse, from tactic languages~\cite{felty1994generalization} and logical frameworks~\cite{caplan1995logical},
to tools for proof abstraction and generalization~\cite{pons2000generalization, johnsen2004theorem},
to domain-specific methodologies~\cite{Delaware:2011:PLT:2048066.2048113} and frameworks~\cite{Delaware:2013:MLC:2429069.2429094}.

\toolnameb focuses on the specific problem of reuse
when adding fully-determined indices to types.
Other approaches to this problem include combinators which definitionally reduce to desirable terms~\cite{DBLP:journals/corr/abs-1803-08150} in the language Cedille,
and automatic generation of conversion functions in Ghostbuster~\cite{McDonell:2016:GTS:2951913.2951914} for GADTs in Haskell.
Our work focuses on a type theory different from both of these, in which the properties that allow for such combinators in Cedille are not present, and in which dependent types introduce challenges not present in Haskell.

\toolnameb is not the first tool to combine search with reuse. 
Optician~\cite{miltner2017synthesizing} synthesizes bidirectional string transformations;
a similar approach may help extend tooling to handle transformations for low-level data.
\textsc{Pumpkin Patch}~\cite{ringer2018adapting} 
searches the difference in proofs for patches that can be used to repair proofs broken by changes;
\toolnameb uses a similar approach to identify functions
that form an equivalence. The resulting tools are complementary: \toolnameb supports the addition
of indices and hypotheses, which \textsc{Pumpkin Patch} does not support; \textsc{Pumpkin Patch} supports changes
in values, which \toolnameb does not support. 

\subsection*{Proof Evolution}

% From PUMPKIN PATCH, unchanged

There is a small body of work on change and dependency management for verification,
both to evaluate impact of potential changes and maximize reuse~\cite{873647, Autexier:2010:CMH:1986659.1986663}
and to optimize build performance~\cite{Celik:2017:IRP:3155562.3155588}.
These approaches may help isolate changes, which is necessary to identify future benchmarks, integrate
with CI systems, and fully support version updates.

\subsection*{Proof Refactoring}

\subsection*{Proof Repair}

\subsection*{Proof Design}

% From PUMPKIN PATCH, unchanged:

Existing proof engineering work addresses brittleness
by planning for changes~\cite{proof-eng} and designing theorems and proofs that make maintenance less of an issue.
Design principles for specific domains (such as formal metatheory~\cite{Aydemir2008, Delaware2013POPL, Delaware2013ICFP})
can make verification more tractable. CertiKOS~\cite{certikos} introduces the idea of a deep specification to
ease verification of large systems.
These design principles and frameworks are complementary to our approach.
Even when programmers use informed design principles,
changes outside of the programmer's control can break proofs;
our approach addresses these changes.

\subsection*{Proof Automation}

% From PUMPKIN PATCH, unchanged:

We address a missed opportunity in proof automation for ITP: searching
for patches that can fix broken proofs.
This is complementary to existing automation techniques. Nonetheless, there is a wealth
of work in proof automation that makes proofs more resilient to change.
Powerful tactics like \lstinline{crush}~\cite{chlipala:cpdt} can make
proofs more resilient to changes. 
Hammers like Isabelle's sledgehammer~\cite{Blanchette2013} can make proofs agnostic to some low-level changes.
Recent work~\cite{coqhammer} paves the way for a hammer in Coq.
Even the most powerful tactics cannot address all changes;
our hope is to open more possibilities for automation.

Powerful project-specific tactics~\cite{chlipala:cpdt, Chlipala2013} can help prevent low-level maintenance tasks.
Writing these tactics requires good engineering~\cite{Gonthier2011} and domain-specific knowledge,
and these tactics still sometimes break in the face of change.
A future patching tool may be able to repair tactics; the debugging process
for adapting a tactic is not too dissimilar to providing an example to a tool.

Rippling~\cite{rippling} is a technique for automating inductive proofs that uses restricted rewrite rules to
guide the inductive hypothesis toward the conclusion; this may guide improvements to the
differencing, abstraction, and specialization components.
The abstraction and factoring components address specific classes of unification problems;
recent developments to higher-order unification~\cite{Miller:2012:PHL:2331097} may help
improve these components.
Lean~\cite{selsam:lean} introduces the first congruence closure algorithm for dependent type theory that
relies only on the Uniqueness of Identity Proofs (UIP) axiom. While UIP is not fundamental to Coq,
it is frequently assumed as an axiom; when it is, it may be tractable to use a similar algorithm to improve the tool.

GALILEO~\cite{bundyreasoning} repairs faulty physics theories
in the context of a classical higher-order logic (HOL); there is preliminary work extending this
style of repair to mathematical proofs. 
Knowledge-sharing methods~\cite{tgck-cicm14} can adapt some proofs across different representations of HOL.
These complementary approaches may guide extensions to support decidable domains and classical logics.


