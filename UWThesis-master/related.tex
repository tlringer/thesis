\chapter{Related Work}
\label{sec:related}

% TODO whatever else isn't here yet, and some of this might be factored out or partially factored out---all papers, including survey, plus generals.
% then organize and clean.

Proof repair can be viewed as program repair (Section~\ref{sec:repair})
for the domain of proof engineering (Section~\ref{sec:proofeng}).
Work in type theory, program synthesis, differencing, program transformations, automated theorem proving, and user studies
has inspired and continues to inspire improvements to proof repair tools and techniques (Section~\ref{sec:inspiration}).

\section{Proof Engineering}
\label{sec:proofeng}

\textit{Proof engineering} refers to the technologies that make it easier to develop and maintain
systems verified using proof assistants.
Proof repair falls into the domain of proof engineering.
This section briefly describes work in proof engineering relevant to my work on proof repair:
proof assistants other than Coq (Section~\ref{sec:ass}),
other technologies for proof evolution (Section~\ref{sec:refrep}),
proof reuse (Section~\ref{sec:reuse}),
proof design (Section~\ref{sec:design}),
and other kinds of proof automation (Section~\ref{sec:automation}.
See my survey paper on proof engineering for a detailed overview of the field~\cite{PGL-045}. % TODO credit coauthors

\subsection{Proof Assistants}
\label{sec:ass}

Introduction, definition, de bruijn.

Summary of proof assistants.

I will discuss how these differ and the implications for proof repair.

\paragraph{Foundations} Most notably, proof terms.
But also differences in logics (constructivism, then refer back to it later).

\paragraph{Aesthetics} Like different tactic languages.

\subsection{Proof Evolution}
\label{sec:refrep}

\paragraph{Proof Refactoring}

\paragraph{Proof Repair}

\paragraph{Dependency Management}

\subsection{Proof Reuse}
\label{sec:reuse}

\paragraph{Proof Transformation}

\subsection{Proof Design}
\label{sec:design}

\subsection{Proof Automation}
\label{sec:automation}

\section{Program Repair}
\label{sec:repair}

% From sysname Pi, unchanged

Proof repair can be viewed as a form of \textit{program repair}~\cite{Monperrus:2018:ASR:3177787.3105906, Gazzola:2018:ASR:3180155.3182526}
for proof assistants. % TODO use knowledge package
Proof assistants like Coq are an especially good fit for program repair (Section~\ref{sec:lessons}).
While it is not straightforward to apply existing program repair techniques to proof assistants,
looking to them for inspiration may help improve proof repair tools more in the future (Section~\ref{sec:techniques}).

\subsection{A Good Fit}
\label{sec:lessons}

A recent survey of program repair distinguishes between repair tools based on the \textit{oracle} they use to
judge whether a patch is correct.
For example, proof repair is a kind of \textit{specification-based} repair,
since it uses a specification (a goal type derived from differencing) as an oracle.
Program repair tools sometimes use other oracles---commonly, test suites (\textit{test-based} repair).

A recent review~\cite{Qi:2015:APP:2771783.2771791} of a popular test-based program repair tool~\cite{LeGoues:2012:SSA:2337223.2337225} and its variants
shows that most of the reported patches generated by the tool are not correct.
These observations are later reaffirmed in a different setting~\cite{DBLP:journals/corr/abs-1811-02429}.
In response, the paper recommends that program repair tools draw on extra information, like specifications or example patches.
In Coq, specifications and examples are rich and widely available: specifications thanks to dependent types,
and examples thanks to constructivism. This shows why proof repair in Coq is an especially good fit for program repair.
 
\paragraph{Specifications}
One limitation of test-based program repair tools is that tests in evaluation suites are often underspecified,
so it can be hard to know when a patch to a program is correct.
For example, the review notes that some tests in the evaluation suite for the tool check whether a program terminates with an exit code of 0, 
but do not check the program output.
In addition, patches are often overfit to the tests in the test suite; additional tests expose problems with those patches.
In fact, some patches are outright harmful, as they introduce new problems which the test suite does not check for.

In contrast, in the world of proof repair, there is always a specification to work with---the theorem being proven---so
a proof repair tool does not need to rely on tests.
Furthermore, the scope of properties that can be specified in proof assistants like Coq is especially large thanks to its experessive type system \kl{CIC$_{\omega}$},
with polymorphism and dependent types.
The richness of the type theory further makes it possible for \sysnamelong to check itself along the way and make sure it is on the right track.

Still, there is always a chance that the specification itself must change in order for proof repair to work,
as I showed with \toolnamec.
In those cases, it is helpful to have some assurance that the specifications the tool produces are meaningful---in the case of
\toolnamec, that the old and new specifications are equal up to transport along the change in the datatype.
It is also useful to have a human in the loop to check specifications in the end,
as \toolnamec does.
Section~\ref{sec:techniques} discusses other specification-based repair tools,
as well as other repair tools that bring a human into the loop.

\paragraph{Examples}
Another challenge for test-based program repair tools is defining the correct search space and searching efficiently within it.
For example, the review found that running the same tool on strengthened versions of the test suites produced no patches at all in the time alloted.
One possible reason for this is that the tools could not search for the correct patches efficiently enough.
Example-based techniques can help navigate a large search space quickly.

\sysnamelong uses examples---in the former of changes to datatypes or proofs---to derive patches.
The constructive nature of the logic \kl{CIC$_{\omega}$} beneath Coq makes this especially appealing and powerful,
since it means (by definition) that proofs must be constructed from basic principles.
So existence proofs, for example, must be accompanied by a witness.\footnote{This is known as the \textit{existence property}.}
Each of these witnesses is in effect an example that \sysnamelong can extract and generalize,
narrowing down the search space of possible repairs.

Thanks to the richness of the type theory, \sysnamelong can in practical use cases repair proofs by generalizing a very small number of examples,
like a single example patched proof, or a single example change to a datatype.
Section~\ref{sec:techniques} describes other example-based repair tools.

\subsection{Techniques for Inspiration}
\label{sec:techniques}

% TODO explain why here it's not straightforward to just use program repair tools for proof repair, like did in the talk.
% But then segue into saying the techniques are still useful.

This section discusses techniques from existing program repair tools that are relevant to proof repair.
It focuses in particular on what a recent survey~\cite{Monperrus:2018:ASR:3177787.3105906} of program repair calls behavioral repair,
or patching the code, rather than state repair, or patching the dynamic behavior.
Among behavioral repair tools, it focuses on regression repair, specification-based repair,
repair by example, and other techniques that bring a human into the loop.

\paragraph{Regression Repair}
Regression repair tools target regression bugs, or bugs introduced by changes in code.
In some sense, proof repair is a kind of regression repair, as it repairs
proofs that used to succeed, but after some change, no longer do.

\paragraph{Specification-Based Repair}

\paragraph{Repair by Example}

\paragraph{Human in the Loop}
Some tools avoid using test suites to judge correctness of candidate patches, and instead
bring the programmer into the loop. For example, both ReAssert~\cite{daniel2009reassert}
and QACrashFix~\cite{gao2015fixing} suggest repairs directly to the programmer. % TODO is this true? accurate?
% TODO more here if they exist
Opad~\cite{Yang:2017:BTC:3106237.3106274} provides an alternative to expecting the test-based repair tool
to make use of extra information. Instead, Opad automatically detects overfitted patches and improves existing test suites.
The evaluation shows that using Opad to improve test suites improves the performance of several test-based program repair tools. % TODO accuracy check

\iffalse
Test-based regression repair tools repair code that causes a set of tests (the \textit{regressed tests}) that used to pass to no longer pass,
such that regressed tests pass on the repaired code.
One such tool is ReAssert~\cite{daniel2009reassert} for Java,
which focuses on regressions caused by refactoring.
ReAssert uses a program analysis to identify broken code,
chooses a strategy for repair, and suggests repairs to the programmer using that strategy that cause regressed tests to pass.
It loops through strategies until one works or none remain.
Another such tool is Relifix~\cite{Tan:2015:RAR:2818754.2818813} for C.
Relifix uses a manual inspection to find code transformations based on regressions, then searches those transformations for 
patches that make the regressed tests pass without making other tests fail.

% fix up transition or whatever
While not a regression repair tool, GRAFTER~\cite{Zhang:2017:ATD:3097368.3097448} is a related tool that adapts the tests themselves,
rather than the code under test. Its focus is on testing software clones for errors introduced during the
cloning process. It uses a static analysis to identify variables and methods that correspond between the clones,
then ensures that the flow is preserved using that mapping. The user can then run the new tests to compare behavior.
It provides a guarantee about type safety, and it performs reasonably well on some real-world software.
% accuracy check and clean up and so on

\paragraph{Repair by Example} % TODO can we really call them this? Maybe don't categorize like this, just mention technique
Some program repair tools generalize example changes into patches that repair the broken program.
\sysname\ is one such tool, since it generalizes example changes in proofs that address some breaking change
into a patch that can fix other broken proofs. 

Prophet~\cite{Long:2016:APG:2837614.2837617}, a test-based
repair tool for C,
uses human-generated patches from software repositories as examples.
These examples can come from different applications from the one that is being repaired.
Prophet uses differencing over ASTs % of the unpatched and patched code 
to extract \textit{features} that describe the behavior of the example patch abstracted from its particular application. % TODO is this correct, roughly?
From these patches, it learns a model of correct code. Then,
it localizes faults and generates candidates, which it ranks according to the learned model.
In this way, it produces patches that not only cause the tests to succeed, but also
are likely according to the learned model to be correct to humans. % TODO how are the results?

% TODO also note that they change the Oracle to the human instead of tests because of controversy
The repair tool QACrashFix~\cite{gao2015fixing} uses pairs of buggy and fixed code from Q \& A sites like
StackOverflow to derive patches for crashing input bugs. These patches are in the form of edit scripts,
so that they can apply in different contexts. %The idea here is that many bugs recur, so they look for fixes that apply to fix other bugs. 
It uses a preprocessing step to find the right query for the Q \& A site, then they
look at answers for buggy and fixed code examples, then from those they derive edit scripts to try to fix the bug.
It then uses a combination of tests and human validation to determine whether the patches are correct. % TODO is this accurate?
% TODO results?
% TODO fix ups

SearchRepair~\cite{Ke:2015:RPS:2916135.2916260} turns code from repositories into a searchable database.
To form this database, it uses a static analysis to encode the input-output behavior of the code as constraints for an SMT solver.
It then localizes the fault in the buggy program,
encodes the buggy program similarly, performs a semantic code search over that database to identify candidate patches,
and finally uses the test suite as an oracle to determine whether candidates succeed. % TODO anything else worth mentioning?
% TODO results?

Systematic editing~\cite{meng2011systematic} is a technique that could help repair by example tools.
This technique generalizes an edit to a program into a program transformation that can apply in similar program contexts.
It works by syntactic differencing over the AST of the example edit, abstracting the difference, and applying it elsewhere.
It can handle insertions, deletions, updates, and moves.
\textsc{Lase}~\cite{meng2013lase} implements and improves on this,
making use of multiple examples instead of just one, % maybe we should too? for implications for sysname section
and also automatically identifying locations to apply transformations.
Similarly, \lstinline{spdiff}~\cite{andersen2010generic} generalizes patches into semantic patches for Cocinelle~\cite{padioleau2008documenting},
which can then apply those patches automatically in different contexts. This way, the library designer can write a semantic patch
himself, or \lstinline{spdiff} can infer one.
% TODO language? results? guarantees? limitations? for each of these

A natural integration point for a tool like this is at the IDE level. % does this belong here? or whatever?
CatchUp!~\cite{Henkel:2005:CCR:1062455.1062512} is an IDE plugin (implemented for Eclipse in Java) that automatically adapts library clients to API refactorings.
It records refactorings that the library developer makes inside of the IDE,
then replays the refactorings in in client code, reconstructing everything from the recorded trace. % TODO accuracy check
% TODO results? guarantees? limitations?

\paragraph{Specification-Based Repair} Some tools use specifications as an oracle, like \sysname.
Sometimes these tools combine this with other oracles like tests. % TODO fix up a lot
For example, Automated Debugging Using Path-Based Weakest Preconditions~\cite{10.1007/978-3-540-24721-0_20} % TODO does this have a reasonable name of a tool?
uses pre and post conditions written in FOL to locate buggy statements and generate repairs, 
then runs tests to verify the repairs. 

AutoFix-E~\cite{Wei:2010:AFP:1831708.1831716, pei2014automated} uses contracts
to repair Eiffel programs. % TODO also something about repair templates; read in more detail maybe
Specification-Based Program Repair Using SAT~\cite{gopinath2011specification} % TODO ugh name your tools guys
encodes pre and post conditions in combination with other constraints from the code % TODO accuracy check
into SAT and then uses Alloy to generate patches. % TODO accuracy check again

Proof-directed repair~\cite{dennis2006proof} presents a methodology
for repairing programs based on information from incomplete proofs in Isabelle.
Essentially, the programmer writes a proof, and then uses feedback
from the attempted proof to debug and fix the code.
In a sense, since if the repair succeeds the proof should go through,
it uses proofs as an oracle. The paper presents a few techniques for fixing the broken code,
then shows some examples using those techniques with existing tools.
It does not yet automate it in a tool.

Many test-based program repair tools meet these criteria, some developed before these results came to light,
and some in response to these results. 
SemFix~\cite{nguyen2013semfix}, for example,
generalizes test suites to specifications, which the authors claim improves the performance of search.
Similarly, NOPOL~\cite{Xuan:2017:NAR:3071893.3071964} repairs a certain class of bugs by generating and solving SMT formulas from a test suite.
Other tools that augment test-based techniques with constraint problems include
directFix~\cite{Mechtaev:2015:DLS:2818754.2818811} and SearchRepair~\cite{Ke:2015:RPS:2916135.2916260}. % TODO are there more? If so, add

\subsection{Implications for Proof Repair}

\sysname\ uses similar techniques to existing tools, though it is in a different language
and so encounters different challenges. Some things are in fact easier for \sysname\ than for other tools;
the richness of specifications tells \sysname\ exactly when a patch is successful, for example. 
But the proof assistant \sysname\ operates over supports dependent types, and in the world of proof repair,
the criteria for a patch being correct is very strict. 

Even with these differences, proof repair tools like \sysname\ can learn a lot from other tools that use these techniques.
Consider regression repair tools. %While test-based techniques like those used by ReAssert and Relifix
%don't transfer over in a straightforward way, \sysname\ can learn something from both tools.
Both ReAssert and Relifix support something similar to a kind of change in the \sysname\ sense:
strategies for ReAssert, and operators for Relifix. Relifix uses a manual insection of changes made to determine which operators to support;
when extending \sysname, using the methodology from this inspection may help identify initial kinds of changes for \sysname to support, even though
in the long term, automating this process is ideal (which the Relifix paper similarly notes).
ReAssert also suggests repairs to programmers rather than apply them directly; % TODO check accuracy
supporting this mode of interaction in \sysname\ would integrate
naturally with the typical ITP workflow.

GRAFTER also contributes lessons for proof repair tools like \sysname.
For one, it is essentially a differencing tool: It identifies significant differences between clones and uses those differences
to reuse tests, while ignoring changes that are expected. Interestingly, GRAFTER adapts the tests themselves, rather than adapting code to pass
those tests; this is akin to how in the world of proof repair, sometimes it makes sense not only to change the proof,
but also to change the theorem statement itself. Understanding both the differencing technique and how to adapt the oracle for correctness
along those differences could certainly help future developments.
Still, GRAFTER uses a much simpler type system than that supported by most ITPs like Coq, and restricts the kinds of changes allowed relative to what
is desirable in a proof repair tool like \sysname. % TODO implications of simpler type system and so on

Several of the repair by example tools make use of code repositories and libraries to identify examples.
The long-term vision for \sysname\ discusses using both of these sources, but so far there is little automation
to do so. Making use of code repositories is especially difficult, since Github commits are typically large.
While the research plan mostly considers how to work around this, % by looking at the IDE level instead,
these tools may offer some insights for how to approach this problem.

Many of these tools can also make use of code from different contexts, for example from different libraries. % altogether.
For this, Prophet uses universal features, QACrashFix generalizes patches identified by a differencing algorithm in one context to another context,
SearchRepair uses indexes code by its input-output behavior as constraints for an SMT query,
and \textsc{Lase} makes use of systematic editing to adapt program transformations to different contexts.
Ideally, a tool like \sysname\ could also handle code from different contexts. % what makes it ``different''? do I mean ``similar''? what is the ``same'' context here?
Combining these ideas with work on hammers or proof reuse may help solve this problem
in an ITP context.

Several repair by example tools can also make use of multiple examples, as opposed to just one.
While in the proof repair world, one example is often % is it? why?
enough, perhaps existing techniquess have something to contribute with respect to handling multiple examples. % like machine learning or whatever; but honestly, I doubt it

CatchUp! also provides a useful model for IDE integration for a proof repair tool like \sysname.
For example, it might be useful to record changes within a project inside of an IDE 
so that \sysname\ can later on use those changes to find patches in other contexts. % clarify this nonsensical explanation
Additionally, the \sysname\ paper identifies a need for library designers providing patches for clients,
so that clients can circumvent the search functionality; something like the trace file CatchUp! 
uses may provide useful insight on how to accomplish this. % do we need this? sounds weird in our context
The use of comments at the library developer level is also potentially useful, as is the idea of a simple log for manual replay.

Specification-based repair tools use
the same kind of oracle \sysname\ uses,
though there is a lot of diversity
within these tools. %For example, several tools use
%pre and post conditions, which are not as relevant
%for \sysname, which makes use of proofs.
Some of these tools such as AutoFix-E make
use of existing automation in the form of constraint
solvers to identify patches that satisfy specifications;
making use of Coq's existing automation
in this way might prove fruitful for a tool like \sysname.
The most similar technique is the proof-directed repair methodology. 
\sysname\ focuses
only on repairing proofs, and not
on repairing functions; perhaps using partial 
proofs as in proof-directed repair
can help a tool like \sysname\
repair functions as well.
\fi

\section{More Inspiration}
\label{sec:inspiration}

Other inspiration comes from type theory (Section~\ref{sec:typetheory}),
program synthesis (Section~\ref{sec:synthesis}),
differencing (Section~\ref{sec:diff-incremental}),
program transformations (Section~\ref{sec:rel-transformation}),
automated theorem proving (Section~\ref{sec:atp}),
and user studies (Section~\ref{sec:user-studies}).

\subsection{Type Theory}
\label{sec:typetheory}

\paragraph{Ornaments}

\paragraph{Transport}

\paragraph{Parametricity}

\subsection{Program Synthesis}
\label{sec:synthesis}

\paragraph{Programming by Example}

\paragraph{Neurosymbolic Programming}

\subsection{Differencing}
\label{sec:diff-incremental}

\subsection{Program Transformations}
\label{sec:rel-transformation}

\subsection{Automated Theorem Proving}
\label{sec:atp}

% how stuff caries over to ATP, plus stuff about e-graphs and so on

\paragraph{E-Graphs}

\subsection{User Studies}
\label{sec:user-studies}


\iffalse

TODO somewhere here or elsewhere (if elsewhere, fix references): talk about what lessons carry over to automated theorem provers,
and which lessons carry over to other ITPs, and what work is needed to reach those tools.

\section{Type Theory}

\subsection{Ornaments}

% From DEVOID, unchanged

\toolnameb automates discovery of and lifting across algebraic ornaments in a higher-order dependently typed language.
In the decade since the discovery of ornaments~\cite{mcbride}, there have been a number
of formalizations and embedded implementations of ornaments~\cite{Dagand:2013:CTO:2591370.2591396, ko2013relational, dagand2014transporting, ko2016programming, dagand2017essence}.
\toolnameb is the first tool for ornamentation to operate over a non-embedded dependently typed language.
It essentially moves the automation-heavy approach of Ornamentation in ML~\cite{Williams2017},
which operates on non-embedded ML code, into the type theory that forms the basis of theorem provers like Coq. 
In doing so, it takes advantage of the properties of algebraic ornaments~\cite{mcbride}.
It also introduces the first search algorithm to identify ornaments, which in the past 
was identified as a ``gap'' in the literature~\cite{ko2016programming}.

\subsection{Transport}

The \toolnamec transformation implements transport.
Transport is realizable as a function given univalence~\cite{univalent2013homotopy}.
UP~\cite{tabareau2017equivalences} approximates it
in Coq, only sometimes relying on functional extensionality.
While powerful, neither approach removes references to the old type. %making them poorly suited for repair.

\section{Other Programming Tools}

\subsection{Program Synthesis}

% From sysname PATCH, unchanged

\paragraph{Programming by Example}
Our approach generalizes an example that the programmer provides.
This is similar to programming by example, a subfield of 
program synthesis~\cite{DBLP:journals/ftpl/GulwaniPS17}. 
This field addresses different challenges in different logics,
but may drive solutions to similar problems in a dependently typed language.

\paragraph{Neural Synthesis} (Ongoing work is related to this---really promising approach.)

\subsection{Differencing \& Incremental Computation}

% From sysname PATCH, unchanged

Existing work in differencing and incremental computation may help 
improve our semantic differencing component.
Type-directed diffing~\cite{Miraldo:2017:TDS:3122975.3122976}
finds differences in algebraic data types.
Semantics-based change impact analysis~\cite{Autexier:2010:SCI:1860559.1860580} models semantic differences
between documents.
Differential assertion checking~\cite{differential-assertion-checking-2} analyzes different
versions of a program for relative correctness with respect to a specification.
Incremental $\lambda$-calculus~\cite{Cai:2014:TCH:2594291.2594304} introduces a general model for program changes.
All of these may be useful for improving semantic differencing.


\section{Proofs}

\subsection*{Proof Reuse}

% From sysname PATCH, mostly unchanged

Our approach reimagines the problem of proof reuse in the context of proof automation.
While we focus on changes that occur over time, traditional proof reuse techniques can help
improve our approach.

Proof reuse for extended inductive types~\cite{Boite2004} adapts proof obligations
to structural changes in inductive types. Later work~\cite{Mulhern06proofweaving} proposes a method
to generate proofs for new constructors. These approaches may be useful when extending the differencing
component to handle structural changes. Existing work in theorem reuse and proof generalization~\cite{Felty1994, pons00, Johnsen2004} abstracts existing proofs for reusability, and may be useful
for improving the abstraction component. % TODO much more generalization work should be cited here; see stuff from UIUC interview follow-up email, maybe move into sysname PATCH chapter
Our work focuses on the components critical to searching for patches; these complementary approaches
can drive improvements to the components.

% From sysname Pi, unchanged

A few proof reuse tools work by proof term transformation and so can be used for repair.
Existing work~\cite{Johnsen2004} describes a transformation that generalizes theorems in Isabelle/HOL.
\toolnamec generalizes the transformation from \textsc{Devoid}~\cite{Ringer2019},
which transformed proofs along algebraic ornaments~\cite{mcbride}.
Magaud \& Bertot 2000~\cite{magaud2000changing} implement a proof term transformation between
unary and binary numbers. 
Both of these fit into \toolnamec configurations,
and none suggests tactics in Coq like \toolnamec does.
The expansion algorithm from Magaud \& Bertot 2000~\cite{magaud2000changing} may help guide the design
of unification heuristics in \toolnamec.

% From sysname PATCH, unchanged

Existing work in proof reuse focuses on transferring proofs between isomorphisms,
either through extending the type system~\cite{Barthe:2001:TIP:646793.704711} or through an automatic method~\cite{Magaud2002}.
This is later generalized and implemented in Isabelle~\cite{Huffman2013} and Coq~\cite{ZimmermannH15, tabareau:hal-01559073};
later methods can also handle implications.

% From sysname Pi, unchanged

The widely used Transfer~\cite{Huffman2013} package supports proof reuse in Isabelle/HOL. % TODO somewhere discuss other proof assistants
Transfer works by combining a set of extensible transfer rules with a type inference algorithm.
Transfer is not yet suitable for repair, as it necessitates maintaining references to both datatypes.
%In addition, the proof assistant Isabelle/HOL that Transfer works for lacks both dependent types and proof terms.
One possible path toward implementing proof repair in Isabelle/HOL may be to reify proof terms using something like
Isabelle/HOL-Proofs, apply a transformation based on Transfer, and then (as in \toolname) decompile those terms to automation that does not apply Transfer or refer to the old datatype in any way.

CoqEAL~\cite{cohen:hal-01113453} transforms functions across relations in Coq,
and these relations can be more general than \toolnamec's equivalences.
However, while \toolnamec supports both functions and proofs, CoqEAL supports only simple functions
due to the problem that \lstinline{Iota} addresses.
CoqEAL may be most useful to chain with \toolnamec to get faster functions.
Both CoqEAL and recent ornaments work~\cite{williamsphd} may help with
better workflow support for changes that do not correspond to equivalences.

Recent work~\cite{tabareau2019marriage} extends UP with 
a white-box transformation that may work for repair.
This imposes proof obligations on the proof engineer beyond those imposed by \toolname,
%that establish what is effectively the correctness criteria
%for the configuration in \toolname, while \toolname needs only that it holds metatheoretically.
and it includes neither search procedures for equivalences nor tactic script generation.
It also does not support changes in inductive structure,
instead relying on its original black-box functionality;
\lstinline{Iota} solves this in \toolname. % and is based on lessons learned from reading that article.
The most fruitful progress may come from combining these tools. % to take advantage of the benefits of both.

% From DEVOID, mostly unchanged

\toolnameb identifies and lifts proofs along a specific equivalence 
similar to that from existing ornaments work~\cite{ko2016programming}.
The need to automatically lift functions and proofs
across equivalences and other relations is a long-standing challenge for proof 
engineers~\cite{magaud2000changing, barthe2001type, magaud2003changing, huffman2013lifting, zimmermann2015automatic, cohen:hal-01414881}.
The univalence axiom from Homotopy Type Theory~\cite{univalent2013homotopy} enables transparent transport of proofs;
cubical type theory~\cite{cohen2016cubical} gives univalence a constructive interpretation. 

The problem that we solve is fundamentally about proof reuse,
which applies software reuse principles to ITPs. 
There is a wealth of work in proof reuse, from tactic languages~\cite{felty1994generalization} and logical frameworks~\cite{caplan1995logical},
to tools for proof abstraction and generalization~\cite{pons2000generalization, johnsen2004theorem},
to domain-specific methodologies~\cite{Delaware:2011:PLT:2048066.2048113} and frameworks~\cite{Delaware:2013:MLC:2429069.2429094}.

\toolnameb focuses on the specific problem of reuse
when adding fully-determined indices to types.
Other approaches to this problem include combinators which definitionally reduce to desirable terms~\cite{DBLP:journals/corr/abs-1803-08150} in the language Cedille,
and automatic generation of conversion functions in Ghostbuster~\cite{McDonell:2016:GTS:2951913.2951914} for GADTs in Haskell.
Our work focuses on a type theory different from both of these, in which the properties that allow for such combinators in Cedille are not present, and in which dependent types introduce challenges not present in Haskell.

\toolnameb is not the first tool to combine search with reuse. 
Optician~\cite{miltner2017synthesizing} synthesizes bidirectional string transformations;
a similar approach may help extend tooling to handle transformations for low-level data.
\textsc{sysname Patch}~\cite{ringer2018adapting} 
searches the difference in proofs for patches that can be used to repair proofs broken by changes;
\toolnameb uses a similar approach to identify functions
that form an equivalence. The resulting tools are complementary: \toolnameb supports the addition
of indices and hypotheses, which \textsc{sysname Patch} does not support; \textsc{sysname Patch} supports changes
in values, which \toolnameb does not support. 

\subsection*{Proof Evolution}

% From sysname PATCH, unchanged

There is a small body of work on change and dependency management for verification,
both to evaluate impact of potential changes and maximize reuse~\cite{873647, Autexier:2010:CMH:1986659.1986663}
and to optimize build performance~\cite{Celik:2017:IRP:3155562.3155588}.
These approaches may help isolate changes, which is necessary to identify future benchmarks, integrate
with CI systems, and fully support version updates.

\subsection*{Proof Refactoring}

% From sysname Pi, mostly unchanged

\textit{Refactoring} is the restructuring of code in a way that preserves semantics~\cite{opdyke1992refactoring};
more can be found in a survey~\cite{mens2004survey}.
\textit{Proof refactoring}~\cite{WhitesidePhD} is program refactoring for proofs.
Proof refactoring tools help automate this process, propogating a single change throughout the proof development.
Like program refactoring tools, proof refactoring tools can help keep developments
maintainable as they change over time~\cite{Bourke12}. In that way, it is possible to consider refactoring tools 
as both proactive and reactive.
Proof repair distinguishes itself from proof refactoring in that it considers changes that do not
preserve semantics, though the two concepts go hand-in-hand.
Proof refactoring tools can operate either at the level of proof automation or at the level of proof terms.

% TODO left off here

\paragraph{Refactoring Automation}

A few proof refactoring tools operate directly over tactics:
POLAR~\cite{Dietrich2013} refactors proof scripts in languages based on Isabelle/Isar~\cite{Wenzel2007isar},
CoqPIE~\cite{Roe2016} is an IDE with support for simple refactorings of Ltac scripts, and
Tactician~\cite{adams2015} is a refactoring tool for proof scripts in HOL Light
that focuses on refactoring proofs between sequences of tactics and tacticals (tactic combinators like
the semicolon in Ltac).
This approach is not tractable for more complex changes~\cite{robert2018}.

Refactoring in \textsc{POLAR} works through a combination of rewrite rules that operate over
a graph representation of the underlying language. % TODO elaborate
\textsc{POLAR} implements ten refactorings by default,
and also supports the definition of custom refactorings by users. 
%The semantics-preserving guarantee that 
\textsc{POLAR} guarantees that all lemmas that go through before
the refactoring should continue to go though after the refactoring.
% TODO example refactoring, e.g. renaming a tactic, inc. what happens under the hood

Chick~\cite{robert2018front} includes a language of commands similar to Coq's commands for defining terms,
and can support some refactoring of definitions in that language;
while Chick focuses primarily on proof term refactoring, the Chick thesis
includes useful discussion of the challenges involved in refactoring Ltac proof scripts.

Some proof refactoring tools focus on specific refactoring tasks that are common in proof development.
For example, Levity~\cite{Bourke12} is a proof refactoring tool for an old version of Isabelle/HOL that automatically
moves lemmas %in such a way as 
to maximize reuse. The design of Levity is informed by
experiences with two large proof developments.
Levity has seen large scale industrial use.

Chick~\cite{robert2018} and RefactorAgda~\cite{wibergh2019} are proof refactoring tools
in a Gallina-like language and in Agda, respectively.
% that also support a few changes that can be viewed as repairs~\cite{PGL-045}.
%Chick operates over a Gallina-like language, while RefactorAgda is implemented in Agda.
These tools support primarily syntactic changes and do not have tactic support.
% changes these tools support are still primarily syntactic,
%and neither of these tools have tactic support.

%The Why3~\cite{Bobot2013} verification platform,
%a front-end which integrates several backend theorem provers and proof assistants including Coq, 
%includes functionality which automatically ports user tactics across sessions. 
% TODO is Why3 relevant? Also fix ref. in PE paper since it's confusing what Why3 actually does...
% TODO briefly describe what these are or how they work, example, etc; elaborate as much as possible, maybe email the dudes
% TODO does Levity belong here or in spec section?

% TODO left off here
Refactoring tools are often integrated into the user interfaces and integrated development environments (IDEs) % TODO is this the first reference of IDE?
that programmers use. To this spirit, the Coq IDE CoqPIE~\cite{Roe2016} %for Coq takes this approach for refactoring proof scripts.
includes a \textit{Replay} button which steps through the proof while renaming
any changed hypothesis names. 
CoqPIE can also automatically split out intermediate goals from a proof into separate lemmas. % TODO does this go in proof objects? blurry w/ vernac
There are plans to support more refactoring functionality in CoqPIE in the future. % TODO are any realized yet?
% TODO does CoqPIE support latest Coq? etc.

% TODO more citations maybe from related work

\paragraph{Refactoring Specifications and Proof Terms} % TODO again reconsider this terminology; maybe just terms and types everywhere

There is little work on refactoring proof terms in proof assistants based on dependent type theory like Coq.
This is the main focus of Chick~\cite{robert2018front}, which refactors terms in a dependently-typed functional language
similar to Gallina. To use Chick, the proof engineer applies some refactorings.
Chick then uses a program differencing algorithm to determine the changes to make elsewhere in the program,
then makes those changes.

Chick supports insertion, deletion, modification, and permutation of subterms.
While Chick presents itself as a proof refactoring tool,
this set of changes captures more than refactors.
Adding a new index to a type, for example, does not preserve the semantics of the original program.
The algorithms for differencing and application, however, are syntactic, and do not place any guarantees on
success and on the semantics of the modified program relative to the original program.
 % TODO really need to talk to Val more to get a sense for this and reread

\paragraph{Implications for Proof Repair}

Proof repair tools are similar to proof refactoring tools,
except that they support changes that do not preserve semantics; supporting
both of these is important. There is a lot to learn for proof repair from existing proof refactoring tools,
the most obvious of which is support for common
refactorings, which increases the reach of a proof repair tool and the incentive to use it.
%this is part of the research plan in Section~\ref{sec:plan}.
Likely refactorings worth supporting include hypothesis renaming (as in CoqPIE) and the refactorings Levity can perform, since
the need for both is justified by experiences with large-scale proof development.
%When studying the kinds of changes that proof engineers make, it may help to identify common classes
%of pure refactorings and support these in \sysname\ as well.
Another takeaway from proof refactoring tools is the possibility of supporting custom classes of refactorings or
repairs without requiring modification of the proof repair tool,
for example through custom commands or tactics.

A proof repair tool ideally ought to integrate naturally with proof engineers' workflows;
in Coq, this means integrating with automation.
% ideally, \sysname\ should handle changes not only
%to proof terms, but also to tactics. 
Proof refactoring tools that work at this level may offer hints for how to accomplish this for repairs as well.
The general case of this is not tractable since the semantics of Ltac are not well-defined,
but the updated Ltac2~\cite{ltac2}
may simplify this.
Also in line with supporting the typical workflow of proof engineers is IDE support,
as in CoqPIE; the way CoqPIE accomplishes this % TODO the particular button
may offer useful insights.

%Chick is the one proof refactoring tool that is not a pure refactoring tool.
Since Chick handles some semantic changes, it is possible to think of Chick as a proof repair tool like \sysname.
Chick was developed in parallel to and in cooperation with \sysname, and has a number of similarities.
The Chick workflow is similar to the \sysname\ workflow:
Like \sysname, Chick takes a set of example changes (in this case, supplied by the programmer),
and uses a program differencing algorithm to determine the changes to make elsewhere in the program.

\iffalse
Chick also has some clear differences from \sysname, aside from operating over the Chick language instead of Gallina itself.
Unlike early versions of \sysname, Chick also applies the changes it finds to derive the new program.
However, Chick does this using a syntactic algorithm that handles simple transformations and does
not provide guarantees on the output; for some changes to inductive types, for example, not all proofs from
the old program are preserved in the new program, and the algorithm may fail % TODO does it
on this class of changes. \devoid\ focuses on applying these changes for a class of changes like this
with semantic guarantess. % obviously rephrase
It may be possible to integrate the techniques from Chick, \sysname, and \devoid\
into the same tool and use them to advance the state of proof repair.
%use the techniques from Chick when improving \sysname\
%and handle a larger class of changes, and take advantage of some of the differences between the tool.
\fi

\subsection*{Proof Design}

% From sysname Pi, with some sysname PATCH related work integrated:

Much work focuses on designing proofs
to be robust to change, rather than fixing broken proofs.
This can take the form of design principles, like using 
information hiding techniques~\cite{Woos:2016:PCF:2854065.2854081, Klein:2014:CFV:2584468.2560537}
or any of the structures~\cite{Chrzaszcz2003, Sozeau2008, Saibi:PhD} for encoding interfaces in Coq.
CertiKOS~\cite{certikos} introduces the idea of a deep specification to ease verification of large systems.
Design principles for specific domains (like formal metatheory~\cite{Aydemir2008, Delaware2013POPL, Delaware2013ICFP})
can also make verification more tractable.
Design and repair are complementary: design requires foresight, while repair can occur retroactively.
Repair can help with changes that occur outside of the proof engineer's control,
or with changes that are difficult to protect against even with informed design.

Another approach to this is to use heavy proof automation, for example through
program-specific proof automation~\cite{Chlipala:2013:CPD:2584504}
%implementations of decision procedures~\cite{Pugh1991},
or general-purpose hammers~\cite{Blanchette2016b, Blanchette2013, Kaliszyk2014, Czajka2018}.
The degree to which proof engineers rely on automation varies, as seen in the data from a user study~\cite{replica}.
Automation-heavy proof engineering styles localize the burden of change to the automation,
but can result in terms that are large and slow to type check,
and tactics that can be difficult to debug.
While these approaches are complementary, more work is needed for \toolname to better support 
developments in this style.

\subsection*{Proof Automation}

% From sysname PATCH, unchanged:

We address a missed opportunity in proof automation for ITP: searching
for patches that can fix broken proofs.
This is complementary to existing automation techniques. Nonetheless, there is a wealth
of work in proof automation that makes proofs more resilient to change.
Powerful tactics like \lstinline{crush}~\cite{chlipala:cpdt} can make
proofs more resilient to changes. 
Hammers like Isabelle's sledgehammer~\cite{Blanchette2013} can make proofs agnostic to some low-level changes.
Recent work~\cite{coqhammer} paves the way for a hammer in Coq.
Even the most powerful tactics cannot address all changes;
our hope is to open more possibilities for automation.

Powerful project-specific tactics~\cite{chlipala:cpdt, Chlipala2013} can help prevent low-level maintenance tasks.
Writing these tactics requires good engineering~\cite{Gonthier2011} and domain-specific knowledge,
and these tactics still sometimes break in the face of change.
A future patching tool may be able to repair tactics; the debugging process
for adapting a tactic is not too dissimilar to providing an example to a tool.

Rippling~\cite{rippling} is a technique for automating inductive proofs that uses restricted rewrite rules to
guide the inductive hypothesis toward the conclusion; this may guide improvements to the
differencing, abstraction, and specialization components.
The abstraction and factoring components address specific classes of unification problems;
recent developments to higher-order unification~\cite{Miller:2012:PHL:2331097} may help
improve these components.
Lean~\cite{selsam:lean} introduces the first congruence closure algorithm for dependent type theory that
relies only on the Uniqueness of Identity Proofs (UIP) axiom. While UIP is not fundamental to Coq,
it is frequently assumed as an axiom; when it is, it may be tractable to use a similar algorithm to improve the tool.

GALILEO~\cite{bundyreasoning} repairs faulty physics theories
in the context of a classical higher-order logic (HOL); there is preliminary work extending this
style of repair to mathematical proofs. 
Knowledge-sharing methods~\cite{tgck-cicm14} can adapt some proofs across different representations of HOL.
These complementary approaches may guide extensions to support decidable domains and classical logics.
\fi


