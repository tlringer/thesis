\section{Decompiling Proof Terms to Tactics}
\label{sec:decompiler}

\textbf{Transform} produces a proof term,
while the proof engineer typically writes and maintains proof scripts made up of tactics.
We improve usability thanks to the realization that, since Coq's proof term language Gallina is very structured,
we can decompile these Gallina terms to suggested Ltac proof scripts for the proof engineer to maintain.

%\begin{quote}
%\textbf{Insight 3}: The transformed proof terms can then be translated back to tactic scripts.
%\end{quote}

\textbf{Decompile} implements a prototype of this translation~\href{https://github.com/uwplse/pumpkin-pi/blob/silent/plugin/src/coq-plugin-lib/src/coq/decompiler/decompiler.ml}{\circled{11}}: % decompiler.ml
it translates a proof term to a suggested proof script that attempts to prove the same theorem the same way.
Note that this problem is not well defined: while there is always a proof script that 
works (applying the proof term with the \lstinline{apply} tactic), the result is often qualitatively unreadable.
This is the baseline behavior to which the decompiler defaults.
The goal of the decompiler is to improve on that baseline as much as possible,
or else suggest a proof script that is close enough to correct that the proof engineer can
manually massage it into something that works and is maintainable.

\textbf{Decompile} achieves this in two passes: The first pass decompiles proof terms to proof scripts that use a predefined set of tactics.
The second pass improves on suggested tactics by simplifying arguments, substituting tacticals, and using
hints like custom tactics and decision procedures.

\mysubsubsec{First Pass: Basic Proof Scripts}
The first pass takes Coq terms and produces tactics in Ltac, the proof script language for Coq.
Ltac can be confusing to reason about, since Ltac tactics can refer to Gallina terms, and the semantics of Ltac depends both on the
semantics of Gallina and on the implementation of proof search procedures written in OCaml.
To give a sense of how the first pass works without the clutter of these details, we start by defining a mini decompiler that 
implements a simplified version of the first pass.
Section~\ref{sec:second} explains how we scale this to the implementation.

The mini decompiler takes CIC$_{\omega}$ terms and produces tactics in a 
mini version of Ltac which we call Qtac.
The syntax for Qtac is in Figure~\ref{fig:ltacsyntax1}.
Qtac includes hypothesis introduction (\lstinline{intro}),
rewriting (\lstinline{rewrite}), symmetry of equality (\lstinline{symmetry}),
application of a term to prove the goal (\lstinline{apply}), induction (\lstinline{induction}),
case splitting of conjunctions (\lstinline{split}),
constructors of disjunctions (\lstinline{left} and \lstinline{right}), and
composition (\lstinline{.}).
Unlike in Ltac, \lstinline{induction} and \lstinline{rewrite} take a motive explicitly, rather than relying on unification.
Similarly, \lstinline{apply} leaves the arguments to proof obligations.
%The implementation reasons about Ltac and so does not make these assumptions.

The semantics for the mini decompiler $\Gamma \vdash t \Rightarrow p$ are in Figure~\ref{fig:someantics} (assuming $=$, \lstinline{eq_sym}, $\wedge$, and $\vee$ are defined as in Coq).
As with the real decompiler, the mini decompiler defaults to the proof script
that applies the entire proof term with \lstinline{apply} (\textsc{Base}).
Otherwise, it improves on that behavior by recursing over the proof term and constructing a proof script using a predefined set of tactics.

For the mini decompiler, this is straightforward: Lambda terms become introduction (\textsc{Intro}).
Applications of \lstinline{eq_sym} become symmetry of equality (\textsc{Symmetry}).
Constructors of conjunction and disjunction map to the respective tactics (\textsc{Split}, \textsc{Left}, and \textsc{Right}).
Applications of equality eliminators compose symmetry (to orient the rewrite direction) with rewrites (\textsc{Rewrite}),
and all other applications of eliminators become induction (\textsc{Induction}).
The remaining applications become apply tactics (\textsc{Apply}).
In all cases, the decompiler recurses, breaking into cases, until only the \textsc{Base}
case holds. % at which point we are done.

While the mini decompiler is very simple, only a few small changes are needed
to move this to Coq.
%The result can already handle some of the example proofs \toolnamec has produced.
The generated proof term of \lstinline{rev_app_distr} from Section~\ref{sec:overview},
for example, consists only of induction, rewriting, simplification, and reflexivity (solved by \lstinline{auto}).
Figure~\ref{fig:rainbow} shows the proof term for the base case of \lstinline{rev_app_distr} 
alongside the proof script that \toolnamec suggests.
This script is fairly low-level and close to the proof term, but it is already something that the proof engineer
can step through to understand, modify, and maintain.
There are few differences from the mini decompiler needed to produce this,
for example handling of rewrites in both directions (\lstinline{eq_ind_r} as opposed to \lstinline{eq_ind}),
simplifying rewrites,
and turning applications of \lstinline{eq_refl} into \lstinline{reflexivity} or \lstinline{auto}.

\begin{figure}
\begin{lstlisting}
fun (@\codesimb{(y0 : list A)}@) =>(@\vspace{-0.04cm}@)
  (@\codesima{list\_rect}@) _ _  (fun (@\codesima{a l H}@) =>(@\vspace{-0.04cm}@)
    (@\codesimc{eq\_ind\_r}@) _ (@\codesimd{eq\_refl}@) (@\codesimc{(app\_nil\_r (rev l) (a::[]))}@))(@\vspace{-0.04cm}@)
    (@\codesime{eq\_refl}@)(@\vspace{-0.04cm}@)
    (@\codesima{y0}@)(@\vspace{-0.04cm}@)
(@\vspace{-0.14cm}@)
- (@\codesimb{intro y0.}@) (@\codesima{induction y0 as [a l H|]}.@)(@\vspace{-0.04cm}@)
  + (@\codesimc{simpl. rewrite app\_nil\_r.}@) (@\codesimd{auto.}@)(@\vspace{-0.04cm}@)
  + (@\codesime{auto.}@)(@\vspace{-0.04cm}@)
\end{lstlisting}
\caption{Proof term (top) and decompiled proof script (bottom) for the base case of 
\lstinline{rev_app_distr} (Section~\ref{sec:overview}), with corresponding terms and tactics 
highlighted the same color.}
\label{fig:rainbow}
\end{figure}

\mysubsubsec{Second Pass: Better Proof Scripts}
The implementation of \textbf{Decompile} first runs something similar to the mini decompiler, then modifies the suggested tactics to produce a more natural proof script~\href{https://github.com/uwplse/pumpkin-pi/blob/silent/plugin/src/coq-plugin-lib/src/coq/decompiler/decompiler.ml}{\circled{11}}. % decompiler.ml
For example, it cancels out sequences of \lstinline{intros} and \lstinline{revert},
inserts semicolons, and removes extra arguments to \lstinline{apply} and \lstinline{rewrite}. %, ensuring the result still holds. % TODO rewrite
It can also take tactics from the proof engineer (like part of the old proof script) as hints,
then iteratively replace tactics with those hints, checking the result. % as it recurses.
This makes it possible for suggested scripts to include goal-solving custom tactics and decision procedures.
%We omit the details due to space constraints. TODO add back for PLDI?
%Further improvements could come from preserving comments and indentation, or automatically using information from the old 
%version of the proof script rather than asking for it explicitly.

%In fact, since \toolnamec uses an existing command to translate pattern matching and fixpoints to eliminators,
%\textit{all} of the proof terms that \toolnamec produces will use induction and rewriting instead.
%Because we have control over output terms, even a mini decompiler gets us pretty far.

% TODO add any new things RanDair implements, like exists



