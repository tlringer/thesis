\chapter{Related Work}
\label{sec:related}

% TODO whatever else isn't here yet, and some of this might be factored out or partially factored out---all papers, including survey, plus generals.
% then organize and clean.

Proof repair can be viewed as program repair (Section~\ref{sec:repair})
for the domain of proof engineering (Section~\ref{sec:proofeng}).

\section{Proof Engineering}
\label{sec:proofeng}

Proof repair falls into the domain of \kl{proof engineering},
or the technologies that make it easier to develop and maintain
systems \kl{verified} using \kl{proof assistants}.
Proof repair in this thesis is implemented for Coq, but there are
many other proof assistants to choose from, some with different implications
for proof repair (Section~\ref{sec:ass}).
In contrast with proof repair,
most work on proof maintenance focuses on
designing proofs to be robust to change to begin with (Section~\ref{sec:design}).
While proof repair is new, it builds on work in proof evolution (Section~\ref{sec:refrep}),
proof reuse (Section~\ref{sec:reuse}),
and other kinds of proof automation (Section~\ref{sec:automation}).
\kl{QED at Large} contains a detailed overview of all of these proof engineering technologies and more.

\subsection{Proof Assistants}
\label{sec:ass}

Proof engineering as defined in \kl{QED at Large} considers proof assistants that satisfy the \intro{de Bruijn criterion}~\cite{Barendregt2002,Barendregt2351}, which requires that they produce proof objects that a small proof-checking \kl{kernel} can check.
This includes \kl{Coq}~\cite{coq}---the proof assistant that this thesis focuses on---but also other proof assistants like
\kl{Isabelle/HOL}~\cite{isabelle}, \kl{HOL Light}~\cite{hollight}, \kl{HOL4}~\cite{hol4-interact}, \kl{Agda}~\cite{agda}, \kl{Lean}~\cite{lean}, and \kl{NuPRL}~\cite{nuprl}.
These proof assistants have different foundations (in the case of Coq, \kl{CIC$_{\omega}$}),
different notions of proof objects (in the case of Coq, \kl{proof terms} in \kl{Gallina}),
and different automation built on top of those proof objects (in the case of Coq, \kl{proof scripts} made up of \kl{Ltac} \kl{tactics}).
Differences in proof assistants along these dimensions have different implications for proof repair.

\paragraph{Foundations}
The foundations that make up proof assistants vary by proof assistant.
The foundations of Coq, for example, build on the \kl{intensional} type theory \kl{CIC$_{\omega}$}.
CIC$_{\omega}$ is \intro{intuitionistic}~\cite{Heyting1956} (or \kl{constructive}) in that
proofs in CIC$_{\omega}$ do not assume the \intro{law of the excluded middle} (\kl{LEM}),
which states that for any proposition, either that proposition is true, or its negation is true.
CIC$_{\omega}$ also does not assume \intro{double negation elimination} (\kl{DNE}),
which states that the negation of the negation is the original proposition or type.
Because of this, in CIC$_{\omega}$, it is not possible in general to prove existence by proving that 
nonexistence implies a contradiction.
Instead, one must supply a witness to the existential.\footnote{Perhaps notably, though, the witness to the existential can be that 
\kl{DNE} \emph{provably} holds for a particular instance. This is true for decidable domains in CIC$_{\omega}$.} 

The proof assistants Isabelle/HOL~\cite{isabelle}, HOL4~\cite{hol4-interact}, and HOL Light~\cite{hollight} are built on \intro{classical} foundations
in that they assume both \kl{LEM} and \kl{DNE}.
The proof assistants Agda and Lean are built on \kl{constructive} foundations that are similar to Coq, though with some minor differences.
Lean in particular further assumes an axiom called \intro{uniqueness of identity proofs} (\kl{UIP}), which states that all proofs of
\kl{propositional equality} at a given type are equal.
As I detail in \kl{QED at Large}, this axiom is incompatible with the \kl{univalence} axiom from homotopy type theory~\cite{univalent2013homotopy},
which states that \kl{equivalence} is equivalent to propositional equality.
\intro{Cubical type theory}---of which there are two flavors~\cite{cohen2016cubical, angiuli2017cubical}---gives univalence a constructive interpretation,
so that it is no longer an axiom.
Implementations of cubical type theory include \intro{RedPRL}~\cite{redprl} and \intro{Cubical Agda}~\cite{cubical-agda}.

Proof repair in this thesis assumes \kl{constructive} rather than \kl{classical} foundations.
The core techniques should largely transfer to other proof assistants built on constructive foundations, like Agda and Lean.
It is possible that the particular transformations may have to account for differences, like the presence of \kl{UIP} in Lean,
which may make the general correctness statement of the \toolnamec transformation---one that relies on \kl{univalence} at the level of the metatheory---less meaningful.
The techniques transfer with a bit more resistance to proof assistants built on classical foundations,
since classical proofs may omit information helpful for repair.

\paragraph{Proof Objects} 
In proof assistants that satisfy the \kl{de Bruijn criterion}, the \kl{proof object} is the certificate that the \kl{kernel} can check for
a given proof to make sure that it proves a given theorem.
In Coq, proof objects are \kl{proof terms} in \kl{Gallina}; the kernel verifies these terms by checking their types.
As \kl{Karl} notes in \kl{QED at Large}, producing \intro{explicit proof objects} and checking them is just one of the two dominant approaches to satisfying 
the de Bruijn criterion---the approach followed by \kl{Coq}, \kl{Agda}, and \kl{Lean}.
The other approach is to produce \intro{ephemeral proof objects} that are correct by construction~\cite{Barendregt2013}---an approach followed
by \kl{Isabelle/HOL}, \kl{HOL Light}, and \kl{HOL4}. % what about NuPRL?

Proof repair in this thesis assumes \kl{explicit} rather than \kl{ephemeral} proof objects.
One possible way to apply the same techniques to proof assistants with ephemeral proof objects is to follow the following workflow:

\begin{enumerate}
\item Reify ephemeral proof objects to be explicit.
\item Apply differencing and transformations over those objects.
\item Decompile the transformed proof objects to automation.
\end{enumerate}
Section~\ref{sec:forall} describes a potential specific instance of this workflow for \kl{Isabelle/HOL}.

\paragraph{Automation} %Like different tactic languages.
Typically, layers of \kl{proof automation} act as an interface between the proof engineer and the \kl{kernel}.
In Coq, for example, proof engineers write \kl{proof scripts} interactively using \kl{tactics}.
Proof engineers can combine existing tactics, or write their own, either in the general-purpose programming language
OCaml or in the tactic language \kl{Ltac}. 

In contrast, in \kl{Isabelle/HOL}, proof engineers commonly write proofs in Isabelle/Isar~\cite{wenzel1999isar, Wenzel2007isar}, a high-level
language for structuring and composing propositions, facts, and proof goals.
Proof engineers can also sometimes mix languages for automation.
For example, Coq proof engineers can write proofs using the high-level proof language SSReflect~\cite{Gonthier2010, Gonthier2008},
or they can even mix SSReflect with Ltac tactics.
Isabelle/HOL proof engineers can write automation in the general-purpose language Standard ML---which was originally introduced specifically
for developing proof automation~\cite{Gordon1978}---or with the Ltac-inspired tactic language Eisbach~\cite{Matichuk2015EisbachAP}.
\kl{Agda} proof engineers typically rely only on reflection~\cite{Demers95reflectionin, harrison-reflection, van2012engineering} and not
on any additional language to automate their proofs.

The approach to proof repair taken in this thesis is independent of the kind of automation used, or the language used to implement it.
All that needs to change to transfer this approach to a different tactic or proof language, for example,
is the implementation of the decompiler.
Still, some kinds of automation may produce proof terms that are larger or more difficult to manipulate,
or may make decompilation especially difficult.

Better languages for automation may help circumvent some of the difficulties of repairing tactics directly, without relying a decompiler.
Or, they may help simplify the implementation of the decompiler.
The Ltac successor Ltac2~\cite{ltac2}, for example, is much more structured than Ltac, and may help ease proof repair in Coq in the future.

\subsection{Proof Design}
\label{sec:design}

Much work focuses on designing proofs
to be robust to change, rather than fixing broken proofs.
This can take the form of robust abstractions or robust automation.

% TODO QED if time

\paragraph{Robust Abstractions}
Proof engineers often use abstractions to make proofs less likely to break to begin with.
Examples of this include using 
information hiding techniques~\cite{Woos:2016:PCF:2854065.2854081, Klein2014}
or any of the structures~\cite{Chrzaszcz2004, Sozeau2008, Saibi:PhD} for encoding interfaces in Coq.
CertiKOS~\cite{certikos} introduces the idea of a deep specification to ease verification of large systems.
Design principles for specific domains (like formal metatheory~\cite{Aydemir2008, Delaware2013POPL, Delaware2013ICFP})
can also make verification more tractable.
Design and repair are complementary: design requires foresight, while repair can occur retroactively.
Repair can help with changes that occur outside of the proof engineer's control,
or with changes that are difficult to protect against even with informed design.

\paragraph{Robust Automation}
Another approach to robust design is to use heavy \kl{proof automation}, for example through
custom program-specific \kl{tactics}~\cite{chlipala:cpdt}
%implementations of decision procedures~\cite{Pugh1991},
or general-purpose hammers~\cite{Blanchette2016b, Blanchette2013, Kaliszyk2014, Czajka2018}.
The degree to which proof engineers rely on automation varies, as seen in the data from the \contour[2]{violet}{\kl{\textsc{REPLica}}} user study.
Automation-heavy proof engineering styles localize the burden of change to the automation,
but can result in \kl{proof terms} that are large and slow to type check,
and tactics that can be difficult to debug.
While these approaches are complementary, more work is needed for proof repair tools to better support 
developments in this style.

\subsection{Proof Evolution}
\label{sec:refrep}

% TODO some of this may move into Chapter 2

The need to evolve proofs to changes was raised as a barrier for verification of real software systems as far back as 1977~\cite{DeMillo1977}.
This barrier impacted real developments.
A review~\cite{Elphinstone2013} of the evolution of the seL4 verified 
OS microkernel~\cite{Klein2009}, for example, notes that while
customizing the kernel to different environments may be desirable, 
``the formal verification of seL4 creates a powerful disincentive to changing the kernel.''
Another paper~\cite{leroy2012} motivates and describes updates to the initial CompCert memory model
that include changes in specifications, automation, and proofs~\cite{leroy-mem-2010}.

As I have shown in this thesis, breaking changes are not always in the proof engineer's control.
\intro{Proof refactoring}~\cite{WhitesidePhD} tools---meant to help proof engineers redesign proof developments---can also help proof engineers
repair proofs in response to breaking changes.
These tools are the proof engineering equivalent of \intro{program refactoring} tools, or tools
that restructure code in a way that preserves semantics~\cite{opdyke1992}.
Some proof refactoring tools developed in parallel with my thesis work can be viewed as \kl{proof repair} tools.
This section describes refactoring tools that work at the level of \kl{proof scripts} and \kl{proof terms};
\sysnamelong is the only tool suite for proof evolution I am aware of that supports both.

\paragraph{Proof Scripts}
A few proof refactoring tools operate directly over proof scripts:
\textsc{POLAR}~\cite{Dietrich2013} refactors proof scripts in languages based on Isabelle/Isar~\cite{Wenzel2007isar},
CoqPIE~\cite{Roe2016} is an \intro{Integrated Development Environment} (IDE) with support for simple refactorings of Ltac scripts, and
Tactician~\cite{adams2015} is a refactoring tool for proof scripts in HOL Light
that focuses on refactoring proofs between sequences of tactics and tacticals.
This approach is not tractable for more complex changes~\cite{robert2018}.

Some proof refactoring tools focus on specific refactoring tasks that are common in proof development.
For example, Levity~\cite{Bourke12} is a proof refactoring tool for an old version of Isabelle/HOL that automatically
moves lemmas to maximize reuse. The design of Levity is informed by experiences with two large proof developments.
Levity addresses problems that are especially pronounced in the domain of proof refactoring, such as the
context-sensitivity of proof scripts. Levity has seen large scale industrial use.
 
\paragraph{Proof Terms}
There is little work on refactoring proof terms directly. This is the main focus of Chick~\cite{robert2018}, 
which refactors terms in a language similar to \kl{Gallina}.
Chick was developed in parallel to the \sysname prototype, and both tools influenced one another.
Consequentially, Chick and \sysnamelong have similar workflows:
both take example changes supplied by the proof engineer,
use differencing algorithms to determine the changes to make elsewhere,
and then apply the changes they find. 
Chick supports insertion, deletion, modification, and permutation of subterms.
Chick does this using a syntactic algorithm that handles only simple transformations,
and so presents itself primarily as a proof refactoring tool.

Another term-based refactoring tool is the refactoring tool RefactorAgda~\cite{wibergh2019} for a subset of \kl{Agda} terms.
RefactorAgda supports many changes, including changing indentation, renaming terms, moving terms, converting between implicit and
explicit arguments, reordering subterms, and adding or removing constructors to or from types; 
it also documents ideas for supporting other refactorings, such as adding and removing arguments and indices to and from types.
Both Chick and RefactorAgda support primarily syntactic changes and operate solely over \kl{proof terms}.

\subsection{Proof Reuse}
\label{sec:reuse}

Proof repair is ultimately a form of \intro{proof reuse}---applying software reuse principles to proof assistants
in order to repurpose existing proofs as much as possible.
Like software reuse, proof reuse leverages design principles and language constructs.
In addition, the interactive nature of proof assistants naturally leads to a class of proof reuse technologies less explored
in the software reuse world: automated tooling.
Proof repair falls into the class of automated tooling for proof reuse.
This section describes other automated tooling for proof reuse that may be useful to a future proof repair tool.

\paragraph{Extending Inductive Types} 
\sysnamelong is yet to save proof engineers work when it comes to extending \kl{inductive types} with new \kl{constructors}.
In the future, it may help to draw on early work in proof reuse for extending inductive types.
For example, a 2004 paper~\cite{Boite2004} describes a tactic to adapt proof obligations
to changes in inductive types.
Soon after, a 2006 paper~\cite{Mulhern06proofweaving} provides a high-level
description of a possible method to synthesize missing proofs for those new obligations using a type reconstruction algorithm,
though it is not currently implemented.

\iffalse
\paragraph{Proof Planning}
Proof repair tools may also benefit from work in \textit{proof planning}~\cite{Bundy1998}, a proof search technique
that uses plans to guide search for proofs with similar structures.
Proof planning can involve the use of \textit{critics}~\cite{ireland1996},
which reuse information from failing proofs to guide search for correct proofs.
While proof planning was originally designed for use with automated theorem provers, it has also reached
proof assistants.
For example, IsaPlanner~\citep{Dixon2003} is a proof planner for Isabelle with support
for rippling~\citep{shah2005}, a technique for automatic induction.
Rippling has also been implemented in an induction automation
tool for Coq~\citep{wilson2010}.
\fi

\paragraph{Proof Transformation}
Proof repair in this thesis combines \kl{differencing} with \kl{proof term transformations}.
The idea of proof term transformations dates back to at least 1987~\cite{pfenning}.
Any proof reuse tool that works by proof term transformation can, in theory, be used for repair, especially when coupled with something like the \toolnamec decompiler.

The \sysname prototype implements a kind of proof \kl{generalization}.
This is a common kind of proof term transformation that arose in the context of proof assistants
in the 1990s~\cite{hasker1992generalization, kolbe1998proof, pons1999conception}.
Coq's \lstinline{generalize} tactic does basic syntactic generalization~\cite{coq-tactics}.
Both \sysname and a tool~\cite{Johnsen2004} for generalizing theorems in \kl{Isabelle/HOL}
implement more complex transformations for generalization.

Magaud \& Bertot 2000~\cite{magaud2000changing} implement a proof term transformation between
unary and binary numbers that fits into a \toolnamec configuration.
The expansion algorithm from the paper describing this transformation may help guide the design
of better unification heuristics for \toolnamec, in particular when identifying applications of \kl{definitional} \contour[2]{violet}{\kl{\lstinline{Eta}}}
and \contour[2]{violet}{\kl{\lstinline{Iota}}}.

The refinement framework CoqEAL~\cite{cohen:hal-01113453} transforms functions across relations in Coq,
and these relations can be more general than \toolnamec's equivalences.
However, while \toolnamec supports both functions and proofs, CoqEAL supports only simple functions
due to the problem with \kl{definitional equality} that \contour[2]{violet}{\kl{\lstinline{Iota}}} addresses.
CoqEAL may be most useful to chain with \toolnamec to get faster functions,
or to help support better workflows for changes that do not correspond to equivalences.

One of the automatic configurations in \toolnamec automates discovery of and transport across equivalences
that correspond to \kl{algebraic ornaments}.
This automatic configuration formed the basis of the first tool for ornamentation to operate over a non-embedded dependently typed language,
initially called \textsc{Devoid}---but later generalized to arbitrary equivalences and renamed to \toolnamec.
This stands in contrast to the many existing embedded implementations of 
ornaments~\cite{Dagand:2013:CTO:2591370.2591396, ko2013relational, dagand2014transporting, ko2016programming, dagand2017essence}
that had arisen since their discovery~\cite{mcbride}.
\textsc{Devoid} essentially moved the automation-heavy approach of Ornamentation in ML~\cite{Williams2017},
which operates on non-embedded ML code, into \kl{CIC$_{\omega}$}.
It also introduced the first differencing algorithm to identify ornaments, which in the past 
had been identified as a ``gap'' in the literature~\cite{ko2016programming}.
Other kinds of ornaments may prove useful for future \toolnamec differencing algorithms and configurations.
A recent thesis~\cite{williamsphd} on ornaments may prove especially useful.
% TODO survey paper, and some of the work below
% TODO note the thing about transfer versus transport, and correct thesis (see Twitter)

\paragraph{Transfer \& Transport}
%\toolnamec automatically transports proofs across equivalences.
The need to automatically transfer functions and proofs across equivalences and other relations is a long-standing challenge for proof 
engineers~\cite{magaud2000changing, Barthe2001, magaud2003changing}.
Particular successful is the widely used Transfer~\cite{Huffman2013} package, which supports proof reuse in Isabelle/HOL. % TODO somewhere discuss other proof assistants
Transfer works by combining a set of extensible transfer rules with a type inference algorithm.
Transfer is not yet suitable for repair, as it necessitates maintaining references to both datatypes.
Section~\ref{sec:forall} describes one possible path building on Transfer to implement a proof repair tool for Isabelle/HOL.
%In addition, the proof assistant Isabelle/HOL that Transfer works for lacks both dependent types and proof terms.

The \toolnamec transformation implements a particular kind of transfer called automatic \kl{transport}.
The name here is a potentially confusing: \kl{transport} itself refers to a particular form of 
rewriting along a \kl{propositional equality}, or inhabitance of the identity type.
It often (but not always) refers to \kl{univalent} \kl{transport}, an application of an \kl{eliminator} derivable
in \kl{homotopy type theory} from \kl{univalence}~\cite{univalent2013homotopy}
that rewrites along the identity type corresponding to an \kl{equivalence}~\cite{escardo2018self}.
\textit{Automatic transport} refers to any automated tooling for rewriting along propositional equalities
that behaves like transport at the level of either \kl{internally} to the theory or (as in \toolnamec) \kl{externally} in the metatheory.
Automatic transport is a kind of transfer, but by virtue of it being automatic, not by virtue of it applying transport.\footnote{I got this wrong in \kl{QED at Large}.}
Transfer may apply more broadly than across equalities or equivalences.

\toolnamec implements automatic univalent transport \kl{externally}, without relying on any additional axioms at the level of the theory itself.
The UP black-box transformation~\cite{tabareau2017equivalences} approximates automatic univalent transport \kl{internally}
in Coq, only sometimes relying on additional axioms.
The UP black-box transformation does not remove references to the old type, making it poorly suited for repair.
However, unlike \toolnamec, it supports type-directed search---analogous functionality
may help improve \toolnamec substantially.

Recent work~\cite{tabareau2019marriage} extends UP with 
a white-box transformation that may work for repair.
However, the white-box transformation imposes proof obligations on the proof engineer beyond those imposed by \toolnamec.
%that establish what is effectively the correctness criteria
%for the configuration in \toolname, while \toolname needs only that it holds metatheoretically.
In addition, it comes with neither \kl{differencing} algorithms for equivalences nor \kl{proof script} generation.
It also does not support changes in inductive structure,
instead relying on its original black-box functionality;
\contour[2]{violet}{\kl{\lstinline{Iota}}} solves this in \toolnamec, and is based on lessons learned from reading that article.
The most fruitful progress may come from combining these tools. % to take advantage of the benefits of both.

\subsection{Other Proof Automation}
\label{sec:automation}

Proof repair implements a kind of proof automation.
New proof automation continues to make proof repair more feasible.

\paragraph{Ontology Repair}
GALILEO~\cite{chan2011galileo} is a tool built on \kl{Isabelle/HOL} for identifying and repairing faulty ontologies in response to contradictory
evidence; it has been applied to repair faulty physics ontologies, and may have applications for proof repair.
GALILEO uses repair plans to determine when to trigger a repair, as well as how to repair the ontology.

\paragraph{Knowledge Sharing Methods}
Knowledge sharing methods~\cite{gauthier2014} match concepts across
different proof assistants with similar logics and identify isomorphic types,
and may have implications for proof repair.
Later work uses these methods in combination with HOL(y)Hammer to
reprove parts of the standard library of HOL4 and HOL Light using combined knowledge 
from the two proof assistants~\cite{Gauthier2015}. 
More recently, this approach has been used to identify similar concepts
across libraries in proof assistants with different logics~\cite{gauthier2017}.
These methods may have applications
when repairing proofs even within the same logic, using information from different 
libraries, different commits, or different representations of similar types.

\paragraph{E-Graphs} % TODO lol this sucks
The \toolnamec proof term transformation can in some sense be viewed as a rewrite system across equivalences.
A number of modern rewrite systems use data structures called \textit{e-graphs}~\cite{egraph1} for managing equivalences.
E-graphs have been implemented in \kl{Lean}~\cite{selsam:lean} (assuming \kl{UIP}),
and in \kl{Cubical Agda}~\cite{egraph6} (implying \kl{univalence}).
Similar implementations of e-graphs could help improve \toolnamec and similar tools to support
type-directed search and more (see Section~\ref{sec:forall}).

\section{Program Repair}
\label{sec:repair}

Proof repair can be viewed as a form of \textit{program repair}~\cite{Monperrus:2018:ASR:3177787.3105906, Gazzola:2018:ASR:3180155.3182526}
for proof assistants. % TODO use knowledge package
Proof assistants like Coq are an especially good fit for program repair (Section~\ref{sec:lessons}).
While it is not straightforward to apply existing program repair techniques to proof assistants,
looking to them for inspiration may help improve proof repair tools more in the future (Section~\ref{sec:techniques}).

\subsection{A Good Fit}
\label{sec:lessons}

A recent survey of program repair distinguishes between repair tools based on the \textit{oracle} they use to
judge whether a patch is correct.
For example, proof repair is a kind of \textit{specification-based} repair,
since it uses a specification (a goal type derived from differencing) as an oracle.
Program repair tools sometimes use other oracles---commonly, test suites (\textit{test-based} repair).

A recent review~\cite{Qi:2015:APP:2771783.2771791} of a popular test-based program repair tool~\cite{LeGoues:2012:SSA:2337223.2337225} and its variants
shows that most of the reported patches generated by the tool are not correct.
These observations are later reaffirmed in a different setting~\cite{DBLP:journals/corr/abs-1811-02429}.
In response, the paper recommends that program repair tools draw on extra information, like specifications or example patches.
In \kl{Coq}, specifications and examples are rich and widely available: specifications thanks to dependent types,
and examples thanks to \kl{constructivism}. This shows why proof repair in Coq is an especially good fit for program repair.
 
\paragraph{Specifications}
One limitation of test-based program repair tools is that tests in evaluation suites are often underspecified,
so it can be hard to know when a patch to a program is correct.
For example, the review notes that some tests in the evaluation suite for the tool check whether a program terminates with an exit code of 0, 
but do not check the program output.
In addition, patches are often overfit to the tests in the test suite; additional tests expose problems with those patches.
In fact, some patches are outright harmful, as they introduce new problems which the test suite does not check for.

In contrast, in the world of proof repair, there is always a specification to work with---the theorem being proven---so
a proof repair tool does not need to rely on tests.
Furthermore, the scope of properties that can be specified in proof assistants like Coq is especially large thanks to its expressive type system \kl{CIC$_{\omega}$},
with polymorphism and dependent types.
The richness of the type theory further makes it possible for \sysnamelong to check itself along the way and make sure it is on the right track.

Still, there is always a chance that the specification itself must change in order for proof repair to work,
as I showed with \toolnamec.
In those cases, it is helpful to have some assurance that the specifications the tool produces are meaningful---in the case of
\toolnamec, that the old and new specifications are equal up to \kl{transport} along the change in the datatype.
It is also useful to have a human in the loop to check specifications in the end,
as all of the plugins in \sysnamelong do.
Section~\ref{sec:techniques} discusses other specification-based repair tools,
as well as other repair tools that bring a human into the loop.

\paragraph{Examples}
Another challenge for test-based program repair tools is defining the correct search space and searching efficiently within it.
For example, the review found that running the same tool on strengthened versions of the test suites produced no patches at all in the time allotted.
One possible reason for this is that the tools could not search for the correct patches efficiently enough.
Example-based techniques can help navigate a large search space quickly.

\sysnamelong uses examples---in the former of changes to datatypes or proofs---to derive patches.
The \kl{constructive} foundations of Coq make this especially appealing and powerful.
For example, existence proofs in Coq must be accompanied by a witness.
Each of these witnesses is in effect an example that \sysnamelong can extract and generalize,
narrowing down the search space of possible repairs.

Thanks to the richness of the type theory, \sysnamelong can in practical use cases repair proofs by generalizing a very small number of examples,
like a single example patched proof, or a single example change to a datatype.
Section~\ref{sec:techniques} describes other example-based repair tools.

\subsection{Techniques for Inspiration}
\label{sec:techniques}

% TODO explain why here it's not straightforward to just use program repair tools for proof repair, like did in the talk.
% But then segue into saying the techniques are still useful.
%\sysname\ uses similar techniques to existing tools, though it is in a different language
%and so encounters different challenges. Some things are in fact easier for \sysname\ than for other tools;
%the richness of specifications tells \sysname\ exactly when a patch is successful, for example. 
%But the proof assistant \sysname\ operates over supports dependent types, and in the world of proof repair,
%the criteria for a patch being correct is very strict. 

Proof repair can in the future draw on many of the techniques that program repair tools use,
even though the tools themselves do not carry over in a straightforward way (recall Section~\ref{sec:how}).
This section discusses techniques from existing program repair tools that are relevant to proof repair.
It focuses in particular on what a recent survey~\cite{Monperrus:2018:ASR:3177787.3105906} of program repair calls behavioral repair,
or patching the code, rather than state repair, or patching the dynamic behavior.
Among behavioral repair tools, it focuses on regression repair, specification-based repair,
repair by example, and other techniques that bring a human into the loop.

\paragraph{Regression Repair}
Regression repair tools target regression bugs, like changes that cause a set of tests (the \textit{regressed tests}) that used to pass to no longer pass.
Test-based regression repair tools repair code such that regressed tests pass on the repaired code.
In some sense, proof repair is a kind of regression repair, as it repairs
proofs that used to succeed, but after some change, no longer do (the \textit{regressed proofs}).
A section by \kl{Karl} in \kl{QED at Large} describes the correspondence between regressed proofs and regressed tests in more detail,
and details existing techniques~\cite{Palmskog2018, Wenzel2013MultiProcessing, Barras2013, Celik:2017:IRP:3155562.3155588, Wenzel2013, Barras2015, deMoura2015, Wenzel2014, WenzelScalingIsabelle, WenzelFurtherScalingIsabelle} for rechecking regressed proofs.

One test-based regression program repair tool is ReAssert~\cite{daniel2009reassert} for Java,
which focuses on regressions caused by refactoring.
ReAssert uses a program analysis to identify broken code,
chooses a strategy for repair, and suggests repairs to the programmer using that strategy that cause regressed tests to pass.
It loops through strategies until one works or none remain.
Another such tool is Relifix~\cite{Tan:2015:RAR:2818754.2818813} for C.
Relifix uses a manual inspection to find code transformations based on regressions, then searches those transformations for 
patches that make the regressed tests pass without making other tests fail.
Both ReAssert and Relifix are configurable like \toolnamec, and may provide interesting examples of configurations
or ways of inferring new configurations.

While not quite a regression repair tool, GRAFTER~\cite{Zhang:2017:ATD:3097368.3097448} is a related tool that adapts the tests themselves,
rather than the code under test. Its focus is on testing software clones for errors introduced during the
cloning process. It uses a static analysis to identify variables and methods that correspond between the clones,
then ensures that the flow is preserved using that mapping. The user can then run the new tests to compare behavior.
It provides a guarantee about type safety, and it performs reasonably well on some real-world software.
GRAFTER, like \sysnamelong, takes an approach to repair that uses a form of \kl{differencing}.
Looking to this to help inform new differencing algorithms for \sysnamelong could be fruitful,
in spite of foundational differences of the target domains.

\paragraph{Specification-Based Repair}
Some tools use specifications as an oracle, like \sysnamelong.
For example, AutoFix-E~\cite{Wei:2010:AFP:1831708.1831716, pei2014automated} uses contracts to repair Eiffel programs. 
Specification-Based Program Repair Using SAT~\cite{gopinath2011specification}
encodes pre and post conditions in combination with other constraints from the code 
into SAT and then uses Alloy to generate patches.
Other tools combine test-based program repair with logical specifications and automated solving~\cite{10.1007/978-3-540-24721-0_20, nguyen2013semfix, nguyen2013semfix, Xuan:2017:NAR:3071893.3071964, Mechtaev:2015:DLS:2818754.2818811, Ke:2015:RPS:2916135.2916260}.
For future proof reuse tools, making better use of existing proof automation in proof assistants to generate
patches that satisfy specifications may prove fruitful.

Proof-directed repair~\cite{dennis2006proof} presents a methodology
for repairing programs based on information from incomplete proofs in \kl{Isabelle/HOL}.
Essentially, the programmer writes a proof, and then uses feedback
from the attempted proof to debug and fix the code.
In a sense, since if the repair succeeds the proof should go through,
it uses proofs as an oracle. The paper presents a few techniques for fixing the broken code,
then shows some examples using those techniques with existing tools.
It does not yet automate it in a tool.
Still, perhaps using partial proofs as in proof-directed repair can help a proof repair tool like \sysnamelong
better repair functions.
It also matches the workflow of proof engineers seen in the \contour[2]{violet}{\kl{\textsc{REPLica}}} user study.

\paragraph{Repair by Example}
Some program repair tools work \kl{by example}, like \sysname.
Prophet~\cite{Long:2016:APG:2837614.2837617}, a test-based repair tool for C,
uses human-generated patches from software repositories as examples.
These examples can come from different applications from the one that is being repaired.
Prophet uses differencing over ASTs % of the unpatched and patched code 
to extract features that describe the behavior of the example patch abstracted from its particular application.
From these patches, it learns a model of correct code. Then,
it localizes faults and generates candidates, which it ranks according to the learned model.
In this way, it produces patches that not only cause the tests to succeed, but also
are likely according to the learned model to be correct to humans.

The repair tool QACrashFix~\cite{gao2015fixing} uses pairs of buggy and fixed code from Q \& A sites like
StackOverflow to derive patches for crashing input bugs. These patches are in the form of edit scripts,
so that they can apply in different contexts. %The idea here is that many bugs recur, so they look for fixes that apply to fix other bugs. 
It uses a preprocessing step to find the right query for the Q \& A site, then they
look at answers for buggy and fixed code examples, then from those they derive edit scripts to try to fix the bug.
It then uses a combination of tests and human validation to determine whether the patches are correct.

SearchRepair~\cite{Ke:2015:RPS:2916135.2916260} turns code from repositories into a searchable database.
To form this database, it uses a static analysis to encode the input-output behavior of the code as constraints for an SMT solver.
It then localizes the fault in the buggy program,
encodes the buggy program similarly, performs a semantic code search over that database to identify candidate patches,
and finally uses the test suite as an oracle to determine whether candidates succeed.

Systematic editing~\cite{meng2011systematic} is a technique that could help repair by example tools.
This technique generalizes an edit to a program into a program transformation that can apply in similar program contexts.
It works by syntactic differencing over the AST of the example edit, abstracting the difference, and applying it elsewhere.
It can handle insertions, deletions, updates, and moves.
\textsc{Lase}~\cite{meng2013lase} implements and improves on this,
making use of multiple examples instead of just one, % maybe we should too? for implications for sysname section
and also automatically identifying locations to apply transformations.
Similarly, \lstinline{spdiff}~\cite{andersen2010generic} generalizes patches into semantic patches for Cocinelle~\cite{padioleau2008documenting},
which can then apply those patches automatically in different contexts. This way, the library designer can write a semantic patch
himself, or \lstinline{spdiff} can infer one.

A number of program repair tools above---much like the proof repair tools described in this thesis---build on \kl{differencing} algorithms.
Existing work in differencing and incremental computation may help 
improve semantic differencing algorithms for both program and proof repair.
Type-directed diffing~\cite{Miraldo:2017:TDS:3122975.3122976}
finds differences in algebraic data types.
Semantics-based change impact analysis~\cite{Autexier:2010:SCI:1860559.1860580} models semantic differences
between documents.
Differential assertion checking~\cite{differential-assertion-checking-2} analyzes different
versions of a program for relative correctness with respect to a specification.
Incremental $\lambda$-calculus~\cite{Cai:2014:TCH:2594291.2594304} introduces a general model for program changes.
All of these may be useful for improving semantic differencing.

Some of the program repair tools above use machine learning to generalize examples---I discuss some ideas combining proof repair
with machine learning in Section~\ref{sec:forall}.
Several of the tools identify examples from code repositories and libraries.
These tools may offer some insights for how to break down the large composite changes typically found in static artifacts or in code repositories
into smaller incremental changes like those made during development in the \contour[2]{violet}{\kl{\textsc{REPLica}}} user study.
Isolating changes may help with extracting repair benchmarks from artifacts, supporting library and version
updates, and integrating with \intro{Continuous Integration} (CI) systems.

\paragraph{Human in the Loop}
Some tools avoid using test suites to judge correctness of candidate patches, and instead
bring the programmer into the loop. For example, both ReAssert~\cite{daniel2009reassert}
and QACrashFix~\cite{gao2015fixing} suggest repairs directly to the programmer---a workflow
that partially inspired the tactic suggestion interface in \toolnamec.
In general, an approach that suggests repairs to proof engineers in the end
and allows them to vet the specifications and tactics used seems to fit naturally into proof engineering workflows. 

A natural integration point for a repair tool like \sysnamelong is at the IDE level. 
CatchUp!~\cite{Henkel:2005:CCR:1062455.1062512} is an IDE plugin (implemented for Eclipse in Java) that automatically adapts library clients to API refactorings.
It records refactorings that the library developer makes inside of the IDE,
then replays the refactorings in in client code, reconstructing everything from the recorded trace.
Future proof repair tools may benefit from IDE integration of this kind.
For example, it may be useful to record changes within a project inside of an IDE 
so that \sysnamelong can find patches corresponding to incremental changes without the proof engineering needing to deconstruct them manually.
It may also help to have something like the trace file in CatchUp! so that library developers can easily provide patches for client proof developments.

\iffalse
\section{More Inspiration}
\label{sec:inspiration}

Other inspiration comes from type theory (Section~\ref{sec:typetheory}),
program synthesis (Section~\ref{sec:synthesis}),
and differencing (Section~\ref{sec:diff-incremental}).


\subsection{Type Theory}
\label{sec:typetheory}

(TODO move this! Because moving HoTT stuff to foundations.)

\paragraph{Indexed Types}
The automatic configuration for algebraic ornaments in \toolnamec focuses on the specific problem of reuse and repair when adding fully-determined indices to types.
Other approaches to this problem include combinators which definitionally reduce to desirable terms~\cite{DBLP:journals/corr/abs-1803-08150} in the language Cedille,
and automatic generation of conversion functions in Ghostbuster~\cite{McDonell:2016:GTS:2951913.2951914} for GADTs in Haskell.
My work focuses on a type theory different from both of these, in which the properties that allow for such combinators in Cedille are not present, and in which dependent types introduce challenges not present in Haskell.

\subsection{Program Synthesis}
\label{sec:synthesis}

\paragraph{Programming by Example}
My approach to proof repair works by example.
There is an entire field of program synthesis dedicated to programming by example~\cite{DBLP:journals/ftpl/GulwaniPS17}. 
This field addresses different challenges in different logics,
but may drive solutions to similar problems in a dependently typed language.
% TODO elaborate

\paragraph{Neurosymbolic Programming}

\paragraph{Congruence}

\fi


