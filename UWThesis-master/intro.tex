\chapter{Introduction}

% Current intro sources, mixed together:
% - some new content
% - research statement
% - QED at Large (intro and why proof engineering matters)
% - PUMPKIN Pi
% TODO somewhere, clarify scope of verification here

% TODO can say ``see survey paper''

What would it take to empower programmers of all skill levels across all domains to formally prove
the absence of costly or dangerous bugs in software systems---that is, to formally \intro{verify} them?

Verification has already come a long way toward this since its inception.
This is especially true when it comes to the scale of systems that can be verified.
The seL4~\cite{Klein2009} verified operating system (OS) microkernel, for example,
is the result of a team effort spanning more than
a million lines of proof, costing over 20 person-years.
Given a famous 1977 critique of verification~\cite{DeMillo1977} (emphasis mine):

\begin{quote}
\textit{A sufficiently fanatical researcher}
might be willing to devote \textit{two or 
three years} to verifying a significant 
piece of software if he could be 
assured that the software would remain stable.
\end{quote}
I could argue that, over 40 years, either verification has become easier,
or researchers have become more fanatical. Unfortunately, not all has changed (emphasis still mine):

\begin{quote}
But real-life programs need to 
be maintained and modified. 
There is \intro{no reason to believe} that verifying a modified program is any 
easier than verifying the original the 
first time around.
\end{quote}
This remains so difficult that sometimes, even experts give up in the face of change (Section~\ref{sec:irl}).

This thesis aims to change that by taking advantage of a missed opportunity: tools for developing verified systems (Section~\ref{sec:dev-verif})
have no understanding of how these systems evolve over time, so they miss out on crucial information.
This thesis introduces a new class of verification tools called \textit{proof repair} tools (Section~\ref{sec:thesis})
that understand how software systems evolve, and use the crucial information that evolution carries
to automatically evolve proofs about those systems (Section~\ref{sec:intro-approach}).
This gives us \kl{reason to believe} (Section~\ref{sec:intro-results}).

\section{Developing Verified Systems}
\label{sec:dev-verif}

% TODO segue sentence
Proof repair falls under the umbrella of \intro{proof engineering}: the technologies that make it easier
to develop and maintain verified systems (Section~\ref{sec:proofeng}).
Much like software engineering scales programming to large systems, so proof engineering scales verification to large systems. 
In recent years, proof engineers have verified OS microkernels~\cite{Klein2009, Klein2014micro}, machine learning systems~\cite{pmlr-v70-selsam17a}, distributed systems~\cite{Woos:2016:PCF:2854065.2854081}, constraint solvers~\cite{blanchette2018verified}, web browser kernels~\cite{Jang2012}, compilers~\cite{Leroy:POPL06, Leroy2009, Kumar2014}, file systems~\cite{Chajed2019, Chen2015, Chajed2017}, and even a quantum optimizer~\cite{hietala2021verified}.
Practitioners have found verified systems to be more robust and secure in deployment (Chapter~\ref{chapt:mot}).

Proof engineering focuses in particular on verified systems that have been
developed using special tools called \intro{proof assistants}.
Examples of proof assistants include \intro{Coq}~\cite{coq}, \intro{Isabelle/HOL}~\cite{isabelle}, \intro{HOL Light}~\cite{hollight}, \intro{HOL4}~\cite{hol4-interact},
\intro{Agda}~\cite{agda}, \intro{Lean}~\cite{lean}, and \intro{NuPRL}~\cite{nuprl}.
The proof assistant that I focus on in this thesis will be the \kl{Coq} proof assistant.
A discussion of how this work carries over to other proof assistants is in Chapters~\ref{sec:related} and~\ref{chapt:conclusions}.

To develop a verified system using a proof assistant like Coq, the proof engineer does three things:

\begin{enumerate}
\item implements a \intro{program},
\item \intro{specifies} what it means for the \kl{program} to be correct, and
\item \intro{proves} that the \kl{program} satisfies the \kl{specification}.
\end{enumerate}
This proof assistant then automatically checks this \kl{proof} with a small trusted part of its system
called the \intro{kernel}~\cite{Barendregt2002,Barendregt2351}.
If the proof is correct, then the \kl{program} satisfies its \kl{specification}---it is \kl{verified}.

\section{Thesis}
\label{sec:thesis}

The challenge this thesis addresses is that \kl{programs} and \kl{specifications}
change all of the time---and these changes can break many \kl{proofs}.
For example, a proof engineer who optimizes an algorithm may change the program, but not the specification;
a proof engineer who adapts an OS to new hardware may change both.
Even a small change to a program or specification can break many proofs, especially in large systems.
Changing a verified library, for example, can break proofs about a program that depends on that library---and that breaking change
can be outside of the proof engineer's control.

In response to this challenge, this thesis introduces \intro{proof repair}.
Proof repair automatically fixes broken proofs in response to changes in programs and specifications.
In other words, proof repair views these broken proofs as bugs that a tool can patch.
In doing so, it shows that there \textit{is} \kl{reason to believe} that verifying a modified system should often, in practical use cases, be easier than verifying the original the first time around,
even when the proof engineer does not follow good development processes,
or when change occurs outside of the proof engineer's control.
More formally:

\begin{quote}
\textbf{\intro{Thesis}}: Changes in programs, specifications, and proofs can carry information that a tool can extract, generalize, and apply to fix other proofs broken by the same change. A tool that automates this can save work for proof engineers relative to reference manual repairs in practical use cases.
\end{quote}

\section{Approach}
\label{sec:intro-approach}

\begin{figure}
\begin{center}
\includegraphics[scale=0.32]{Development}
\end{center}
\caption{An illustration of the typical interactive workflow of using the \kl{Coq} \kl{proof assistant} to write a proof. The checkmark at the end
represents correctness of the proof, which is communicated back to the proof engineer in the end.}
\label{fig:workflow}
\end{figure}

My approach to proof repair operates over a low-level representation of proofs,
one that carries structure and information useful to proof engineering tools.
But that very structure can make it challenging for proof engineers to write proofs in that low-level representation
to begin with, which is why proof engineers typically do not interact with it directly.
Instead, proof engineers typically write proofs in a high-level representation.

Consider the typical proof engineering workflow in \kl{Coq} (Figure~\ref{fig:workflow}).
This workflow is interactive:
To write a proof, the proof engineer passes Coq high-level search procedures called \intro{tactics} (like \lstinline{induction}), and Coq responds to each tactic
by refining the current goal to some subgoal (like the goal for the base case). This loop of tactics and goals 
continues until no goals remain, at which point the proof engineer has constructed a sequence of tactics called a \intro{proof script}---the
high-level representation.
To check the proof, Coq compiles that proof script down to a low-level representation called a \intro{proof term},
then uses its \kl{kernel} to check that the proof term has the expected type.
If the term has the expected type, Coq lets the proof engineer know in the end.

One major challenge for a proof repair tool is that it is not clear how to extract and generalize changes and apply
them to fix proofs just by looking at the changes in high-level proof scripts that proof engineers make.
The high-level language of tactics can abstract away important details of these changes.
But the low-level language of proof terms can be brittle and challenging to work with.
Crucially, though, the language is brittle and challenging precisely \textit{because}
it carries so much structure and gives such strong guarantees---two things that are very useful to a proof repair tool.

My approach to proof repair takes advantage of the structure and guarantees of the low-level language of proof terms,
but produces something in the high-level language of proof scripts for proof engineers in the end.
In particular, uses \intro{semantic differencing} algorithms over proof terms
to extract information from a breaking change in a program, specification, or proof.
It then combines those with program transformations over proof terms---called \intro{proof term transformations}---to
generalize and, in some cases, apply that information to fix other  proofs broken by the same change.
In the end, it uses a prototype decompiler to get from the low-level language back up to the high-level language,
so that proof engineers can continue to work in that language going forward. % TODO lol this sucks but whatever it's a first draft

By working over the low-level language of proof terms,
my approach to proof repair is able to systematically and with strong guarantees extract and generalize the information that breaking changes carry,
then apply those changes to fix other proofs broken by the same change.
But by later building up to the high-level language of proof scripts,
my approach can in the end produce proofs that integrate more naturally with proof engineering workflows.

\section{Results}
\label{sec:intro-results}

This thesis is divided into six chapters; chapters are further divided into sections.
After motivating proof repair (Chapter~\ref{chapt:mot}),
this thesis describes two different kinds of proof repair that validate the thesis:
by example (Chapter~\ref{ch:example}) and across equivalences (Chapter~\ref{chapt:pi}).
It concludes with a discussion of related work (Chapter~\ref{sec:related}),
followed by a reflection on the thesis and how it can inform the next era of 
proof engineering (Chapter~\ref{chapt:conclusions}).

The technical \intro{results} of this thesis are threefold:

\begin{enumerate}
\item the \textbf{design} of semantic differencing algorithms \& proof term transformations for proof repair (Sections~\ref{sec:pumpkin-approach},~\ref{sec:pumpkin-diff},~\ref{sec:pumpkin-trans},~\ref{sec:pi-approach},~\ref{sec:pi-diff},and~\ref{sec:pi-trans}),
\item an \textbf{implementation} of these algorithms and transformations inside of a proof repair tool suite (Sections~\ref{sec:pumpkin-impl} and~\ref{sec:pi-implementation}), and
\item \textbf{case studies} to evaluate the tool suite on real proof repair scenarios (Sections~\ref{sec:pumpkin-results} and~\ref{sec:pi-results}).
\end{enumerate}
Viewing the thesis statement as a theorem, the proof is as follows: % TODO link to particular sections here

\begin{quote}
\textbf{Thesis Proof}: Changes in programs, specifications, and proofs can carry information that a tool can extract, generalize, and apply to fix other proofs broken by the same change (by \textbf{design} and \textbf{implementation}). A tool that automates this can save work for proof engineers relative to reference manual repairs in practical use cases (by \textbf{case studies}).
\end{quote}

\paragraph{Design}
The design describes semantic differencing algorithms to extract information from breaking changes in verified systems,
along with proof term transformations to generalize and apply the information to fix proofs broken by the change.
The semantic differencing algorithms compare the old and new versions of a changed term or type,
and from that find a \kl{diff} that describes the change.
The transformations then use that diff to \kl{transform} some term to a more general fix.
The details vary by the class of change supported.
The design of these differencing algorithms and transformations is guided heavily by foundational developments in dependent type theory;
the theory is sprinkled throughout as appropriate.

\paragraph{Implementation}
The implementation shows that in fact \textit{a tool} can extract and generalize the information that changes carry,
and then apply that information to fix other proofs broken by the same change.
This implementation comes in the form of a proof repair tool suite for Coq called \intro{\sysnamelong} (Proof Updater Mechanically Passing Knowledge Into New Proofs, Assisting the Coq Hacker).
Notably, since all repairs that \sysnamelong produces are checked Coq in the end, \sysnamelong does not extend the \intro{Trusted Computing Base} (TCB):
the set of unverified components that the correctness of the proof development depends on~\cite{PGL-045}.
In total, \sysnamelong is about 15000 lines of code implemented in OCaml.
These 15000 lines of code consist of three plugins and a library,
which together bridge the gap between the theory supported by design and the practical proof repair needed for the case studies.

\iffalse
Toward that end, five notable features include:

\begin{enumerate}
\item a preprocessing tool to support features in the implementation language missing from the theory,
\item a prototype decompiler from proof terms to proof scripts for better workflow integration,
\item optimizations for efficiency,
\item meaningful error messages for usability, and
\item additional automation for applying patches. 
\end{enumerate}
\fi

\paragraph{Case Studies}
The case studies show that \sysnamelong can save work for proof engineers relative to 
reference manual repairs in practical use cases. % TODO link to corresponding chapters instead
In particular, the case studies in Chapter~\ref{ch:example} show retroactively that a prototype implementation of proof repair
by example \textit{could have} saved work for proof engineers on major proof developments.
The case studies in Chapter~\ref{chapt:pi} show that proof repair across type equivalences \textit{can} save
and in fact \textit{has already} saved work for proof engineers in practical use cases.

\input{guide}
