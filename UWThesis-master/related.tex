\chapter{Related Work}
\label{sec:related}

% TODO whatever else isn't here yet, and some of this might be factored out or partially factored out---all papers, including survey, plus generals.
% then organize and clean.

Proof repair can be viewed as program repair (Section~\ref{sec:repair})
for the domain of proof engineering (Section~\ref{sec:proofeng}).
Work in type theory, program synthesis, differencing, program transformations, automated theorem proving, and user studies
has inspired and continues to inspire improvements to proof repair tools and techniques (Section~\ref{sec:inspiration}).

\section{Proof Engineering}
\label{sec:proofeng}

\textit{Proof engineering} refers to the technologies that make it easier to develop and maintain
systems verified using proof assistants.
Proof repair falls into the domain of proof engineering.
This section briefly describes work in proof engineering relevant to my work on proof repair:
proof assistants other than Coq (Section~\ref{sec:ass}),
other technologies for proof evolution (Section~\ref{sec:refrep}),
proof reuse (Section~\ref{sec:reuse}),
proof design (Section~\ref{sec:design}),
and other kinds of proof automation (Section~\ref{sec:automation}.
See my survey paper on proof engineering for a detailed overview of the field~\cite{PGL-045}. % TODO credit coauthors

\subsection{Proof Assistants}
\label{sec:ass}

% TODO from survey paper
%Introduction, definition, de bruijn.

%Summary of proof assistants.

%I will discuss how these differ and the implications for proof repair.

\paragraph{Foundations} % Most notably, proof terms.
%But also differences in logics (constructivism, then refer back to it later).

\paragraph{Aesthetics} %Like different tactic languages.
Better proof script languages can help circumvent some of the difficulties of repairing tactics.
The Ltac successor Ltac2~\cite{ltac2}, for example, is much more structured than Ltac, and may help ease proof repair in Coq in the future.

\subsection{Proof Evolution}
\label{sec:refrep}

% TODO some of this may move into Chapter 2

The need to evolve proofs to changes was raised as a barrier for verification of real software systems as far back as 1977, in my favorite critique of program verification~\cite{DeMillo1977}.
This barrier has been realized in real developments; a review~\cite{Elphinstone2013} of the evolution of the seL4 verified 
OS microkernel~\cite{Klein2009}, for example, notes that while
customizing the kernel to different environments may be desirable, 
``the formal verification of seL4 creates a powerful disincentive to changing the kernel.''
Leroy and friends 2012~\cite{leroy2012} motivates and describes updates to the initial CompCert memory model
that include changes in specifications, automation, and proofs~\cite{leroy-mem-2010}.

As I have shown in this thesis, breaking changes are not always in the proof engineer's control.
\textit{Proof refactoring}~\cite{WhitesidePhD} tools---meant to help proof engineers redesign proof developments---can also help proof engineers
repair proofs in response to breaking changes.
These tools are the proof engineering equivalent of \textit{program refactoring} tools, or tools
that restructure code in a way that preserves semantics~\cite{opdyke1992}.
While proof repair is a concept that I introduced with the work in this thesis,
some proof refactoring tools developed in parallel with my work can be viewed as proof repair tools.
This section describes refactoring tools that work at the level of proof scripts and proof terms;
\toolnamec is the only tool for proof evolution I am aware of that supports both proof scripts and proof terms.

\paragraph{Proof Scripts}
A few proof refactoring tools operate directly over tactics:
\textsc{POLAR}~\cite{Dietrich2013} refactors proof scripts in languages based on Isabelle/Isar~\cite{Wenzel2007isar},
CoqPIE~\cite{Roe2016} is an IDE with support for simple refactorings of Ltac scripts, and
Tactician~\cite{adams2015} is a refactoring tool for proof scripts in HOL Light
that focuses on refactoring proofs between sequences of tactics and tacticals.
This approach is not tractable for more complex changes~\cite{robert2018}.

Some proof refactoring tools focus on specific refactoring tasks that are common in proof development.
For example, Levity~\cite{Bourke12} is a proof refactoring tool for an old version of Isabelle/HOL that automatically
moves lemmas to maximize reuse. The design of Levity is informed by experiences with two large proof developments.
Levity addresses problems that are especially pronounced in the domain of proof refactoring, such as the
context-sensitivity of proof scripts. Levity has seen large scale industrial use.
 
\paragraph{Proof Terms}
There is little work on refactoring proof terms directly. This is the main focus of Chick~\cite{robert2018}, 
which refactors terms in a language similar to \kl{Gallina}.
Chick was developed in parallel to the \sysname prototype, and both tools influenced one another.
Consequentially, Chick and \sysnamelong have similar workflows:
both take example changes supplied by the proof engineer,
use differencing algorithms to determine the changes to make elsewhere,
and then (in Chick and \toolnamec, but only sometimes in \sysname) apply the changes they find. 
Chick supports insertion, deletion, modification, and permutation of subterms.
Chick does this using a syntactic algorithm that handles only simple transformations,
and so presents itself primarily as a proof refactoring tool.

Another term-based refactoring tool is the refactoring tool RefactorAgda~\cite{wibergh2019} for a subset of Agda terms.
RefactorAgda supports many changes, including changing indentation, renaming terms, moving terms, converting between implicit and
explicit arguments, reordering subterms, and adding or removing constructors to or from types; 
it also documents ideas for supporting other refactorings, such as adding and removing arguments and indicies to and from types.
Both Chick and RefactorAgda support primarily syntactic changes and do not have tactic support.

\subsection{Proof Reuse}
\label{sec:reuse}

Proof repair is ultimately a form of \textit{proof reuse}---applying software reuse principles to proof assistants.
There is a wealth of work in proof reuse, from tactic languages~\cite{felty1994generalization} and logical frameworks~\cite{caplan1995logical},
to tools for proof abstraction and generalization~\cite{pons2000generalization, johnsen2004theorem},
to domain-specific methodologies~\cite{Delaware:2011:PLT:2048066.2048113} and frameworks~\cite{Delaware:2013:MLC:2429069.2429094}.
I discuss some especially relevant work below. % TODO better segue

% TODO survey paper, and some of the work below
% TODO note the thing about transfer versus transport, and correct thesis (see Twitter)

\paragraph{Transfer \& Transport}
\toolnamec transports proofs across equivalences.
The need to automatically lift functions and proofs across equivalences and other relations is a long-standing challenge for proof 
engineers~\cite{magaud2000changing, barthe2001type, magaud2003changing}.
Particular successful is the widely used Transfer~\cite{Huffman2013} package, which supports proof reuse in Isabelle/HOL. % TODO somewhere discuss other proof assistants
Transfer works by combining a set of extensible transfer rules with a type inference algorithm.
Transfer is not yet suitable for repair, as it necessitates maintaining references to both datatypes.
Chapter~\ref{chapt:conclusions} describes one possible path building on Transfer to implement a proof repair tool for Isabelle/HOL.
%In addition, the proof assistant Isabelle/HOL that Transfer works for lacks both dependent types and proof terms.

The \toolnamec transformation implements a particular kind of transfer called transport from homotopy type theory.
Transport is realizable as a function given univalence~\cite{univalent2013homotopy}---I will discuss this more in Section~\ref{sec:typetheory}.
UP~\cite{tabareau2017equivalences} approximates it
in Coq, only sometimes relying on functional extensionality.
While powerful, neither approach removes references to the old type. %making them poorly suited for repair.

Recent work~\cite{tabareau2019marriage} extends UP with 
a white-box transformation that may work for repair.
This imposes proof obligations on the proof engineer beyond those imposed by \toolnamec,
%that establish what is effectively the correctness criteria
%for the configuration in \toolname, while \toolname needs only that it holds metatheoretically.
and it includes neither search procedures for equivalences nor tactic script generation.
It also does not support changes in inductive structure,
instead relying on its original black-box functionality;
\lstinline{Iota} solves this in \toolnamec. % and is based on lessons learned from reading that article.
The most fruitful progress may come from combining these tools. % to take advantage of the benefits of both.

\paragraph{Proof Transformation}
A few proof reuse tools work by proof term transformation and so can be used for repair. % TODO: include thesis of the CMU dude!
Existing work~\cite{Johnsen2004} describes a transformation that generalizes theorems in Isabelle/HOL.
Magaud \& Bertot 2000~\cite{magaud2000changing} implement a proof term transformation between
unary and binary numbers. 
This fits into a \toolnamec configuration,
and none of these tools suggest tactics in Coq like \toolnamec does.
The expansion algorithm from Magaud \& Bertot 2000~\cite{magaud2000changing} may help guide the design
of unification heuristics in \toolnamec.

The refinement framework CoqEAL~\cite{cohen:hal-01113453} transforms functions across relations in Coq,
and these relations can be more general than \toolnamec's equivalences.
However, while \toolnamec supports both functions and proofs, CoqEAL supports only simple functions
due to the problem that \lstinline{Iota} addresses.
CoqEAL may be most useful to chain with \toolnamec to get faster functions.
Both CoqEAL and recent ornaments work (Section~\ref{sec:typetheory}) may help with
better workflow support for changes that do not correspond to equivalences.

\subsection{Proof Design}
\label{sec:design}

% TODO sentence up here, and include some work from survey paper

\paragraph{Robust Abstractions}
Much work focuses on designing proofs
to be robust to change, rather than fixing broken proofs.
This can take the form of design principles, like using 
information hiding techniques~\cite{Woos:2016:PCF:2854065.2854081, Klein:2014:CFV:2584468.2560537}
or any of the structures~\cite{Chrzaszcz2003, Sozeau2008, Saibi:PhD} for encoding interfaces in Coq.
CertiKOS~\cite{certikos} introduces the idea of a deep specification to ease verification of large systems.
Design principles for specific domains (like formal metatheory~\cite{Aydemir2008, Delaware2013POPL, Delaware2013ICFP})
can also make verification more tractable.
Design and repair are complementary: design requires foresight, while repair can occur retroactively.
Repair can help with changes that occur outside of the proof engineer's control,
or with changes that are difficult to protect against even with informed design.

\paragraph{Robust Automation}
Another approach to robust design is to use heavy proof automation, for example through
program-specific proof automation~\cite{Chlipala:2013:CPD:2584504}
%implementations of decision procedures~\cite{Pugh1991},
or general-purpose hammers~\cite{Blanchette2016b, Blanchette2013, Kaliszyk2014, Czajka2018}.
The degree to which proof engineers rely on automation varies, as seen in the data from the \textsc{REPLica} user study. % TODO make sure named earlier
Automation-heavy proof engineering styles localize the burden of change to the automation,
but can result in terms that are large and slow to type check,
and tactics that can be difficult to debug.
While these approaches are complementary, more work is needed for proof repair tools to better support 
developments in this style.

\subsection{Proof Automation}
\label{sec:automation}

% TODO sentences, more stuff---repair is a kind of automation yadda yadda
New automation continues to make proof repair more feasible.

\paragraph{Ontology Repair}
GALILEO~\cite{chan2011galileo} is a tool build on Isabelle for identifying and repairing faulty ontologies in response to contradictory
evidence; it has been applied to repair faulty physics ontologies, and may have applications more generally for mathematical proofs.
GALILEO uses repair plans to determine when to trigger a repair, as well as how to repair the ontology.

\paragraph{Knowledge Sharing Methods}
Knowledge sharing methods~\cite{gauthier2014} match concepts across
different proof assistants with similar logics and identify isomorphic types,
and may have implications for proof repair.
Later work uses these methods in combination with HOL(y)Hammer to
reprove parts of the standard library of HOL4 and HOL Light using combined knowledge 
from the two proof assistants~\cite{Gauthier2015}. 
More recently, this approach has been used to identify similar concepts
across libraries in proof assistants with different logics~\cite{gauthier2017}.
These methods combined with automation like hammers may help the proof engineer 
adapt proofs between isomorphic types, and may have applications
when repairing proofs even within the same logic, using information from different 
libraries, different commits, or different representations of similar types.

%\paragraph{Unification}
%Much of the functionality of \sysnamelong relies on unification, or solves specific instances of unification problems.
%Recent developments to higher-order unification~\cite{Miller:2012:PHL:2331097} may help improve this functionality.
% TODO if time. also anti-unification or whatever

\section{Program Repair}
\label{sec:repair}

Proof repair can be viewed as a form of \textit{program repair}~\cite{Monperrus:2018:ASR:3177787.3105906, Gazzola:2018:ASR:3180155.3182526}
for proof assistants. % TODO use knowledge package
Proof assistants like Coq are an especially good fit for program repair (Section~\ref{sec:lessons}).
While it is not straightforward to apply existing program repair techniques to proof assistants,
looking to them for inspiration may help improve proof repair tools more in the future (Section~\ref{sec:techniques}).

\subsection{A Good Fit}
\label{sec:lessons}

A recent survey of program repair distinguishes between repair tools based on the \textit{oracle} they use to
judge whether a patch is correct.
For example, proof repair is a kind of \textit{specification-based} repair,
since it uses a specification (a goal type derived from differencing) as an oracle.
Program repair tools sometimes use other oracles---commonly, test suites (\textit{test-based} repair).

A recent review~\cite{Qi:2015:APP:2771783.2771791} of a popular test-based program repair tool~\cite{LeGoues:2012:SSA:2337223.2337225} and its variants
shows that most of the reported patches generated by the tool are not correct.
These observations are later reaffirmed in a different setting~\cite{DBLP:journals/corr/abs-1811-02429}.
In response, the paper recommends that program repair tools draw on extra information, like specifications or example patches.
In Coq, specifications and examples are rich and widely available: specifications thanks to dependent types,
and examples thanks to constructivism. This shows why proof repair in Coq is an especially good fit for program repair.
 
\paragraph{Specifications}
One limitation of test-based program repair tools is that tests in evaluation suites are often underspecified,
so it can be hard to know when a patch to a program is correct.
For example, the review notes that some tests in the evaluation suite for the tool check whether a program terminates with an exit code of 0, 
but do not check the program output.
In addition, patches are often overfit to the tests in the test suite; additional tests expose problems with those patches.
In fact, some patches are outright harmful, as they introduce new problems which the test suite does not check for.

In contrast, in the world of proof repair, there is always a specification to work with---the theorem being proven---so
a proof repair tool does not need to rely on tests.
Furthermore, the scope of properties that can be specified in proof assistants like Coq is especially large thanks to its experessive type system \kl{CIC$_{\omega}$},
with polymorphism and dependent types.
The richness of the type theory further makes it possible for \sysnamelong to check itself along the way and make sure it is on the right track.

Still, there is always a chance that the specification itself must change in order for proof repair to work,
as I showed with \toolnamec.
In those cases, it is helpful to have some assurance that the specifications the tool produces are meaningful---in the case of
\toolnamec, that the old and new specifications are equal up to transport along the change in the datatype.
It is also useful to have a human in the loop to check specifications in the end,
as \toolnamec does.
Section~\ref{sec:techniques} discusses other specification-based repair tools,
as well as other repair tools that bring a human into the loop.

\paragraph{Examples}
Another challenge for test-based program repair tools is defining the correct search space and searching efficiently within it.
For example, the review found that running the same tool on strengthened versions of the test suites produced no patches at all in the time alloted.
One possible reason for this is that the tools could not search for the correct patches efficiently enough.
Example-based techniques can help navigate a large search space quickly.

\sysnamelong uses examples---in the former of changes to datatypes or proofs---to derive patches.
The constructive nature of the logic \kl{CIC$_{\omega}$} beneath Coq makes this especially appealing and powerful,
since it means (by definition) that proofs must be constructed from basic principles.
So existence proofs, for example, must be accompanied by a witness.\footnote{This is known as the \textit{existence property}.}
Each of these witnesses is in effect an example that \sysnamelong can extract and generalize,
narrowing down the search space of possible repairs.

Thanks to the richness of the type theory, \sysnamelong can in practical use cases repair proofs by generalizing a very small number of examples,
like a single example patched proof, or a single example change to a datatype.
Section~\ref{sec:techniques} describes other example-based repair tools.

\subsection{Techniques for Inspiration}
\label{sec:techniques}

% TODO explain why here it's not straightforward to just use program repair tools for proof repair, like did in the talk.
% But then segue into saying the techniques are still useful.
%\sysname\ uses similar techniques to existing tools, though it is in a different language
%and so encounters different challenges. Some things are in fact easier for \sysname\ than for other tools;
%the richness of specifications tells \sysname\ exactly when a patch is successful, for example. 
%But the proof assistant \sysname\ operates over supports dependent types, and in the world of proof repair,
%the criteria for a patch being correct is very strict. 
(Missing paragraph here: not straightforward to just use program repair tools here.)
Even with these differences, proof repair can learn a lot from other tools that use these techniques.

This section discusses techniques from existing program repair tools that are relevant to proof repair.
It focuses in particular on what a recent survey~\cite{Monperrus:2018:ASR:3177787.3105906} of program repair calls behavioral repair,
or patching the code, rather than state repair, or patching the dynamic behavior.
Among behavioral repair tools, it focuses on regression repair, specification-based repair,
repair by example, and other techniques that bring a human into the loop.

\paragraph{Regression Repair}
Regression repair tools target regression bugs, or bugs introduced by changes in code.
Test-based regression repair tools repair code that causes a set of tests (the \textit{regressed tests}) that used to pass to no longer pass,
such that regressed tests pass on the repaired code.
In some sense, proof repair is a kind of regression repair, as it repairs
proofs that used to succeed, but after some change, no longer do (the \textit{regressed proofs}).
A section that \kl{Karl} wrote in our survey paper~\cite{PGL-045} describes the correspondence between regressed proofs and regressed tests in more detail,
and details existing techniques~\cite{Palmskog2018, Wenzel2013MultiProcessing, Barras2013, Celik2017, Wenzel2013, Barras2015, deMoura2015, Wenzel2014, WenzelScalingIsabelle, WenzelFurtherScalingIsabelle} for rechecking regressed proofs.

One test-based regression program repair tool is ReAssert~\cite{daniel2009reassert} for Java,
which focuses on regressions caused by refactoring.
ReAssert uses a program analysis to identify broken code,
chooses a strategy for repair, and suggests repairs to the programmer using that strategy that cause regressed tests to pass.
It loops through strategies until one works or none remain.
Another such tool is Relifix~\cite{Tan:2015:RAR:2818754.2818813} for C.
Relifix uses a manual inspection to find code transformations based on regressions, then searches those transformations for 
patches that make the regressed tests pass without making other tests fail.
Both ReAssert and Relifix are configurable like \sysnamelong, and may provide interesting examples of configurations
or ways of inferring new configurations.

While not quite a regression repair tool, GRAFTER~\cite{Zhang:2017:ATD:3097368.3097448} is a related tool that adapts the tests themselves,
rather than the code under test. Its focus is on testing software clones for errors introduced during the
cloning process. It uses a static analysis to identify variables and methods that correspond between the clones,
then ensures that the flow is preserved using that mapping. The user can then run the new tests to compare behavior.
It provides a guarantee about type safety, and it performs reasonably well on some real-world software.
GRAFTER, like \toolnamec, takes an approach to repair that uses a form of differencing.
Looking to this to help inform new differencing algorithms for \sysnamelong could be fruitful,
in spite of foundational differences of the target domains.

\paragraph{Specification-Based Repair}
Some tools use specifications as an oracle, like \sysnamelong.
For example, AutoFix-E~\cite{Wei:2010:AFP:1831708.1831716, pei2014automated} uses contracts to repair Eiffel programs. 
Specification-Based Program Repair Using SAT~\cite{gopinath2011specification}
encodes pre and post conditions in combination with other constraints from the code 
into SAT and then uses Alloy to generate patches.
Other tools combine test-based program repair with logical specifications and automated solving~\cite{10.1007/978-3-540-24721-0_20, nguyen2013semfix, nguyen2013semfix, Xuan:2017:NAR:3071893.3071964, Mechtaev:2015:DLS:2818754.2818811, Ke:2015:RPS:2916135.2916260}.
For future proof reuse tools, making better use of existing proof automation in proof assistants to generate
patches that satisfy specifications may prove fruitful.

Proof-directed repair~\cite{dennis2006proof} presents a methodology
for repairing programs based on information from incomplete proofs in Isabelle.
Essentially, the programmer writes a proof, and then uses feedback
from the attempted proof to debug and fix the code.
In a sense, since if the repair succeeds the proof should go through,
it uses proofs as an oracle. The paper presents a few techniques for fixing the broken code,
then shows some examples using those techniques with existing tools.
It does not yet automate it in a tool.
Still, perhaps using partial proofs as in proof-directed repair can help a proof repair tool like \sysnamelong
better repair functions.
It also matches the workflow of proof engineers seen in the \textsc{REPLica} user study. % TODO say it's mine somehow 

\paragraph{Repair by Example}
Some program repair tools work by example, like \sysnamelong.
Prophet~\cite{Long:2016:APG:2837614.2837617}, a test-based repair tool for C,
uses human-generated patches from software repositories as examples.
These examples can come from different applications from the one that is being repaired.
Prophet uses differencing over ASTs % of the unpatched and patched code 
to extract features that describe the behavior of the example patch abstracted from its particular application.
From these patches, it learns a model of correct code. Then,
it localizes faults and generates candidates, which it ranks according to the learned model.
In this way, it produces patches that not only cause the tests to succeed, but also
are likely according to the learned model to be correct to humans.

The repair tool QACrashFix~\cite{gao2015fixing} uses pairs of buggy and fixed code from Q \& A sites like
StackOverflow to derive patches for crashing input bugs. These patches are in the form of edit scripts,
so that they can apply in different contexts. %The idea here is that many bugs recur, so they look for fixes that apply to fix other bugs. 
It uses a preprocessing step to find the right query for the Q \& A site, then they
look at answers for buggy and fixed code examples, then from those they derive edit scripts to try to fix the bug.
It then uses a combination of tests and human validation to determine whether the patches are correct.

SearchRepair~\cite{Ke:2015:RPS:2916135.2916260} turns code from repositories into a searchable database.
To form this database, it uses a static analysis to encode the input-output behavior of the code as constraints for an SMT solver.
It then localizes the fault in the buggy program,
encodes the buggy program similarly, performs a semantic code search over that database to identify candidate patches,
and finally uses the test suite as an oracle to determine whether candidates succeed.

Systematic editing~\cite{meng2011systematic} is a technique that could help repair by example tools.
This technique generalizes an edit to a program into a program transformation that can apply in similar program contexts.
It works by syntactic differencing over the AST of the example edit, abstracting the difference, and applying it elsewhere.
It can handle insertions, deletions, updates, and moves.
\textsc{Lase}~\cite{meng2013lase} implements and improves on this,
making use of multiple examples instead of just one, % maybe we should too? for implications for sysname section
and also automatically identifying locations to apply transformations.
Similarly, \lstinline{spdiff}~\cite{andersen2010generic} generalizes patches into semantic patches for Cocinelle~\cite{padioleau2008documenting},
which can then apply those patches automatically in different contexts. This way, the library designer can write a semantic patch
himself, or \lstinline{spdiff} can infer one.

Several of the repair by example tools make use of code repositories and libraries to identify examples.
One challenge that I faced in my proof repair work was making use of examples changes in code repositories, since Github commits are typically large.
These tools may offer some insights for how to approach this problem.
Some of these tools also use machine learning---I discuss some ideas combining proof repair
with machine learning in Section~\ref{sec:synthesis}.

\paragraph{Human in the Loop}
Some tools avoid using test suites to judge correctness of candidate patches, and instead
bring the programmer into the loop. For example, both ReAssert~\cite{daniel2009reassert}
and QACrashFix~\cite{gao2015fixing} suggest repairs directly to the programmer---a workflow
that partially inspired the tactic suggestion interface in \toolnamec.
In general, an approach that suggests repairs to proof engineers in the end
and allows them to vet the specifications and tactics used seems to fit naturally into proof engineering workflows. 

A natural integration point for a repair tool like \sysnamelong is at the IDE level. 
CatchUp!~\cite{Henkel:2005:CCR:1062455.1062512} is an IDE plugin (implemented for Eclipse in Java) that automatically adapts library clients to API refactorings.
It records refactorings that the library developer makes inside of the IDE,
then replays the refactorings in in client code, reconstructing everything from the recorded trace.
Future proof repair tools may benefit from IDE integration of this kind.
For example, it may be useful to record changes within a project inside of an IDE 
so that \sysnamelong can find patches corresponding to incremental changes without the proof engineering needing to deconstruct them manually.
It may also help to have something like the trace file in CatchUp! so that library developers can easily provide patches for client proof developments.

\section{More Inspiration}
\label{sec:inspiration}

Other inspiration comes from type theory (Section~\ref{sec:typetheory}),
program synthesis (Section~\ref{sec:synthesis}),
differencing (Section~\ref{sec:diff-incremental}),
program transformations (Section~\ref{sec:rel-transformation}),
automated theorem proving (Section~\ref{sec:atp}),
and user studies (Section~\ref{sec:user-studies}).

\subsection{Type Theory}
\label{sec:typetheory}

\paragraph{Ornaments}
One of the automatic configurations in \toolnamec automates discovery of and transport across algebraic ornaments in a higher-order dependently typed language.
In the decade since the discovery of ornaments~\cite{mcbride}, there have been a number
of formalizations and embedded implementations of ornaments~\cite{Dagand:2013:CTO:2591370.2591396, ko2013relational, dagand2014transporting, ko2016programming, dagand2017essence}.
An earlier version of \toolnamec called \textsc{Devoid} was the first tool for ornamentation to operate over a non-embedded dependently typed language.
It essentially moved the automation-heavy approach of Ornamentation in ML~\cite{Williams2017},
which operates on non-embedded ML code, into the type theory that forms the basis of theorem provers like Coq. 
In doing so, it took advantage of the properties of algebraic ornaments~\cite{mcbride}.
It also introduced the first search algorithm to identify ornaments, which in the past 
had been identified as a ``gap'' in the literature~\cite{ko2016programming}.

I later integrated this functionality into an automatic configuration in \toolnamec.
Other kinds of ornaments may make useful search procedures for future proof repair tools, or for future configurations of \toolnamec.
A recent thesis~\cite{williamsphd} on ornaments may prove especially useful.

\paragraph{Indexed Types}
The automatic configuration for algebraic ornaments in \toolnamec focuses on the specific problem of reuse and repair when adding fully-determined indices to types.
Other approaches to this problem include combinators which definitionally reduce to desirable terms~\cite{DBLP:journals/corr/abs-1803-08150} in the language Cedille,
and automatic generation of conversion functions in Ghostbuster~\cite{McDonell:2016:GTS:2951913.2951914} for GADTs in Haskell.
My work focuses on a type theory different from both of these, in which the properties that allow for such combinators in Cedille are not present, and in which dependent types introduce challenges not present in Haskell.

\paragraph{Homotopy Type Theory}
% TODO including cubical

%\paragraph{Parametricity?}

\subsection{Program Synthesis}
\label{sec:synthesis}

\paragraph{Programming by Example}
My approach to proof repair works by example.
There is an entire field of program synthesis dedicated to programming by example~\cite{DBLP:journals/ftpl/GulwaniPS17}. 
This field addresses different challenges in different logics,
but may drive solutions to similar problems in a dependently typed language.
% TODO elaborate

\paragraph{Neurosymbolic Programming}

\subsection{Differencing}
\label{sec:diff-incremental}

Existing work in differencing and incremental computation may help 
improve semantic differencing algorithms for proof repair.
Type-directed diffing~\cite{Miraldo:2017:TDS:3122975.3122976}
finds differences in algebraic data types.
Semantics-based change impact analysis~\cite{Autexier:2010:SCI:1860559.1860580} models semantic differences
between documents.
Differential assertion checking~\cite{differential-assertion-checking-2} analyzes different
versions of a program for relative correctness with respect to a specification.
Incremental $\lambda$-calculus~\cite{Cai:2014:TCH:2594291.2594304} introduces a general model for program changes.
All of these may be useful for improving semantic differencing.

\subsection{Program Transformations}
\label{sec:rel-transformation}

\subsection{Automated Theorem Proving}
\label{sec:atp}

% how stuff caries over to ATP, plus stuff about e-graphs and so ons

\paragraph{E-Graphs} % stuff
Lean~\cite{selsam:lean} uses e-graphs to implement the first congruence closure algorithm for dependent type theory that
relies only on the Uniqueness of Identity Proofs (UIP) axiom.
% While UIP is not fundamental to Coq,
%it is frequently assumed as an axiom; when it is, it may be tractable to use a similar algorithm to improve the tool.

\subsection{User Studies}
\label{sec:user-studies}

\iffalse

\paragraph{Congruence}

\paragraph{Homotopy Type Theory}
The univalence axiom from Homotopy Type Theory~\cite{univalent2013homotopy} enables transparent transport of proofs;
cubical type theory~\cite{cohen2016cubical} gives univalence a constructive interpretation. 

\fi


