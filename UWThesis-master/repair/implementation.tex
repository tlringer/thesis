\section{Implementation}
\label{sec:pumpkin-impl}

The source code of the \sysnamelong proof repair plugin suite is on Github.\footnote{\url{http://github.com/uwplse/PUMPKIN-PATCH}} % TODO thesis release
It includes the source code of the \sysname prototype plugin, extended with a number of new features,
including the more advanced \toolnamec plugin that I will present in Chapter~\ref{chapt:pi}.
The latest version supports Coq 8.8, with Coq 8.9.1 support in a branch. % TODO link

This section decribes the implementation of the \sysname prototype (Section~\ref{sec:tool}),
along with some new features that go beyond the original prototype and help with workflow integration (Section~\ref{sec:workflow}),
plus an evaluation of the boundaries of the \sysname prototype that still stand (Section~\ref{sec:eval}).
The interested reader can follow along in the repository.

\subsection{Tool Details}
\label{sec:tool}

% from Inside the Core
% Some of this may be better placed in earlier sections
% TODO use the cool links

The implementation (Section~\ref{sec:pumpkin-impl-procedure}) of the procedure from Figure~\ref{alg:patching} in Section~\ref{sec:pumpkin-workflow}
starts with a preprocessing step which compiles the proof terms to 
trees (like the tree in Figure~\ref{fig:cattree}).\footnote{Representing proof terms directly as trees in the implementation rather
than just in the theory is one of my biggest regrets three years later, and I am actively working on removing this representation from the implementation.
It is very useful for understanding how differencing works over inductive types, but it adds clutter to the implementation that make it difficult to maintain.
\toolnamec represents proof terms as terms, and avoids this representation.}
Differencing (Section~\ref{sec:pumpkin-impl-diff} operates over those trees, 
while the transformations (Section~\ref{sec:pumpkin-impl-trans}) operate directly over the terms those trees represent.
\sysname has no impact on the trusted computing base (Section~\ref{sec:tcb}).

\subsubsection{The Procedure}
\label{sec:pumpkin-impl-procedure}

The implementation (\lstinline{patcher.ml4})

The \sysname prototype exposes the patch finding procedure to users through the Coq command \lstinline{Patch Proof}. \sysname automatically
infers which configuration to use for the procedure from the example change. For example, to
find a patch for the case study in Section~\ref{sec:compcert}, we
used this command:

\begin{lstlisting}[language=ml4]
  Patch Proof Old.unsigned_range unsigned_range as patch.
\end{lstlisting}
\sysname analyzed both versions of \lstinline{unsigned_range} and determined 
that a constructor of the \lstinline{int} type changed (Figure~\ref{fig:int}),
so it initialized the configuration for changes in constructors.

Internally, \sysname represents configurations as sets of options,
which it passes to the procedure. The procedure uses these options to determine
how to compose components (for example, whether to abstract candidates) 
and how to customize components (for example, whether semantic differencing should look for an intermediate lemma).
To implement new configurations for different classes of changes, we simply tweak the options.

\subsubsection{Differencing} 
\label{sec:pumpkin-impl-diff}

We implement semantic differencing over \emph{trees}:
\sysname compiles each proof term into a tree (\lstinline{evaluation.ml}). In these trees,
every node is a type context, and every edge is an extension to that type context with a 
new term.\footnote{These trees are inspired by categorical models of dependent type theory~\cite{Hofmann97}.}
Correspondingly, type differencing (to identify goal types) compares nodes, 
and term differencing (to find candidates) compares edges. (Note that this is a regret, in a footnote.)

sec:pumpkin-diff

The component (\lstinline{differencing.ml}) uses these nodes and edges to prioritize semantically
relevant differences. At the lowest level, it calls a primitive differencing function 
which checks if it can substitute one term within another term to find a function between their types.

The key benefit to this model is that it gives us a natural way to express inductive proofs, so
that differencing can efficiently identify good candidates.
Consider, for example, searching for a patch between conclusions of two inductive proofs of theorems about the natural numbers:

\begin{lstlisting}[language=coq]
  nat_ind (@\diff{P}@) ... (fun (IH : (@\diff{P}@) n) => ...) : (@\ltacforall@) n, (@\diff{P}@) n(@\vspace{-0.08cm}@)
  nat_ind (@\diff{P'}@) ... (fun (IH : (@\diff{P'}@) n) => ...) : (@\ltacforall@) n, (@\diff{P'}@) n
\end{lstlisting}
In each case, the component diffs the terms in the dotted edges of the tree for \lstinline{nat_ind} (Figure~\ref{fig:cattree}) to
try to find a term that maps between conclusions of that case:

\begin{lstlisting}[language=coq]
  P' (@\diff{0}@) -> P (@\diff{0}@)           (* base case candidate *)(@\vspace{-0.08cm}@)
  P' (@\diff{(S n)}@) -> P (@\diff{(S n)}@) (* inductive case candidate *)
\end{lstlisting}
The component also knows that the change in the type of \lstinline{IH} is inconsequential (it occurs for any change in conclusion).
Furthermore, it knows that \lstinline{IH} cannot show up as a hypothesis in the patch,
so it attempts to remove any occurrences of \lstinline{IH} in any candidate.

When the component finds a candidate, it knows \lstinline{P'} and \lstinline{P}
as well as the arguments \lstinline{0} or \lstinline{(S n)}. This makes it simple
to query abstraction for the final patch:

\begin{lstlisting}[language=coq]
  (@\ltacforall@) (@\diff{n}@), P' (@\diff{n}@) -> P (@\diff{n}@)
\end{lstlisting}


The differencing component is \textit{lazy}: it compiles terms into trees one step at a time.
It then \emph{expands} each tree as needed to find candidates (\lstinline{expansion.ml}).
For example, consider searching two functions for a patch between conclusions:
%For example, suppose both terms are functions that take an argument of the same type:

\begin{lstlisting}
  fun (t : T) => b(@\vspace{-0.08cm}@)
  fun (t' : T) => b'
\end{lstlisting}
Differencing introduces a single term of type \lstinline{T} to a common environment,
then expands and recursively diffs the bodies \lstinline{b} and \lstinline{b'} in that environment.

The tool always maintains pointers to easily switch between the tree and AST representations of the terms.
This representation enables extensibility.

\subsubsection{Transformation}
\label{sec:pumpkin-impl-trans}

% TODO redundant for now
\paragraph{Patch Specialization} Specialization (\lstinline{specialize.ml}) takes a patch candidate and some arguments,
all of which are Coq terms.
It applies the candidate to the arguments, then it $\beta\iota$-reduces~\cite{equality} the result using Coq's
\lstinline{Reduction.nf_betaiota} function. It is the job of the 
patch finding procedure to provide both the candidate and the arguments.

(Explain: other reducers do not reduce at all, or remove unecessary applications of the identity function.)

\paragraph{Patch Abstraction} Abstraction (\lstinline{abstraction.ml}) takes a patch candidate, 
the goal type, and the function arguments or function to abstract.
It first generalizes the candidate, wrapping it inside of a lambda from the type of the term to abstract.
Then, it substitutes terms inside the body with the abstract term.
It continues to do this until there is nothing left to abstract, then filters results by the goal type.
Consider, for example, abstracting this candidate by \lstinline{m}:

\begin{lstlisting}[language=coq]
  fun (H : n <= m) => le_plus_trans n m 1 H(@\vspace{-0.04cm}@)
  : n <= m -> n <= m + 1
\end{lstlisting}
The generalization step wraps this in a lambda from some \lstinline{nat}, the type of \lstinline{m}:

\begin{lstlisting}[language=coq]
  fun ((@\diff{n0}@) : nat) =>(@\vspace{-0.04cm}@)
    (fun (H : n <= m) => le_plus_trans n m 1 H)(@\vspace{-0.04cm}@)
  : (@\ltacforall@) (@\diff{n0}@), n <= m -> n <= m + 1
\end{lstlisting}
The substitution step replaces \lstinline{m} with \lstinline{n0}:

\begin{lstlisting}[language=coq]
  fun ((@\diff{n0}@) : nat) =>(@\vspace{-0.04cm}@)
    (fun (H : n <= (@\diff{n0}@)) => le_plus_trans n (@\diff{n0}@) 1 H)(@\vspace{-0.04cm}@)
  : (@\ltacforall@) (@\diff{n0}@), n <= (@\diff{n0}@) -> n <= (@\diff{n0}@) + 1
\end{lstlisting}

Abstraction uses a list of \textit{abstraction strategies} to determine what subterms
to substitute. In this case, the simplest strategy works: The tool
replaces all terms that are convertible to the concrete argument \lstinline{m} with the abstract argument
\lstinline{n0}, which produces a single candidate. Type-checking this candidate confirms that it is a patch.

In some cases, the simplest strategy is not sufficient, even when it is possible to abstract the term.
It may be possible to produce a patch only by abstracting \emph{some} of the subterms
convertible to the argument or function (we show an example of this in Section~\ref{sec:fail}),
or the term may not contain any subterms convertible to the argument or function at all.
We implement several strategies to account for this. The combinations strategy, for example,
tries all combinations of substituting only some of the convertible subterms with the abstract argument. 
The pattern-based strategy substitutes subterms that match a certain pattern
with a term that corresponds to that pattern.

It is the job of the patch finding procedure to provide the candidate and the terms to abstract.
In addition, each configuration includes a list of strategies.
The configuration for changes in conclusions, for example, starts with the simplest strategy,
and moves on to more complex strategies only if that strategy fails.
This design makes abstraction simple to extend with new strategies and simple to call with different strategies
for different classes of changes.

\paragraph{Patch Inversion} Patch inversion (\lstinline{inverting.ml}) exploits symmetry to try to reverse the conclusions of a 
candidate patch.
It first factors the candidate using the factoring component, then calls the primitive inversion
function on each factor, then finally folds the resulting list in reverse.
The primitive inversion function exploits symmetry. 
For example, equality is symmetric, so the component can invert any application of \lstinline{eq_ind} or \lstinline{eq_ind_r}
(any rewrite). Indeed, \lstinline{eq_ind} and \lstinline{eq_ind_r} are inverses, and are related by symmetry:

\begin{lstlisting}[language=coq]
  (@\diff{eq\_ind\_r}@) A x P (H : P x) y (H0 : y = x) :=(@\vspace{-0.04cm}@)
    (@\diff{eq\_ind}@) x (fun y0 : A => P y0) H y ((@\diff{eq\_sym}@) H0)	
\end{lstlisting}
If inversion does not recognize that the type is symmetric, it
swaps subterms and type-checks the result to see if it is an inverse.

\paragraph{Lemma Factoring} The lemma factoring component (\lstinline{factoring.ml}) searches within a term
for its factors. For example,
if the term composes two functions, it returns both factors:

\begin{lstlisting}[language=coq]
  t : (@\diff{X}@) -> (@\diff{Z}@)                (* term *)(@\vspace{-0.04cm}@)
 [f : (@\diff{X}@) -> (@\diff{Y}@); g : (@\diff{Y}@) -> (@\diff{Z}@)] (* factors *)
\end{lstlisting}
In this case, the component takes the composite term and \lstinline{X} as arguments.
It first searches as deep as possible for a term of type \lstinline{X -> Y} for some \lstinline{Y}.
If it finds such a term, then it recursively searches for a term with type \lstinline{Y -> Z}. 
It maintains all possible 
paths of factors along the way, and it discards any paths that cannot reach \lstinline{Z}.

The current implementation can handle paths
with more than two factors, but it fails when \lstinline{Y} depends on \lstinline{X}.
Other components may benefit from dependent factoring; we leave this to future work.

\subsubsection{Trusted Computing Base}
\label{sec:tcb}

A common concern for Coq plugins is an increase in the trusted computing base.
The Coq developers provide a safe plugin API in Coq 8.7 to address this~\cite{coq87news}.
Our prototype takes this into consideration:
While \sysname does not yet support Coq 8.7, it only calls the internal Coq functions that the 
developers plan to expose in the safe API~\cite{coqPR}.
Furthermore, Coq type-checks terms that plugins produce.
Since \sysname does not modify the type checker, it cannot produce an ill-typed term.

\subsection{Workflow Integration}
\label{sec:workflow}

add something about Git, add something about hint application,
add something about optimization via the identity class of change (changes in nothing, sixth configuration).
some forward reference to tactic work later, and other workflow help.

\paragraph{Git Integration}

\paragraph{Patch Application}

\paragraph{Proof Optimization}

\subsection{Testing Boundaries}
\label{sec:eval}

\begin{figure*}[ht]
\begin{minipage}{0.48\textwidth}
\begin{lstlisting}[language=coq]
fun n m p (H : n <= m) (H0 : m <= p) =>(@\vspace{-0.04cm}@)
  (@\diff{le\_S n p}@) (* ... proof of stronger lemma *)(@\vspace{-0.04cm}@)
: (@\ltacforall@) n m p, n <= m -> m <= p -> n <= (@\diff{S p}@)
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}{0.48\textwidth}
\begin{lstlisting}[language=coq]
fun n m p (H : n <= m) (H0 : m <= p) =>(@\vspace{-0.04cm}@)
  (@\diff{le\_plus\_trans n p 1}@) (* ... proof of stronger lemma *)(@\vspace{-0.04cm}@)
: (@\ltacforall@) n m p, n <= m -> m <= p -> n <= (@\diff{p + 1}@)
\end{lstlisting}
\end{minipage}
\vspace{-.35cm}
\caption{Two proof terms \lstinline{old} (left) and \lstinline{new} (right) that contain the same proof of a stronger lemma.}
\label{fig:stronger}
\end{figure*}

\lstset{language=coq, aboveskip=3pt,belowskip=3pt}

In the case studies in Section~\ref{sec:case}, we showed how
the core components are useful for real scenarios.
In this section, we explore the boundary between what the \sysname prototype can and cannot handle.
It is precisely this boundary that informs us how to improve the implementations of the
core components.

To evaluate this boundary, we tested the core components of \sysname on a suite of 50 pairs of proofs (Section~\ref{sec:suite}).
We designed 11 of these pairs to succeed, then modified their proofs to produce the remaining 39 pairs
that try to stress the core functionality of the tool.
%28 of the 50 variants did not stress \sysname at all.
We learned the following from the pairs
that tested \sysname's limitations:

\begin{enumerate}
\item \textbf{The failed pairs drive improvements.} \\
\sysname failed on 17 of 50 pairs. These pairs tell us how to improve the core. (Section~\ref{sec:fail})
\item \textbf{The pairs unearth abstraction strategies.} \\
\sysname produced an exponential number of candidates in 5 of 50 pairs.
New abstraction strategies can dramatically reduce the number of candidates. (Section~\ref{sec:fail})
\item \textbf{\sysname was fast, and it can be faster.} \\
The slowest successful patch took \SI{48}{\ms}. The slowest failure took \SI{7}{\ms}.
Simple changes can make \sysname more efficient. (Section~\ref{sec:perf})
\end{enumerate}

\subsubsection{Patch Generation Suite}
\label{sec:suite}

We wrote a suite\footnote{\url{http://github.com/uwplse/PUMPKIN-PATCH/blob/cpp18/plugin/coq/Variants.v}} of 50 pairs of proofs.
We wrote these proofs ourselves since searching for proof patches is a new domain,
so there was no existing benchmark suite to work with.
We used the following methodology:
%We designed 11 pairs to succeed, then modified these pairs to produce the remaining 39 pairs
%that stress the functionalti
%We designed 11 pairs to succeed:

\begin{enumerate}
\item Choose theorems \lstinline{old} and \lstinline{new}
\item Write similar inductive proofs of \lstinline{old} and \lstinline{new}
\item Modify the proof of \lstinline{old} to produce more pairs
\item Search for patches from \lstinline{new} to \lstinline{old}
\item If possible, search for patches from \lstinline{old} to \lstinline{new}
\end{enumerate}

In total, we chose 11 pairs of theorems \lstinline{old} and \lstinline{new}, and we wrote
50 pairs of proofs of those theorems.

For example, one pair of theorems \lstinline{old} and \lstinline{new} was a 
simplification of the auxiliary lemmas
that we encountered in the case study in Section~\ref{sec:foundations}.
For the first proof of \lstinline{old}, we added a rewrite, like in the case study:

\begin{lstlisting}[language=coq]
    (@\diff{rewrite <- plus\_n\_O.}@) rewrite -> plus_comm.
\end{lstlisting}

For the second proof of \lstinline{old}, we commuted the rewrites:

\begin{lstlisting}[language=coq]
    rewrite -> plus_comm. (@\diff{rewrite <- plus\_n\_O.}@)
\end{lstlisting} 

We then searched for patches in both directions,
since the conclusions of \lstinline{old}
and \lstinline{new} were propositionally equal.

Our goal was to determine what changes to proofs stress the components
and how to use that information to drive improvements.
We focused on differences in conclusions, the most supported configuration.
%The procedure defaults to \lstinline{old} when it cannot find a patch; 
%we marked each pair a success if \sysname found a direct patch,
%and a failure if it returned the default.
Since \sysname operates over terms,
we removed redundant proof terms, even if they were produced by different tactics.
We controlled the first pair of proofs of each pair of theorems for features we had not yet implemented,
like nested induction, changes in hypotheses, and abstracting \lstinline{omega} terms.
These features sometimes showed up in later proofs (for example, after moving a rewrite);
we kept these proofs in the suite, since isolated changes to supported proofs that
introduce unsupported features can inform future improvements.	

\subsubsection{Three Challenges}
\label{sec:fail}

\sysname found patches for 33 of the 50 pairs. 28 of the 33 successes
did not stress \sysname at all: \sysname found the correct candidate immediately and was able to abstract it
in one try.
The pairs that \sysname failed to patch and the successful pairs that stressed abstraction
reveal key information about how to improve the core components.
We walk through three examples.
Future tools can use these as challenge problems to improve upon \sysname.

\paragraph{A Challenge for Differencing} For one pair of proofs of theorems 
with propositionally equal conclusions (Figure~\ref{fig:stronger}),
the differencing component failed to find candidates in either direction.
These proofs both contain the same proof of a stronger lemma;
\sysname found patches from this lemma to
both \lstinline{old} and \lstinline{new},
but it was unable to find a patch between \lstinline{old} and \lstinline{new}.
A patch may show up deep in the difference between \lstinline{le_plus_trans}
and \lstinline{le_S}, but even if we $\delta$-reduce (unfold the definition of~\cite{equality}) \lstinline{le_plus_trans}, this is not obvious:

\begin{lstlisting}
    le_plus_trans n m p (H : n <= m) :=(@\vspace{-0.04cm}@)
      (fun lemma : m <= m + p =>(@\vspace{-0.04cm}@)
        trans_contra_inv_impl_morphism(@\vspace{-0.04cm}@)
          PreOrder_Transitive(@\vspace{-0.04cm}@)
          (m + p)(@\vspace{-0.04cm}@)
          m(@\vspace{-0.04cm}@)
          lemma)(@\vspace{-0.04cm}@)
      (le_add_r m p)(@\vspace{-0.04cm}@)
      H
\end{lstlisting}

This points to two difficulties in finding patches: Knowing when to $\delta$-reduce terms 
is difficult; exploring the appropriate time for reduction
may produce patches for pairs that \sysname currently cannot patch.
Furthermore, finding patches is more challenging
when neither theorem has a conclusion that is as strong as possible.

\paragraph{A Challenge for Inversion} For one pair of proofs with propositionally equal conclusions,
\sysname found a patch in one direction, but failed to invert it:

\begin{lstlisting}[language=coq]
    fun n m p (_ : n <= m) (_ : m <= p) (H1 : n <= p) =>(@\vspace{-0.04cm}@)
      gt_le_S n (S p) (le_lt_n_Sm n p H1)(@\vspace{-0.04cm}@)
    : (@\ltacforall@) n m p, n <= m -> m <= p -> n <= p -> S n <= S p
\end{lstlisting}

The inversion component was unable to invert this term, even though an inverse does exist.
To invert this, the component needs to know to $\delta$-reduce \lstinline{gt_le_S}:

\begin{lstlisting}[language=coq]
  gt_le_S n m :=(@\vspace{-0.04cm}@)
    (fun (H : (@\ltacforall@) n0 m0, (@\diff{n0 < m0}@) -> (@\diff{S n0 <= m0}@)) => H n m) (@\vspace{-0.1cm}@)
    ...(@\vspace{-0.1cm}@)
  : (@\ltacforall@) n m, (@\diff{n < m}@) -> (@\diff{S n <= m}@)
\end{lstlisting}

It then needs to swap the hypothesis with the conclusion in \lstinline{H} to produce the inverse:

\begin{lstlisting}[language=coq]
  gt_le_S$\inv$ n m :=(@\vspace{-0.04cm}@)
    (fun (H : (@\ltacforall@) n0 m0, (@\diff{S n0 <= m0}@) -> (@\diff{n0 < m0}@)) => H n m)(@\vspace{-0.1cm}@)
    ...(@\vspace{-0.1cm}@)
   : (@\ltacforall@) n m, (@\diff{S n <= m}@) -> (@\diff{n < m}@)
\end{lstlisting}

Inversion currently swaps subterms when it is not
aware of any symmetry properties about the inductive type. However,
it does not know when to $\delta$-reduce function definitions. Furthermore, 
there are many possible subterms to swap;
for inversion to know to only swap the subterms of \lstinline{H}, it must have a better
understanding of the structure of the term. Both of these are ways to improve inversion.

\paragraph{A Challenge for Abstraction} Abstraction produced an exponential number of candidates when abstracting a patch candidate with this type:

\begin{lstlisting}[language=coq]
    (@\ltacforall@) n n0,(@\vspace{-0.04cm}@)
      (fun m => n <= max m n0) n ->(@\vspace{-0.04cm}@)
      (fun m => n <= max n0 m) n
\end{lstlisting}

The goal was to abstract by \lstinline{n} and produce a patch with this type:

\begin{lstlisting}[language=coq]
    (@\ltacforall@) (@\diff{m0}@) n n0,(@\vspace{-0.04cm}@)
      n <= max (@\diff{m0}@) n0 ->(@\vspace{-0.04cm}@)
      n <= max n0 (@\diff{m0}@)
\end{lstlisting}

%search found the following applied patch, For 5 variants, \sysname found a patch, but only after producing an exponential number of abstract candidates.
%While this did not have a significant impact on time, these variants uncover natural ways to extend abstraction
%to produce fewer candidates.
%For example, for one pair of proof terms, search found an applied patch:

The difficulty was in determining which occurrences of \lstinline{n} to abstract.
The component needed to abstract only the highlighted occurrences:

\begin{lstlisting}
    fun n n0 (H0 : n <= max n0 (@\diff{n}@)) =>(@\vspace{-0.04cm}@)
      @eq_ind_r (@\vspace{-0.04cm}@)
        nat (@\vspace{-0.04cm}@)
        (max n0 (@\diff{n}@))(@\vspace{-0.04cm}@)
        (fun n1 => n <= n1)(@\vspace{-0.04cm}@)
        H0(@\vspace{-0.04cm}@)
        (max (@\diff{n}@) n0)(@\vspace{-0.04cm}@)
        (max_comm (@\diff{n}@) n0)
\end{lstlisting}

The simplest abstraction strategy failed, and a more
complex strategy
succeeded only after producing exponentially many candidates.
While this did not have a significant impact on time,
this case gives rise to a new class of abstraction strategies:
semantics-aware abstraction.
In this case, we know from the type of the candidate
and the type of \lstinline{eq_ind_r} that these two hypothesis types 
are equivalent (similarly for the conclusion types):

\begin{lstlisting}
    (fun m => n <= max m n0) n(@\vspace{-0.04cm}@)
    (fun n1 => n <= n1) (max n0 n)
\end{lstlisting}

The tool can search recursively for patches to find two patches that bridge the two equivalent
types:

\begin{lstlisting}
    p1 := fun n => max n0 n(@\vspace{-0.04cm}@)
    p2 := fun n => max n n0
\end{lstlisting}

Then the candidate type is exactly this:

\begin{lstlisting}
    (@\ltacforall@) n n0,(@\vspace{-0.04cm}@)
      (fun n1 => n <= n1) (@\diff{(p2 n)}@) ->(@\vspace{-0.04cm}@)
      (fun n1 => n <= n1) (@\diff{(p1 n)}@)
\end{lstlisting}

Abstraction should thus abstract the highlighted subterms and the
terms that have types constrained by those subterms.
%It should not change \lstinline{(fun n1 => n <= n1)}.
This produces a patch in one candidate:

\begin{lstlisting}
    fun (@\diff{m0}@) n n0 (H0 : n <= max n0 (@\diff{m0}@)) =>(@\vspace{-0.04cm}@)
      @eq_ind_r (@\vspace{-0.04cm}@)
        nat (@\vspace{-0.04cm}@)
        (max n0 (@\diff{m0}@))           (* p1 (@\diff{m0}@) *)(@\vspace{-0.04cm}@)
        (fun n1 => n <= n1) (* P *)(@\vspace{-0.04cm}@)
        H0                    (* : P (p1 (@\diff{m0}@)) *)(@\vspace{-0.04cm}@)
        (max (@\diff{m0}@) n0)           (* p2 (@\diff{m0}@) *)(@\vspace{-0.04cm}@)
        (max_comm (@\diff{m0}@) n0)      (* : p1 (@\diff{m0}@) = p2 (@\diff{m0}@) *)
\end{lstlisting}

%This is a significant engineering effort, but it generalizes beyond this case.
This same strategy would find a patch for one of the pairs that \sysname failed to 
abstract. %This suggests that even if this strategy increases runtime,
%it 
This is a natural future direction for abstraction.

\subsubsection{Performance}
\label{sec:perf}

\sysname performed well for all pairs. The slowest success took \SI{48}{\ms}.\footnote{i7-4790K, at 4.00 GHz, 32 GB RAM}
When \sysname failed, it failed fast. The slowest failure took \SI{7}{\ms}.
While we find this promising, proof terms were small ($\le$ 67 LOC);
we leave evaluating performance on larger terms
to future work.

%When \sysname failed, it failed fast. The slowest failure took \SI{7}{\ms}.
%This was a case of nested induction, which we are yet to implement: \sysname interpreted the difference of parameters
%in the nested inductive case as significant and tried to abstract that candidate. This difference
%was not actually significant, so search failed.

% TODO double-check that that's true

\sysname was slowest %at finding patches 
when the patch showed up inverted in the difference of proofs,
since \sysname had to search twice, once in each direction.
A future procedure may %implement search in both directions at once,
%or may 
determine which direction to search first ahead of time; proof term size may be a simple heuristic for this.

