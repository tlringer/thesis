\chapter{Introduction}

% Current intro sources, mixed together:
% - some new content
% - research statement
% - QED at Large (intro and why proof engineering matters)
% - PUMPKIN Pi
% TODO somewhere, clarify scope of verification here

What would it take to empower programmers of all skill levels across all domains to formally prove
the absence of costly or dangerous bugs in software systems---that is, to formally \textit{verify} them?

Verification has already come a long way since its inception,
especially when it comes to the scale of programs that can be verified.
The seL4~\cite{Klein2009} verified operating system kernel, for example,
is the effort of a team of proof engineers spanning more than
a million lines of proof, costing over 20 person-years.
Given a famous 1977 critique of verification~\cite{DeMillo1977} (emphasis mine):

\begin{quote}
\textit{A sufficiently fanatical researcher}
might be willing to devote \textit{two or 
three years} to verifying a significant 
piece of software if he could be 
assured that the software would remain stable.
\end{quote}
I could argue that, over 40 years, either verification has become easier,
or researchers have become more fanatical. Unfortunately, not all has changed (emphasis still mine):

\begin{quote}
But real-life programs need to 
be maintained and modified. 
There is \textit{no reason to believe} that verifying a modified program is any 
easier than verifying the original the 
first time around.
\end{quote}
As we will soon see, this remains so difficult that sometimes, even experts give up in the face of change. % TODO cite section

This thesis aims to change that by taking advantage of a missed opportunity: tools for developing verified systems
have no understanding of how these systems evolve over time, so they miss out on crucial information.
This thesis introduces a new class of verification tools called \textit{proof repair} tools.
Proof repair tools understand how software systems evolve, and use the crucial information that evolution carries
to automatically evolve proofs about those systems.
This gives us reason to believe.

\section{Thesis}

% TODO segue sentence
Proof repair falls under the umbrella of \textit{proof engineering}: the technologies that make it easier
to develop and maintain verified systems.
Much like software engineering scales programming to large systems, so proof engineering scales verification to large systems. 
In recent years, proof engineers have verified operating system (OS) micro kernels~\cite{Klein2009, Klein2014micro}, machine learning systems~\cite{TODO}, distributed systems~\cite{TODO}, constraint solvers~\cite{TODO}, web browser kernels~\cite{TODO}, compilers~\cite{Leroy:POPL06, Leroy2009}, file systems~\cite{TODO}, and even a quantum optimizer~\cite{TODO}.
As we will soon see, practitioners have found these verified systems to be more robust and secure in deployment. % TODO cite section
% TODO maybe include the Why Proof Engineering Matters from QED at Large in Chapter 2 somewhere. Maybe move this too.

Proof engineering focuses in particular on verified systems that have been
developed using special tools called \textit{proof assistants} or interactive theorem provers (ITPs).
Examples of proof assistants include Coq~\cite{coq}, Isabelle/HOL~\cite{isabelle}, 
HOL Light~\cite{hollight}, and Lean~\cite{lean}.
To develop a verified system using a proof assistant, the proof engineer does three things:

\begin{enumerate}
\item implements a program using a functional programming language,
\item specifies what it means for the program to be correct, and
\item proves that the program satisfies the specification.
\end{enumerate}
This proof assistant then automatically checks this proof with a small trusted part of its system~\cite{Barendregt2002,Barendregt2351}.
If the proof is correct, then the program satisfies its specification---it is \textit{verified}.

Proof repair automatically fixes broken proofs in response to changes in programs and specifications.
For example, a proof engineer who optimizes an algorithm may change the program, but not the specification; a proof engineer who adapts an OS to new hardware may change both. Even a small change to a program or specification can break many proofs, especially in large systems.
Changing a verified library, for example, can break proofs about programs that depend on that library---and those breaking changes
can be outside of the proof engineers' control.

Proof repair views these broken proofs as bugs that a tool can patch.
In doing so, it shows that there \textit{is} reason to believe that verifying a modified system should often, in practical use cases, be easier than verifying the original the first time around,
even when proof engineers do not follow good development processes,
or when change occurs outside of proof engineers' control.
More formally:

\begin{quote}
\textbf{Thesis}: Changes in programs, specifications, and proofs carry information that a tool can extract, generalize, and apply to fix other proofs broken by the same change. A tool that automates this can save work for proof engineers relative to reference manual repairs in practical use cases.
\end{quote}

\section{Approach}

\begin{figure}[ht]
  \centering
{\footnotesize
\begin{tikzpicture}[>=stealth',semithick]

\begin{scope}
\node[ellipse, draw=black, inner ysep=8pt, inner xsep=5pt] (user) { user };
\end{scope}

\begin{scope}[xshift=5.5cm]
\node[rectangle, draw=black, minimum width=6.5cm, minimum height=2cm] (coq) { };
\node[rectangle, draw=black, minimum height=1.5cm, fill=lightgray, xshift=-2cm] (engine) { logic engine };
\node[rectangle, draw=black, xshift=1.8cm] (checker) { proof checker };
\node[xshift=1.7cm, yshift=0.7cm] (sys) { proof assistant };
\end{scope}

\begin{scope}[xshift=9.5cm]
\node[yshift=0.6cm] (ack) {\checkmark};
\node[yshift=-0.6cm,xshift=-0.1cm] (nack) {\cross};
\end{scope}

\draw[->, thick] (user.north east) to node[xshift=-0.2cm, yshift=0.2cm] {tactics} ([yshift=0.33cm]engine.west);
\draw[->, thick] ([yshift=0.38cm]engine.south west) to node[xshift=-0.2cm, yshift=-0.2cm] {subgoals} (user.south east);

\draw[->, thick] (engine.east) to node[yshift=0.2cm] {proof} (checker.west);

\draw[->, thick] (checker.east) to (ack.south west);
\draw[->, thick] (checker.east) to (nack.north west);

\end{tikzpicture}
}
\caption{Typical proof assistant workflow, adapted from \cite{pa-history-geuvers-sadhana09}.}
\label{fig:workflow}
\end{figure}

The way that proof engineers typically write proofs can obfuscate the information that changes in programs, specifications, and proofs carry.
One common process for writing this proof is interactive: The proof engineer passes the proof assistant high-level
search procedures called \textit{tactics} (like \lstinline{induction}), and the proof assistant responds to each tactic
by refining the current goal to some subgoal (like the proof obligation for the base case). This loop of tactics and goals 
continues until no goals remain, at which point the proof engineer has constructed a high-level sequence of tactics called a \textit{proof script}.
To check the proof, the proof assistant checks not the proof script itself, but instead a low-level representation called a \textit{proof object} 
that the proof script constructs.
Figure~\ref{fig:workflow} illustrates this workflow.

The high-level language of tactics can abstract away important details that a proof repair tool needs,
but the low-level language of proof objects can be brittle and challenging to work with.
Crucially, though, the low-level language comes with lots of structure and strong guarantees.
My approach to proof repair works in the low-level language to take advantage of that.
It then builds back up to the high-level language in the end.

By working at the low-level language, it is able to systematically and with strong guarantees extract and generalize the 
information that breaking changes carry,
then apply those changes to fix other proofs broken by the same change.
But by later building up to the high-level language,
it can in the end produce proofs that integrate more naturally with proof engineering workflows.

This works using a combination of semantic differencing and program transformations in this low-level language.
In particular, it uses a semantic differencing algorithm to extract information from a breaking change in a program, specification, or proof.
It then combines that with program transformations to generalize and, in some cases, apply that information to fix other 
proofs broken by the same change.
In the end, it uses a prototype decompiler to get from the low-level language back up to the high-level language,
so that proof engineers can continue to work in that language going forward. % TODO lol this sucks but whatever it's a first draft

\section{Results}

The results of this thesis are threefold:

\begin{enumerate}
\item the \textbf{design} of differencing algorithms \& program transformations for proof repair
\item an \textbf{implementation} of a proof repair tool 
\item \textbf{case studies} to evaluate the tool
\end{enumerate}

\paragraph{Design}
mention the two different kinds of each of these

\paragraph{Implementation}
\sysname
in the Coq proof assistant~\cite{coq} that doesn't extend the TCB (will need to explain the TCB or whatever)
LOC etc
decompiler

\paragraph{Case Studies}
for all of the tools
summary
forward references

% Dan: It might be good either in 1 or in both 3 and 4 to lay out the key /results/ -- you have _design_ of the transformation, 
% the highly non-trivial _implementation_ in Coq in a way that doesn't extend the TCB, and you have substantial case studies to _evaluate_.
% You have a bit of formalism and metatheory, but that is more for exposition than for specific results (am I right?) -- you are 
% guided by the theory to build tools that actually work in this unforgiving domain -- "hacks won't work".

\input{guide}
