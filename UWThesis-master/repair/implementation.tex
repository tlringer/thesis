\section{Implementation}
\label{sec:pumpkin-impl}

% TODO somewhere, something about plugins, either here or earlier. LOC and so on.

The source code of the \contour[2]{violet}{\kl{\sysnamelong}} proof repair plugin suite is on Github.\footnote{Latest version: \url{http://github.com/uwplse/PUMPKIN-PATCH}.\\ Stable thesis release: \url{https://github.com/uwplse/PUMPKIN-PATCH/tree/v1.0}.\\ Coq 8.9.1 branch: \url{https://github.com/uwplse/PUMPKIN-PATCH/tree/8.9.1}.\\ 2018 release: \url{https://github.com/uwplse/PUMPKIN-PATCH/releases/tag/cpp18}.}
It includes the source code of the \contour[2]{violet}{\kl{\sysname}} prototype plugin, extended with a number of new features.
The thesis release supports Coq 8.8, with Coq 8.9.1 support in a branch.

This section describes the implementation of the \sysname prototype (Section~\ref{sec:tool}),
along with some new features that go beyond the original prototype and help with workflow integration (Section~\ref{sec:workflow}),
plus an evaluation of the boundaries of the \sysname prototype that still stand (Section~\ref{sec:bound-eval}).
The interested reader can follow along in the repository.

% TODO somewhere, need to mention some of the things to consider in implementation, like constants

\subsection{Tool Details}
\label{sec:tool}

% from Inside the Core
% Some of this may be better placed in earlier sections
% TODO use the cool links
% TODO which comes first, trees or configuration finding

The implementation (Section~\ref{sec:pumpkin-impl-procedure}) of the procedure from Figure~\ref{alg:patching} in Section~\ref{sec:pumpkin-workflow}
starts with a preprocessing step which compiles the proof terms to 
trees (like the tree in Figure~\ref{fig:cattree}).\footnote{Representing proof terms directly as trees in the implementation rather
than just in the theory is one of my biggest regrets three years later.
This representation is useful for understanding how differencing works over inductive types, but implementing it adds clutter that makes \sysname difficult to maintain.
My later work represents proof terms as terms, and avoids this representation.}
The implementation always maintains pointers to easily switch between the tree and AST representations of the terms.
Differencing (Section~\ref{sec:pumpkin-impl-diff}) operates over trees, 
while the transformations (Section~\ref{sec:pumpkin-impl-trans}) operate directly over the terms those trees represent.
\sysname has no impact on the \kl{TCB} (Section~\ref{sec:tcb}).

\subsubsection{The Procedure}
\label{sec:pumpkin-impl-procedure}

The \sysname prototype exposes the patch finding procedure (\lstinline{patcher.ml4}) to users through the Coq command \lstinline{Patch Proof}. 
After compiling to trees (\lstinline{evaluation.ml}),
\sysname automatically infers which \kl{instance} of the search procedure to use from the example change. % TODO link to right part of code
%For example, to find a patch for the case study we will see in Section~\ref{sec:compcert}, I
%used this command: % TODO adapt this text since case studies are no longer before this, maybe move figure and so on here

%\begin{lstlisting}[language=ml4]
%  Patch Proof Old.unsigned_range unsigned_range as patch.
%\end{lstlisting}
%\sysname analyzed both versions of \lstinline{unsigned_range} and determined 
%that a constructor of the \lstinline{int} type changed (Figure~\ref{fig:int}),
%so it initialized the search procedure to the instance for changes in constructors.

Internally, \sysname represents search procedure instances as sets of options,
which it passes to the procedure. The procedure uses these options to determine
how to compose components (for example, whether to generalize candidates) 
and how to customize components (for example, whether semantic differencing should look for an intermediate lemma).
In total, the \sysname prototype currently implements six instances.
The first five correspond to changes in:

\begin{enumerate}
\item conclusions of theorems,
\item hypotheses of theorems,
\item dependent arguments to constructors of inductive types, 
\item conclusions of constructors of inductive types, and
\item cases of fixpoints.
\end{enumerate}
The final instance is useful for proof optimization (Section~\ref{sec:workflow}).
The support for these changes is limited in expressiveness and power;
more information on limitations in scope can be found in the repository. % TODO link
Extending \sysname with a new instance of the search procedure amounts to extending key functions in the implementation
with a case corresponding to the new instance.

\subsubsection{Differencing} 
\label{sec:pumpkin-impl-diff}

As noted in Section~\ref{sec:pumpkin-diff}, \kl{differencing} (\lstinline{differencing.ml}) operates over trees.
Differencing uses the structure of these trees to prioritize semantically relevant differences.
At the lowest level, it calls a primitive differencing function which checks if it can substitute one term within another term to find a function between their types.

The differencing component is \textit{lazy}: it compiles terms into trees one step at a time.
It then \emph{expands} each tree as needed to find candidates (\lstinline{expansion.ml}).
For example, differencing two functions for a patch between conclusions:
%For example, suppose both terms are functions that take an argument of the same type:

\begin{lstlisting}
  fun (t : T) => b
  fun (t' : T) => b'
\end{lstlisting}
Differencing introduces a single term of type \lstinline{T} to a common environment,
then expands and recursively diffs the bodies \lstinline{b} and \lstinline{b'} in that environment.

\subsubsection{Transformation}
\label{sec:pumpkin-impl-trans}

\sysname implements the four \kl{transformations} from Section~\ref{sec:pumpkin-trans}:
\kl{specialization}, \kl{generalization}, \kl{inversion}, and \kl{factoring}.
These transformations operate directly over terms in Gallina.
The \sysname procedure chooses among them by search procedure instance,
and in the end checks the type of the patch to ensure that is has the goal type.
\sysname also determines what arguments to pass to each transformation based on the instance.
As a bonus, \sysname exposes commands that correspond to each of these transformations (\lstinline{patcher.ml4}),
so that proof engineers can call them outside of the proof patching procedure.

\paragraph{Specialization} \kl{Specialization} (\lstinline{specialize.ml}) takes a patch candidate and some arguments,
all of which are Gallina terms.
It also takes a custom reducer (\lstinline{reducers.ml}) % in coq-plugin-lib
as a higher-order function that reduces a Coq term.
It applies the candidate function to the arguments, then reduces the result using the supplied reducer.

The default specializer reduces the result using Coq's
\lstinline{Reduction.nf_betaiotazeta} function.
Other reducers include one that does not reduce at all, one that removes unnecessary applications of the identity function, 
one that does weak head reduction, one that completely normalizes terms, % one that removes unused hypotheses,
and one that $\delta$-reduces to unwrap constants.
There are also higher-order combinators for reducers,
including chain reduction with errors, chain reduction without errors, and reduction over the types of supplied terms.
This makes it possible for search procedure instances to highly customize specialization.
%and further ends up being a useful programming paradigm for developing the \toolnamec extension in Chapter~\ref{chapt:pi}.
I expose these reducers and combinators in the Coq plugin library. % TODO link and explain

\paragraph{Generalization} \kl{Generalization} (\lstinline{abstraction.ml}) % TODO rename
takes a patch candidate, the goal type, and the arguments or function by which to generalize,
all as Gallina terms.
It also takes a list of substitution strategies to determine what subterms to substitute, and how.
After generalizing the candidate to a lambda term, it substitutes subterms inside of the body with the generalized argument
using the supplied list of substitution strategies, in order.

The simplest strategy replaces all terms convertible to a particular concrete argument % TODO explain convertible/definitionally equal
with the supplied generalized argument.
In some cases, this strategy is not sufficient.
It may be possible to produce a patch only by generalizing \emph{some} of the subterms
convertible to the argument or function (see Section~\ref{sec:fail}),
or the term may not contain any subterms convertible to the argument or function at all.

I implement several strategies to account for this. The combinations strategy, for example,
tries all combinations of substituting only some of the convertible subterms with the generalized argument. 
The pattern-based strategy substitutes subterms that match a certain pattern
with a term that corresponds to that pattern.
Some strategies reduce before generalizing, and some do not.
I expose these strategies in the \sysname OCaml API (\lstinline{abstracters.mli}). % TODO missing earlier section on OCaml/Coq plugins

\paragraph{Inversion} \kl{Inversion} (\lstinline{inverting.ml}) takes as input a patch candidate as a Gallina proof term,
and tries to reverse the conclusion of its type.
It works by first factoring the candidate,
then exploiting symmetry properties to invert those factors,
then finally composing the inverted factors in the opposite order.

For example, recall that the equality eliminator in Gallina is \lstinline{eq_rect}.
The \lstinline{rewrite} tactic in Ltac often compiles down to an application of \lstinline{eq_rect}. % TODO be consistent about this vs eq_ind, including intermediate arguments
Since equality is symmetric, the Coq standard library also comes equipped with an inverse function \lstinline{eq_rect_r},
related to \lstinline{eq_rect} by symmetry of equality:

\begin{lstlisting}[language=coq]
  (@\diff{eq\_rect\_r}@) A x P (H : P x) y (H0 : y = x) :=
    (@\diff{eq\_rect}@) x (fun y0 : A => P y0) H y ((@\diff{eq\_sym}@) H0)	
\end{lstlisting} % TODO types
When inversion encounters an \lstinline{eq_rect} in one of its factors,
it reverses it by applying symmetry of equality, effectively producing an application of \lstinline{eq_rect_r}.
The opposite direction works similarly.

If inversion does not recognize any type symmetry properties it can exploit in a factor, it
strategically swaps subterms in the factor and type checks the result to see if it is an inverse.
This essentially amounts to an ad hoc attempt to discover symmetry properties.

\paragraph{Factoring} \kl{Factoring} (\lstinline{factoring.ml}) takes as input a Gallina term,
and attempts to break it into factors.
When it succeeds, it returns the factors as a list of terms;
otherwise, it returns the empty list.

Factoring works by searching with a term for factors.
Consider factoring a sequence of rewrites:
\begin{lstlisting}
  t (a b c d: nat) (H: a = b) (H0: b = c) (H1: c = d) : a = d :=
    eq_rect_r
      (fun (a0 : nat) => a0 = d)
      (eq_rect_r (fun (b0 : nat) => b0 = d) H1 H0)
      H.
\end{lstlisting}
into two independent rewrites:

\begin{lstlisting}
  f (a b c d: nat) (H: a = b) (H0: b = c) (H1: c = d) : b = d :=
    eq_rect_r (fun (b0 : nat) => b0 = d) H1 H0.

  g (a b c d: nat) (H: a = b) (H0: b = c) (H1: b = d) : a = d :=
    eq_rect_r (fun (a0 : nat) => a0 = d) H1 H.

  t (a b c d: nat) (H: a = b) (H0: b = c) (H1: c = d) : a = d :=
    g a b c d H H0 (f a b c d H H0 H1).
\end{lstlisting}
To discover \lstinline{f} and \lstinline{g},
factoring starts by assuming all of the hypotheses of \lstinline{t},
then searching as deep as possible within the conclusion of \lstinline{t} for a term
of type \lstinline{Y} for some \lstinline{Y} (here, the conclusion of \lstinline{f}, with type \lstinline{b = d}).
It then assumes \lstinline{Y}, and recursively factors the term
it gets from substituting in that hypothesis for \lstinline{f} (here, it assumes \lstinline{b = d}, and substitutes to derive the term \lstinline{g}).
It repeats this until it is able to reach the conclusion type (here \lstinline{a = d}, the type of the conclusion of \lstinline{g}),
at which point it has found the only possible path of factors, and it is done.
It returns these factors as Gallina terms.

\subsubsection{Trusted Computing Base}
\label{sec:tcb}

A common concern for proof developments is an increase in the \kl{TCB}.
%The Coq developers provide a safe plugin API in Coq 8.7 to address this~\cite{coq87news}.
%Our prototype takes this into consideration:
%While \sysname does not yet support Coq 8.7, it only calls the internal Coq functions that the 
%developers plan to expose in the safe API~\cite{coqPR}.
\sysname takes this into consideration.
In particular, \sysname is implemented as a Coq \kl{plugin},
and Coq type checks all terms that plugins produce.
Since \sysname does not modify the type checker, it cannot produce an ill typed term.
\sysname also does not add any axioms,
and so does not increase the TCB. % ugh whatever. I think there's better text on this in another paper

\subsection{Extensions}
\label{sec:workflow}

Since releasing the \sysname prototype, I have extended it with many features
for better integration into \kl{proof engineering} workflows.
This section summarizes three early extensions: Git integration, preliminary support for applying patches,
and proof optimization.
%I will detail tactic generation and more in Chapter~\ref{chapt:pi}.

% new, from Git repo though
\paragraph{Git Integration} \sysnamelong exposes a Git interface to \sysname
called \sysname-git~\cite{pumpkin-git}.
\sysname-git makes it possible to call \sysname's \lstinline{Patch Proof} command by command line over Git commits.
To call \sysname-git, the proof engineer simply runs the (command line) command:

\begin{lstlisting}
  pumpkin-git example_proof file.v -rev rev
\end{lstlisting}
This searches for a patch corresponding to the change in \lstinline{example_proof} in \lstinline{file.v} compared to the revision \lstinline{rev}
of the local repository. It will then prompt the proof engineer with the patch it finds, and either overwrite the file (with consent) 
or otherwise save the results to a temporary file. There are many options to control the behavior of \sysname-git,
all of which can be found in the repository.

\paragraph{Patch Application}
For the \sysname prototype, the differencing algorithm and proof term transformations extract and generalize information from example patched proofs
in the form of reusable patch, but do not yet help apply those patches automatically.
Since implementing the prototype, I have extended \sysname-git with preliminary support for patch application via hint generation.
The interface is: % TODO cite and explain

\begin{lstlisting}
  pumpkin-git example_proof_id file.v -rev rev -hint
\end{lstlisting}
This places the generated patch in a hint database in Coq.
Coq applies hints in its hint databases automatically, in some cases taking care of the changes at the proof script level
that the proof engineer would have to make to use these patches.

%Since the \sysname prototype, I have also extended \sysnamelong with the \toolnamec plugin.
%The \toolnamec plugin does apply the changes that it finds in all cases.
%Furthermore, it exposes a decompiler from proof terms back up to tactic scripts---this
%decompiler is exposed to the \sysname plugin as well, so that proof engineers can decompile patches
%back to tactics by calling the \lstinline{Decompile} command.
%I will discuss this decompiler and more in Chapter~\ref{chapt:pi}.

\paragraph{Proof Optimization}
Five of the implemented search procedure instances correspond to changes, but the sixth is special:
it corresponds to the \textit{absence} of change.
This makes it possible to reuse the \sysname infrastructure to optimize proofs
to automatically remove extra calls to induction.
See \lstinline{Optimization.v} for more information.

\subsection{Testing Boundaries}
\label{sec:bound-eval}

In this section, I explore the boundary between what the semantic differencing
and transformation implementations in the \sysname prototype can and cannot handle.
It is precisely this boundary that informs how to improve the implementations.

To evaluate this boundary, I tested the \sysname prototype on a suite of 50 pairs of proofs (Section~\ref{sec:suite}).
I designed 11 of these pairs to succeed, then modified their proofs to produce the remaining 39 pairs
that try to stress the core functionality of the tool.
%28 of the 50 variants did not stress \sysname at all.
I learned the following from the pairs
that tested \sysname's limitations:

\begin{enumerate}
\item \textbf{The failed pairs drive improvements.} \\
\sysname failed on 17 of 50 pairs. These pairs inform how to improve differencing and transformations in the future. (Section~\ref{sec:fail})
\item \textbf{The pairs reveal potential substitution strategies.} \\
\sysname produced an exponential number of candidates in 5 of 50 pairs.
New substitution strategies would dramatically reduce the number of candidates. (Section~\ref{sec:fail})
\item \contour[2]{violet}{\sysname} \textbf{was fast, but it could be even faster.} \\
The slowest successful patch took \SI{48}{\ms}. The slowest failure took \SI{7}{\ms}.
Simple changes could make \sysname more efficient. (Section~\ref{sec:perf})
\end{enumerate}

\subsubsection{Patch Generation Suite}
\label{sec:suite}

I wrote a suite\footnote{\url{http://github.com/uwplse/PUMPKIN-PATCH/blob/cpp18/plugin/coq/Variants.v}} of 50 pairs of proofs,
proving a total of 11 pairs of theorems.
I wrote these proofs myself since there was no existing benchmark suite to work with.
I used the following methodology:
%We designed 11 pairs to succeed, then modified these pairs to produce the remaining 39 pairs
%that stress the functionalti
%We designed 11 pairs to succeed:

\begin{enumerate}
\item Choose theorems \lstinline{old} and \lstinline{new}.
\item Write similar inductive proofs of \lstinline{old} and \lstinline{new}.
\item Modify the proof of \lstinline{old} to produce more pairs.
\item Search for patches from \lstinline{new} to \lstinline{old}.
\item If possible, search for patches from \lstinline{old} to \lstinline{new}.
\end{enumerate}

\iffalse
For example, one pair of theorems \lstinline{old} and \lstinline{new} was a 
simplification of the auxiliary lemmas
that we encountered in the case study in Section~\ref{sec:foundations}.
For the first proof of \lstinline{old}, we added a rewrite, like in the case study:

\begin{lstlisting}[language=coq]
    (@\diff{rewrite <- plus\_n\_O.}@) rewrite -> plus_comm.
\end{lstlisting}

For the second proof of \lstinline{old}, we commuted the rewrites:

\begin{lstlisting}[language=coq]
    rewrite -> plus_comm. (@\diff{rewrite <- plus\_n\_O.}@)
\end{lstlisting} 

We then searched for patches in both directions,
since the conclusions of \lstinline{old}
and \lstinline{new} were propositionally equal.
\fi

\begin{figure*}
\begin{lstlisting}[language=coq]
fun n m p (H : n <= m) (H0 : m <= p) =>
  (@\diff{le\_S n p}@) $\ldots$ (* proof of stronger lemma *)
: (@\ltacforall@) n m p,
    n <= m $\rightarrow$
    m <= p $\rightarrow$
    n <= (@\diff{S p}@).

fun n m p (H : n <= m) (H0 : m <= p) =>
  (@\diff{le\_plus\_trans n p 1}@) $\ldots$ (* proof of stronger lemma *)
: (@\ltacforall@) n m p,
    n <= m $\rightarrow$
    m <= p $\rightarrow$
    n <= (@\diff{p + 1}@).
\end{lstlisting}
\caption{Two proof terms \lstinline{old} (top) and \lstinline{new} (bottom) that contain the same proof of a stronger lemma.}
\label{fig:stronger}
\end{figure*}

My goal was to determine what changes to proofs stress the components
and how to use that information to drive improvements.
I focused on differences in conclusions, the most supported \kl{instance} of the search procedure at the time.
%The procedure defaults to \lstinline{old} when it cannot find a patch; 
%we marked each pair a success if \sysname found a direct patch,
%and a failure if it returned the default.
Since \sysname operates over terms,
I removed redundant proof terms, even if they were produced by different tactics.
I controlled the first pair of proofs of each pair of theorems for features I had not yet implemented at the time,
like nested induction, changes in hypotheses, and generalizing \lstinline{omega} terms.
These features sometimes showed up in later proofs (for example, after moving a rewrite);
I kept these proofs in the suite, since isolated changes to supported proofs that
introduce unsupported features can inform future improvements.	

\subsubsection{Three Challenges}
\label{sec:fail}

\sysname found patches for 33 of the 50 pairs. 28 of the 33 successes
did not stress \sysname at all: \sysname found the correct candidate immediately and was able to generalize it
in one try.
The pairs that \sysname failed to patch and the successful pairs that stressed generalization
reveal key information about how to improve differencing and the transformations.
I walk through three examples below.
%Future tools can use these as challenge problems to 
%improve upon \sysname.\footnote{The tool in Chapter~\ref{chapt:pi} already does, to some degree.
%For example, it is deliberately strategic about $\delta$-reduction, building on the insights from these challenges.}

\paragraph{A Challenge for Differencing} For one pair of proofs of theorems 
with \kl{propositionally equal} conclusions (Figure~\ref{fig:stronger}),
\kl{differencing} failed to find candidates in either direction.
These proofs both contain the same proof of a stronger lemma;
\sysname found patches from this lemma to
both \lstinline{old} and \lstinline{new},
but it was unable to find a patch between \lstinline{old} and \lstinline{new}.
A patch may show up deep in the difference between \lstinline{le_plus_trans}
and \lstinline{le_S}, but even if we $\delta$-reduce (unfold the definition of) \lstinline{le_plus_trans}, this is not obvious:

\begin{lstlisting}

  le_plus_trans n m p (H : n <= m) :=
    (fun lemma : m <= m + p =>
      trans_contra_inv_impl_morphism
        PreOrder_Transitive
        (m + p)
        m
        lemma)
    (le_add_r m p)
    H.
\end{lstlisting}
This points to two difficulties in finding patches: Knowing when to $\delta$-reduce terms 
is difficult; exploring the appropriate time for reduction
may produce patches for pairs that \sysname currently cannot patch.
Furthermore, finding patches is more challenging
when neither theorem has a conclusion that is as strong as possible.

\paragraph{A Challenge for Inversion} For one pair of proofs with \kl{propositionally equal} conclusions,
\sysname found a patch in one direction, but failed to \kl{invert} it:

\begin{lstlisting}[language=coq]
  fun n m p (_ : n <= m) (_ : m <= p) (H1 : n <= p) =>
    gt_le_S n (S p) (le_lt_n_Sm n p H1)
  : (@\ltacforall@) n m p,
      n <= m $\rightarrow$
      m <= p $\rightarrow$
      n <= p $\rightarrow$
      S n <= S p.
\end{lstlisting}
Inversion was unable to invert this term, even though an inverse does exist.
To invert this, inversion needs to know to $\delta$-reduce \lstinline{gt_le_S}:

\begin{lstlisting}[language=coq]
  gt_le_S n m :=
    (fun (H : (@\ltacforall@) n0 m0, (@\diff{n0 < m0}@) $\rightarrow$ (@\diff{S n0 <= m0}@)) => H n m) $\ldots$
  : (@\ltacforall@) n m,
      (@\diff{n < m}@) $\rightarrow$
      (@\diff{S n <= m}@).
\end{lstlisting}
It then needs to swap the hypothesis with the conclusion in \lstinline{H} to produce the inverse:

\begin{lstlisting}[language=coq]
  gt_le_S$\inv$ n m :=
    (fun (H : (@\ltacforall@) n0 m0, (@\diff{S n0 <= m0}@) $\rightarrow$ (@\diff{n0 < m0}@)) => H n m) $\ldots$
   : (@\ltacforall@) n m,
       (@\diff{S n <= m}@) $\rightarrow$
       (@\diff{n < m}@).
\end{lstlisting}

Inversion currently swaps subterms when it is not
aware of any symmetry properties about the inductive type. However,
it does not know when to $\delta$-reduce function definitions. Furthermore, 
there are many possible subterms to swap;
for inversion to know to only swap the subterms of \lstinline{H}, it must have a better
understanding of the structure of the term. Both of these are ways to improve inversion.

\paragraph{A Challenge for Generalization} \kl{Generalization} produced an exponential number of candidates when generalizing a patch candidate with this type:

\begin{lstlisting}[language=coq]
  (@\ltacforall@) n n0,
    (fun m => n <= max m n0) n $\rightarrow$
    (fun m => n <= max n0 m) n
\end{lstlisting}
The goal was to generalize by \lstinline{n} and produce a patch with this type:

\begin{lstlisting}[language=coq]
  (@\ltacforall@) (@\diff{m0}@) n n0,
    n <= max (@\diff{m0}@) n0 $\rightarrow$
    n <= max n0 (@\diff{m0}@).
\end{lstlisting}
The difficulty was in determining which occurrences of \lstinline{n} to generalize.
The component needed to generalize only the highlighted occurrences:

\begin{lstlisting}
  fun n n0 (H0 : n <= max n0 (@\diff{n}@)) =>
    @eq_rect_r
      nat
      (max n0 (@\diff{n}@))
      (fun n1 => n <= n1)
      H0
      (max (@\diff{n}@) n0)
      (max_comm (@\diff{n}@) n0)
\end{lstlisting}
The simplest substitution strategy failed, and a more
complex strategy
succeeded only after producing exponentially many candidates.
While this did not have a significant impact on time,
this makes a good case for semantics-aware substitution strategies.
In this case, we know from the type of the candidate
and the type of \lstinline{eq_ind_r} that these two hypothesis types 
are equivalent (similarly for the conclusions):

\begin{lstlisting}
  (fun m => n <= max m n0) n
  (fun n1 => n <= n1) (max n0 n)
\end{lstlisting}
The tool could search recursively for patches to find two patches that bridge the two equivalent
types:

\begin{lstlisting}
  p1 := fun n => max n0 n
  p2 := fun n => max n n0
\end{lstlisting}
Then the candidate type is exactly this:

\begin{lstlisting}
  (@\ltacforall@) n n0,
    (fun n1 => n <= n1) (@\diff{(p2 n)}@) $\rightarrow$
    (fun n1 => n <= n1) (@\diff{(p1 n)}@)
\end{lstlisting}
Generalization should thus generalize the highlighted subterms and the
terms that have types constrained by those subterms.
%It should not change \lstinline{(fun n1 => n <= n1)}.
This would produce a patch in one candidate:

\begin{lstlisting}
  fun (@\diff{m0}@) n n0 (H0 : n <= max n0 (@\diff{m0}@)) =>
    @eq_ind_r
      nat
      (max n0 (@\diff{m0}@))           (* p1 (@\diff{m0}@) *)
      (fun n1 => n <= n1) (* P *)
      H0                    (* : P (p1 (@\diff{m0}@)) *)
      (max (@\diff{m0}@) n0)           (* p2 (@\diff{m0}@) *)
      (max_comm (@\diff{m0}@) n0)      (* : p1 (@\diff{m0}@) = p2 (@\diff{m0}@) *)
\end{lstlisting}
This strategy would find a patch for one of the pairs that \sysname failed to generalize.
This is a natural future direction.

\subsubsection{Performance}
\label{sec:perf}

\sysname performed well for all pairs, and when it failed, it failed fast.
The slowest success took \SI{48}{\ms},
and the slowest failure took \SI{7}{\ms}.\footnote{i7-4790K, at 4.00 GHz, 32 GB RAM}
Though proof terms were small ($\le$ 67 LOC), I found this promising.

%\sysname was slowest %at finding patches 
%when the patch showed up inverted in the difference of proofs,
%since \sysname had to search twice, once in each direction.
%A future procedure may %implement search in both directions at once,
%or may 
%determine which direction to search first ahead of time; proof term size may be a simple heuristic for this.

