\section{Proof Repair}
\label{sec:mot-rep}

\kl{Proof repair} is a new form of \kl{proof automation} that automatically fixes broken proofs in response to change.
Unlike traditional proof automation, proof repair views programs, specifications, and proofs as fluid entities.
When a program or specification changes and this breaks proofs, proof repair extracts information from those
changes, generalizes it, and applies it to fix proofs broken by the change.

The name of proof repair is inspired by program repair~\cite{Monperrus:2018:ASR:3177787.3105906, Gazzola:2018:ASR:3180155.3182526},
or automatically fixing bugs in programs.
But my proof repair tools work differently from program repair tools, 
using a combination of \kl{semantic differencing} algorithms and \kl{proof term transformations} (Section~\ref{sec:how}).
All of this happens over low-level proof terms in \kl{Gallina}---and this is the key to success (Section~\ref{sec:infocert}).

\subsection{How Proof Repair Works}
\label{sec:how}

Recall my \kl{thesis}:

\begin{quote}
Changes in programs, specifications, and proofs can carry information that a tool can extract, generalize, and apply to fix other proofs broken by the same change. A tool that automates this can save work for proof engineers relative to reference manual repairs in practical use cases.
\end{quote}
My proof repair tools are the tools that automate this,
using a combination of semantic differencing and proof term transformations.
The \kl{differencing} algorithms compare the old and new version of the program, specification, or proof that has changed,
and from that extract the information carried by the change.
The \kl{transformations} then generalize that information and, in some cases, apply it to fix other proofs broken by the same change.
The details of all of this vary by the kind of breaking change,
as I will demonstrate in Chapters~\ref{ch:example} and~\ref{chapt:pi}.

% TODO an example would be nice here

The way that this works is quite different from the way that program repair tools typically work.
A number of program repair tools work by running tests or the programs themselves,
and many use fitness functions to identify candidate patches that 
are almost correct~\cite{Monperrus:2018:ASR:3177787.3105906}. % TODO check this
But there are not natural analogues of this in the world of proofs:
there are often no tests, it is not possible to just run the proof, and there is not a natural 
fitness function that describes what it means for a patch to a proof to be almost correct.

In addition, proof engineers write proofs in this high-level language of \kl{tactics}, \kl{Ltac}.
Each of these tactics is really a search procedure for a \kl{proof term}, so it is not straightforward to apply
typical program repair techniques to identify the next search procedure when a proof breaks.
Instead, proof repair tools can look down at the low-level language of proof terms, \kl{Gallina}.
But this is difficult: the type theory \kl{CIC$_{\omega}$} beneath Gallina is so rich that Gallina itself is quite unforgiving.
That is, even very small changes can produce proof terms that no longer type check.
But---and this is the key to proof repair---the unforgiving nature of Gallina actually turns out to be \textit{a good thing}.

\subsection{The Key to Proof Repair}
\label{sec:infocert}

The key to proof repair in this thesis is using the structure and information carried by Gallina proof terms.
In other words, differencing operates over Gallina terms,
and is guided by their semantics to narrow down the search space---it is \kl{semantic differencing}.
The transformations use the result of differencing to transform some proof term to a more general patch (in Chapter~\ref{ch:example})
or the patched proof itself (in Chapter~\ref{chapt:pi})---they are \kl{proof term transformations}.

This approach circumvents two of the biggest challenges in program repair:
gathering enough information to efficiently search for a patch,
and knowing when that patch is actually correct (Section~\ref{sec:repair}).
Thanks to the rich type theory beneath Gallina, changes in programs, specifications, and proofs
carry \textit{so much information} that my tools can use to search for a patch,
and proofs provide \textit{so much certainty} that the patch my tools find is correct in the end.
This is why proof repair works.

But this approach presents its own challenges,
like how to deal with the unforgiving nature of proof terms,
and how to produce friendly proof scripts in the end.
So Chapters~\ref{ch:example} and~\ref{chapt:pi} will show two tools that instantiate this approach,
and describe how these tools tackle these challenges.
Each chapter will introduce a tool that supports a different class of changes.
The first tool (Chapter~\ref{ch:example}) implements proof repair \kl{by example},
while the second tool (Chapter~\ref{chapt:pi}) implements proof repair \kl{across equivalences}.
Chapters~\ref{ch:example} and~\ref{chapt:pi} will follow a parallel structure:

\begin{itemize}
\item \textbf{Motivating Example} (Sections~\ref{sec:patch-motivating} and~\ref{sec:overview}):
an example that motivates the supported class of changes. 
\item \textbf{Approach} (Sections~\ref{sec:pumpkin-approach} and~\ref{sec:pi-approach}):
a high-level description of how the approach in Section~\ref{sec:how} is instantiated.
\item \textbf{Differencing} (Sections~\ref{sec:pumpkin-diff} and~\ref{sec:pi-diff}):
detailed explanations of the corresponding differencing algorithms.
\item \textbf{Transformations} (Sections~\ref{sec:pumpkin-trans} and~\ref{sec:pi-trans}):
detailed explanations of the corresponding proof term transformations.
\item \textbf{Implementation} (Sections~\ref{sec:pumpkin-impl} and~\ref{sec:pi-implementation}):
a description of the implementation of the approach as a tool for Coq.
\item \textbf{Results} (Sections~\ref{sec:pumpkin-results} and~\ref{sec:pi-results}):
results from case studies and experiments that show the tool can save work for proof engineers.
\item \textbf{Conclusion} (Sections~\ref{sec:pumpkin-concl} and~\ref{sec:pi-concl}):
a conclusion and reflection on how the thesis is validated so far.
\end{itemize}

Enjoy.

\paragraph{Historical Note}
Chapter~\ref{ch:example} draws on the 2018 work that introduced the original proof repair vision,
while Chapter~\ref{chapt:pi} draws on the more mature work that followed.
This difference in maturity permeates the \kl{results} of each chapter:

\begin{itemize}
\item \kl{Design}: Chapter~\ref{ch:example} describes its algorithms at a high level, as ad hoc heuristics
that sometimes struggle with undecidability.
It defines judgments for these algorithms as interfaces, but does not provide the derivations.
Chapter~\ref{chapt:pi} formalizes more elegant algorithms, building on insights from Chapter~\ref{ch:example},
and cleanly separating the decidable and undecidable parts.
\item \kl{Implementation}:
Chapter~\ref{ch:example} describes a \textit{prototype} plugin.
This prototype includes little automation for \textit{applying} patches,
integrates poorly into proof engineering workflows,
and does not properly unfold constants ($\delta$-reduce).
Chapter~\ref{chapt:pi} details technologies that address these limitations,
some of which can be used with the Chapter~\ref{ch:example} prototype if desired.
\item \kl{Case studies}:
Chapter~\ref{ch:example} shows only that a tool \textit{could have helped} proof engineers retroactively
on a few repair scenarios over small proofs of a fixed style.
Chapter~\ref{chapt:pi} shows that a tool
\textit{can help} and in fact \textit{has helped} proof engineers on a variety of real repair scenarios,
supporting larger proof developments (about 10000 LOC) in an order of seconds,
regardless of proof style.
\end{itemize}

